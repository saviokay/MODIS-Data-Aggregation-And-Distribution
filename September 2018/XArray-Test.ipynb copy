{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (1.14.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas) (1.14.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netcdf4 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (1.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.7 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from netcdf4) (1.14.3)\r\n",
      "Requirement already satisfied: cftime in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from netcdf4) (1.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (0.23.4)\r\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas) (2.7.3)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas) (1.14.3)\r\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas) (2018.4)\r\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (1.14.3)\n",
      "Requirement already satisfied: scipy in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (1.1.0)\n",
      "Requirement already satisfied: matplotlib in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: ipython in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (6.4.0)\n",
      "Requirement already satisfied: jupyter in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: pandas in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: sympy in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied: nose in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (1.3.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from matplotlib) (2.7.3)\n",
      "Requirement already satisfied: pytz in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from matplotlib) (2018.4)\n",
      "Requirement already satisfied: six>=1.10 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pygments in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (39.1.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (0.12.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (4.3.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (4.5.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (0.8.1)\n",
      "Requirement already satisfied: backcall in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (1.0.15)\n",
      "Requirement already satisfied: pickleshare in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (0.7.4)\n",
      "Requirement already satisfied: decorator in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipython) (4.3.0)\n",
      "Requirement already satisfied: notebook in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jupyter) (5.5.0)\n",
      "Requirement already satisfied: qtconsole in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jupyter) (4.3.1)\n",
      "Requirement already satisfied: jupyter-console in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jupyter) (5.2.0)\n",
      "Requirement already satisfied: nbconvert in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jupyter) (5.3.1)\n",
      "Requirement already satisfied: ipykernel in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jupyter) (4.8.2)\n",
      "Requirement already satisfied: ipywidgets in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jupyter) (7.2.1)\n",
      "Requirement already satisfied: parso>=0.2.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->ipython) (0.2.0)\n",
      "Requirement already satisfied: ipython_genutils in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2->ipython) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython) (0.1.7)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (5.2.3)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (2.10)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (0.8.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (17.0.0)\n",
      "Requirement already satisfied: Send2Trash in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: nbformat in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (4.4.0)\n",
      "Requirement already satisfied: tornado>=4 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from notebook->jupyter) (5.0.2)\n",
      "Requirement already satisfied: mistune>=0.7.4 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from nbconvert->jupyter) (0.8.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from nbconvert->jupyter) (0.2.3)\n",
      "Requirement already satisfied: bleach in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from nbconvert->jupyter) (2.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from nbconvert->jupyter) (1.4.2)\n",
      "Requirement already satisfied: testpath in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from nbconvert->jupyter) (0.3.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.2.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from ipywidgets->jupyter) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from jinja2->notebook->jupyter) (1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from nbformat->notebook->jupyter) (2.6.0)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from bleach->nbconvert->jupyter) (1.0.1)\n",
      "Requirement already satisfied: webencodings in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->jupyter) (0.5.1)\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/Users/saviosebastian/.local/lib'\n",
      "Check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user numpy scipy matplotlib ipython jupyter pandas sympy nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xarray in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (0.10.9)\n",
      "Requirement already satisfied: numpy>=1.12 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from xarray) (1.14.3)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from xarray) (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas>=0.19.2->xarray) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pandas>=0.19.2->xarray) (2018.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->xarray) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/9a/592314ceda78f3307afb6cf56d7fdbb92c5a5960a88a6d2fd25c11312ead/pytest-3.8.1-py2.py3-none-any.whl (209kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 5.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pytest) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pytest) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pytest) (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pytest) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pluggy>=0.7 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pytest) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pytest) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from pytest) (18.1.0)\n",
      "Installing collected packages: pytest\n",
      "  Found existing installation: pytest 3.8.0\n",
      "    Uninstalling pytest-3.8.0:\n",
      "      Successfully uninstalled pytest-3.8.0\n",
      "Successfully installed pytest-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mock in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (2.0.0)\r\n",
      "Requirement already satisfied: pbr>=0.11 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from mock) (4.2.0)\r\n",
      "Requirement already satisfied: six>=1.9 in /Users/saviosebastian/anaconda3/lib/python3.6/site-packages (from mock) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.6.5, pytest-3.8.1, py-1.5.3, pluggy-0.7.1\n",
      "rootdir: /Users/saviosebastian/Desktop/XArraysTest, inifile:\n",
      "plugins: remotedata-0.2.1, openfiles-0.3.0, doctestplus-0.1.3, arraydiff-0.2\n",
      "collected 6858 items / 1 skipped                                               \u001b[0m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1m\n",
      "\n",
      "xarray/tests/test_accessors.py .........................................\u001b[36m [  0%]\n",
      "\u001b[0m..............................................................\u001b[36m           [  1%]\u001b[0m\n",
      "xarray/tests/test_backends.py ..........................................\u001b[36m [  2%]\n",
      "\u001b[0m........................................................................\u001b[36m [  3%]\n",
      "\u001b[0m........................................................................\u001b[36m [  4%]\n",
      "\u001b[0m........................................................................\u001b[36m [  5%]\n",
      "\u001b[0m.................sssssssssssssssssssssssssssssssssssssssssssssssssssssss\u001b[36m [  6%]\n",
      "\u001b[0msssssssssssssssssssssssssssssssssssssssssssssssssssssssssss.............\u001b[36m [  7%]\n",
      "\u001b[0m........................................................................\u001b[36m [  8%]\n",
      "\u001b[0m....................................ss..................................\u001b[36m [  9%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 10%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 11%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 12%]\n",
      "\u001b[0m.....................................................................X..\u001b[36m [ 13%]\n",
      "\u001b[0m...............................................X........................\u001b[36m [ 14%]\n",
      "\u001b[0m....................ssssssssssssssssssssssssssssssssssssssssssssssssssss\u001b[36m [ 15%]\n",
      "\u001b[0msssssssssssssssssss..............................F.sssssssssssssssssssss\u001b[36m [ 16%]\n",
      "\u001b[0msssssssssss.............................................................\u001b[36m [ 17%]\n",
      "\u001b[0m.................................sssssssssssssssssssssssssssssssssssssss\u001b[36m [ 18%]\n",
      "\u001b[0mssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\u001b[36m [ 19%]\n",
      "\u001b[0msssssssss...........\u001b[36m                                                     [ 20%]\u001b[0m\n",
      "xarray/tests/test_cftime_offsets.py ....................................\u001b[36m [ 20%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 21%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 22%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 23%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 24%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 26%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 27%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 28%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 29%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 30%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 31%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 32%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 33%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 34%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 35%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 36%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 37%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 38%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 39%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 40%]\n",
      "\u001b[0m.................................................................\u001b[36m        [ 41%]\u001b[0m\n",
      "xarray/tests/test_cftimeindex.py .......................................\u001b[36m [ 42%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 43%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 44%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 45%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 46%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 47%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 48%]\n",
      "\u001b[0m..........\u001b[36m                                                               [ 48%]\u001b[0m\n",
      "xarray/tests/test_coding.py .........\u001b[36m                                    [ 48%]\u001b[0m\n",
      "xarray/tests/test_coding_strings.py ...................\u001b[36m                  [ 49%]\u001b[0m\n",
      "xarray/tests/test_coding_times.py ......................................\u001b[36m [ 49%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 50%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 51%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 52%]\n",
      "\u001b[0m...............\u001b[36m                                                          [ 53%]\u001b[0m\n",
      "xarray/tests/test_combine.py ..................\u001b[36m                          [ 53%]\u001b[0m\n",
      "xarray/tests/test_computation.py .................................\u001b[36m       [ 53%]\u001b[0m\n",
      "xarray/tests/test_conventions.py .......................................\u001b[36m [ 54%]\n",
      "\u001b[0m.......s.................\u001b[36m                                                [ 54%]\u001b[0m\n",
      "xarray/tests/test_dask.py ..............................................\u001b[36m [ 55%]\n",
      "\u001b[0m..x..................\u001b[36m                                                    [ 55%]\u001b[0m\n",
      "xarray/tests/test_dataarray.py .........................................\u001b[36m [ 56%]\n",
      "\u001b[0m.....................................s..................................\u001b[36m [ 57%]\n",
      "\u001b[0m........................................sss.............................\u001b[36m [ 58%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 59%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 60%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 61%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 62%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 63%]\n",
      "\u001b[0m...............................................................sssssssss\u001b[36m [ 64%]\n",
      "\u001b[0mssss\u001b[36m                                                                     [ 64%]\u001b[0m\n",
      "xarray/tests/test_dataset.py ...........................................\u001b[36m [ 65%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 66%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 67%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 68%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 69%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 70%]\n",
      "\u001b[0m.......................................................................s\u001b[36m [ 71%]\n",
      "\u001b[0msssssssssssssss.........................................................\u001b[36m [ 72%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 73%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 74%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 75%]\n",
      "\u001b[0m......................................\u001b[36m                                   [ 76%]\u001b[0m\n",
      "xarray/tests/test_dtypes.py .......................................\u001b[36m      [ 76%]\u001b[0m\n",
      "xarray/tests/test_duck_array_ops.py .................................ss.\u001b[36m [ 77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m.............ss..............ss......ss......ss..............ss.........\u001b[36m [ 78%]\n",
      "\u001b[0m.............................................ss......ss.................\u001b[36m [ 79%]\n",
      "\u001b[0m.............ss..............ss..............ss......ss......ss.........\u001b[36m [ 80%]\n",
      "\u001b[0m.....ss......................................................ss......ss.\u001b[36m [ 81%]\n",
      "\u001b[0m...............ssssssssss..........ssssssssss..........ssssssssss.......\u001b[36m [ 82%]\n",
      "\u001b[0m...ssssssssss..........ssssss..............ssssss..............ssssss...\u001b[36m [ 83%]\n",
      "\u001b[0m...........ssssss..............sssssssssss.s.s.s.s.sssssssssss.s.s.s.s.s\u001b[36m [ 84%]\n",
      "\u001b[0mssssssssss.s.s.s.s.sssssssssss.s.s.s.s.sssssss.s.s.s.s.s.s.sssssss.s.s.s\u001b[36m [ 85%]\n",
      "\u001b[0m.s.s.s.sssssss.s.s.s.s.s.s.sssssss.s.s.s.s.s.s..........................\u001b[36m [ 86%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 87%]\n",
      "\u001b[0m......\u001b[36m                                                                   [ 88%]\u001b[0m\n",
      "xarray/tests/test_extensions.py ....\u001b[36m                                     [ 88%]\u001b[0m\n",
      "xarray/tests/test_formatting.py .............\u001b[36m                            [ 88%]\u001b[0m\n",
      "xarray/tests/test_groupby.py ......\u001b[36m                                      [ 88%]\u001b[0m\n",
      "xarray/tests/test_indexing.py ..........................................\u001b[36m [ 89%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 90%]\n",
      "\u001b[0m....\u001b[36m                                                                     [ 90%]\u001b[0m\n",
      "xarray/tests/test_interp.py .......ss.........................x.\u001b[36m         [ 90%]\u001b[0m\n",
      "xarray/tests/test_merge.py .................\u001b[36m                             [ 90%]\u001b[0m\n",
      "xarray/tests/test_missing.py .................................\u001b[36m           [ 91%]\u001b[0m\n",
      "xarray/tests/test_nputils.py ...\u001b[36m                                         [ 91%]\u001b[0m\n",
      "xarray/tests/test_options.py ..\u001b[36m                                          [ 91%]\u001b[0m\n",
      "xarray/tests/test_plot.py ..............................................\u001b[36m [ 92%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 93%]\n",
      "\u001b[0m.....................................................s..................\u001b[36m [ 94%]\n",
      "\u001b[0m........................................................................\u001b[36m [ 95%]\n",
      "\u001b[0m.....................................\u001b[36m                                    [ 95%]\u001b[0m\n",
      "xarray/tests/test_testing.py .\u001b[36m                                           [ 95%]\u001b[0m\n",
      "xarray/tests/test_tutorial.py s\u001b[36m                                          [ 95%]\u001b[0m\n",
      "xarray/tests/test_ufuncs.py ..............\u001b[36m                               [ 96%]\u001b[0m\n",
      "xarray/tests/test_utils.py ............................\u001b[36m                  [ 96%]\u001b[0m\n",
      "xarray/tests/test_variable.py ..........................................\u001b[36m [ 97%]\n",
      "\u001b[0m................................................................X.....x.\u001b[36m [ 98%]\n",
      "\u001b[0m......x......X..........................................................\u001b[36m [ 99%]\n",
      "\u001b[0m.......x.xxx...................x......x.................\u001b[36m                 [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________ test_open_mfdataset_manyfiles[netcdf4-100-False-False-None] __________\u001b[0m\n",
      "\n",
      "suffix = '.nc', allow_cleanup_failure = False\n",
      "\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\n",
      "\u001b[1m        try:\u001b[0m\n",
      "\u001b[1m>           yield path\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "nfiles = 100, suffix = '.nc', allow_cleanup_failure = False\n",
      "\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\n",
      "\u001b[1m    def create_tmp_files(nfiles, suffix='.nc', allow_cleanup_failure=False):\u001b[0m\n",
      "\u001b[1m        with ExitStack() as stack:\u001b[0m\n",
      "\u001b[1m            files = [stack.enter_context(create_tmp_file(suffix,\u001b[0m\n",
      "\u001b[1m                                                         allow_cleanup_failure))\u001b[0m\n",
      "\u001b[1m                     for apath in np.arange(nfiles)]\u001b[0m\n",
      "\u001b[1m>           yield files\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:900: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "readengine = 'netcdf4', nfiles = 100, autoclose = False, parallel = False\n",
      "chunks = None\n",
      "\n",
      "\u001b[1m    def test_open_mfdataset_manyfiles(readengine, nfiles, autoclose, parallel,\u001b[0m\n",
      "\u001b[1m                                      chunks):\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        # skip certain combinations\u001b[0m\n",
      "\u001b[1m        skip_if_not_engine(readengine)\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        if not has_dask and parallel:\u001b[0m\n",
      "\u001b[1m            pytest.skip('parallel requires dask')\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        if readengine == 'h5netcdf' and autoclose:\u001b[0m\n",
      "\u001b[1m            pytest.skip('h5netcdf does not support autoclose yet')\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        if ON_WINDOWS:\u001b[0m\n",
      "\u001b[1m            pytest.skip('Skipping on Windows')\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        randdata = np.random.randn(nfiles)\u001b[0m\n",
      "\u001b[1m        original = Dataset({'foo': ('x', randdata)})\u001b[0m\n",
      "\u001b[1m        # test standard open_mfdataset approach with too many files\u001b[0m\n",
      "\u001b[1m        with create_tmp_files(nfiles) as tmpfiles:\u001b[0m\n",
      "\u001b[1m            writeengine = (readengine if readengine != 'pynio' else 'netcdf4')\u001b[0m\n",
      "\u001b[1m            # split into multiple sets of temp files\u001b[0m\n",
      "\u001b[1m            for ii in original.x.values:\u001b[0m\n",
      "\u001b[1m                subds = original.isel(x=slice(ii, ii + 1))\u001b[0m\n",
      "\u001b[1m                subds.to_netcdf(tmpfiles[ii], engine=writeengine)\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m            # check that calculation on opened datasets works properly\u001b[0m\n",
      "\u001b[1m            actual = open_mfdataset(tmpfiles, engine=readengine, parallel=parallel,\u001b[0m\n",
      "\u001b[1m>                                   autoclose=autoclose, chunks=chunks)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:1979: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "paths = ['/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpqvolv7p4/temp-2827.nc', '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsq...qc0000gn/T/tmpap8w6xzi/temp-2831.nc', '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp49gj5my9/temp-2832.nc', ...]\n",
      "chunks = None, concat_dim = '__infer_concat_dim__', compat = 'no_conflicts'\n",
      "preprocess = None, engine = 'netcdf4'\n",
      "lock = <SerializableLock: 96447843-0a01-4500-8c9d-e714f8748475>\n",
      "data_vars = 'all', coords = 'different', autoclose = False, parallel = False\n",
      "kwargs = {}\n",
      "\n",
      "\u001b[1m    def open_mfdataset(paths, chunks=None, concat_dim=_CONCAT_DIM_DEFAULT,\u001b[0m\n",
      "\u001b[1m                       compat='no_conflicts', preprocess=None, engine=None,\u001b[0m\n",
      "\u001b[1m                       lock=None, data_vars='all', coords='different',\u001b[0m\n",
      "\u001b[1m                       autoclose=False, parallel=False, **kwargs):\u001b[0m\n",
      "\u001b[1m        \"\"\"Open multiple files as a single dataset.\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        Requires dask to be installed. See documentation for details on dask [1].\u001b[0m\n",
      "\u001b[1m        Attributes from the first dataset file are used for the combined dataset.\u001b[0m\n",
      "\u001b[1m    \u001b[0m\n",
      "\u001b[1m        Parameters\u001b[0m\n",
      "\u001b[1m        ----------\u001b[0m\n",
      "\u001b[1m        paths : str or sequence\u001b[0m\n",
      "\u001b[1m            Either a string glob in the form \"path/to/my/files/*.nc\" or an explicit\u001b[0m\n",
      "\u001b[1m            list of files to open.  Paths can be given as strings or as pathlib\u001b[0m\n",
      "\u001b[1m            Paths.\u001b[0m\n",
      "\u001b[1m        chunks : int or dict, optional\u001b[0m\n",
      "\u001b[1m            Dictionary with keys given by dimension names and values given by chunk\u001b[0m\n",
      "\u001b[1m            sizes. In general, these should divide the dimensions of each dataset.\u001b[0m\n",
      "\u001b[1m            If int, chunk each dimension by ``chunks``.\u001b[0m\n",
      "\u001b[1m            By default, chunks will be chosen to load entire input files into\u001b[0m\n",
      "\u001b[1m            memory at once. This has a major impact on performance: please see the\u001b[0m\n",
      "\u001b[1m            full documentation for more details [2].\u001b[0m\n",
      "\u001b[1m        concat_dim : None, str, DataArray or Index, optional\u001b[0m\n",
      "\u001b[1m            Dimension to concatenate files along. This argument is passed on to\u001b[0m\n",
      "\u001b[1m            :py:func:`xarray.auto_combine` along with the dataset objects. You only\u001b[0m\n",
      "\u001b[1m            need to provide this argument if the dimension along which you want to\u001b[0m\n",
      "\u001b[1m            concatenate is not a dimension in the original datasets, e.g., if you\u001b[0m\n",
      "\u001b[1m            want to stack a collection of 2D arrays along a third dimension.\u001b[0m\n",
      "\u001b[1m            By default, xarray attempts to infer this argument by examining\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m            component files. Set ``concat_dim=None`` explicitly to disable\u001b[0m\r\n",
      "\u001b[1m            concatenation.\u001b[0m\r\n",
      "\u001b[1m        compat : {'identical', 'equals', 'broadcast_equals',\u001b[0m\r\n",
      "\u001b[1m                  'no_conflicts'}, optional\u001b[0m\r\n",
      "\u001b[1m            String indicating how to compare variables of the same name for\u001b[0m\r\n",
      "\u001b[1m            potential conflicts when merging:\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            - 'broadcast_equals': all values must be equal when variables are\u001b[0m\r\n",
      "\u001b[1m              broadcast against each other to ensure common dimensions.\u001b[0m\r\n",
      "\u001b[1m            - 'equals': all values and dimensions must be the same.\u001b[0m\r\n",
      "\u001b[1m            - 'identical': all values, dimensions and attributes must be the\u001b[0m\r\n",
      "\u001b[1m              same.\u001b[0m\r\n",
      "\u001b[1m            - 'no_conflicts': only values which are not null in both datasets\u001b[0m\r\n",
      "\u001b[1m              must be equal. The returned dataset then contains the combination\u001b[0m\r\n",
      "\u001b[1m              of all non-null values.\u001b[0m\r\n",
      "\u001b[1m        preprocess : callable, optional\u001b[0m\r\n",
      "\u001b[1m            If provided, call this function on each dataset prior to concatenation.\u001b[0m\r\n",
      "\u001b[1m        engine : {'netcdf4', 'scipy', 'pydap', 'h5netcdf', 'pynio'}, optional\u001b[0m\r\n",
      "\u001b[1m            Engine to use when reading files. If not provided, the default engine\u001b[0m\r\n",
      "\u001b[1m            is chosen based on available dependencies, with a preference for\u001b[0m\r\n",
      "\u001b[1m            'netcdf4'.\u001b[0m\r\n",
      "\u001b[1m        autoclose : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, automatically close files to avoid OS Error of too many files\u001b[0m\r\n",
      "\u001b[1m            being open.  However, this option doesn't work with streams, e.g.,\u001b[0m\r\n",
      "\u001b[1m            BytesIO.\u001b[0m\r\n",
      "\u001b[1m        lock : False, True or threading.Lock, optional\u001b[0m\r\n",
      "\u001b[1m            This argument is passed on to :py:func:`dask.array.from_array`. By\u001b[0m\r\n",
      "\u001b[1m            default, a per-variable lock is used when reading data from netCDF\u001b[0m\r\n",
      "\u001b[1m            files with the netcdf4 and h5netcdf engines to avoid issues with\u001b[0m\r\n",
      "\u001b[1m            concurrent access when using dask's multithreaded backend.\u001b[0m\r\n",
      "\u001b[1m        data_vars : {'minimal', 'different', 'all' or list of str}, optional\u001b[0m\r\n",
      "\u001b[1m            These data variables will be concatenated together:\u001b[0m\r\n",
      "\u001b[1m              * 'minimal': Only data variables in which the dimension already\u001b[0m\r\n",
      "\u001b[1m                appears are included.\u001b[0m\r\n",
      "\u001b[1m              * 'different': Data variables which are not equal (ignoring\u001b[0m\r\n",
      "\u001b[1m                attributes) across all datasets are also concatenated (as well as\u001b[0m\r\n",
      "\u001b[1m                all for which dimension already appears). Beware: this option may\u001b[0m\r\n",
      "\u001b[1m                load the data payload of data variables into memory if they are not\u001b[0m\r\n",
      "\u001b[1m                already loaded.\u001b[0m\r\n",
      "\u001b[1m              * 'all': All data variables will be concatenated.\u001b[0m\r\n",
      "\u001b[1m              * list of str: The listed data variables will be concatenated, in\u001b[0m\r\n",
      "\u001b[1m                addition to the 'minimal' data variables.\u001b[0m\r\n",
      "\u001b[1m        coords : {'minimal', 'different', 'all' o list of str}, optional\u001b[0m\r\n",
      "\u001b[1m            These coordinate variables will be concatenated together:\u001b[0m\r\n",
      "\u001b[1m              * 'minimal': Only coordinates in which the dimension already appears\u001b[0m\r\n",
      "\u001b[1m                are included.\u001b[0m\r\n",
      "\u001b[1m              * 'different': Coordinates which are not equal (ignoring attributes)\u001b[0m\r\n",
      "\u001b[1m                across all datasets are also concatenated (as well as all for which\u001b[0m\r\n",
      "\u001b[1m                dimension already appears). Beware: this option may load the data\u001b[0m\r\n",
      "\u001b[1m                payload of coordinate variables into memory if they are not already\u001b[0m\r\n",
      "\u001b[1m                loaded.\u001b[0m\r\n",
      "\u001b[1m              * 'all': All coordinate variables will be concatenated, except\u001b[0m\r\n",
      "\u001b[1m                those corresponding to other dimensions.\u001b[0m\r\n",
      "\u001b[1m              * list of str: The listed coordinate variables will be concatenated,\u001b[0m\r\n",
      "\u001b[1m                in addition the 'minimal' coordinates.\u001b[0m\r\n",
      "\u001b[1m        parallel : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, the open and preprocess steps of this function will be\u001b[0m\r\n",
      "\u001b[1m            performed in parallel using ``dask.delayed``. Default is False.\u001b[0m\r\n",
      "\u001b[1m        **kwargs : optional\u001b[0m\r\n",
      "\u001b[1m            Additional arguments passed on to :py:func:`xarray.open_dataset`.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        Returns\u001b[0m\r\n",
      "\u001b[1m        -------\u001b[0m\r\n",
      "\u001b[1m        xarray.Dataset\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        See Also\u001b[0m\r\n",
      "\u001b[1m        --------\u001b[0m\r\n",
      "\u001b[1m        auto_combine\u001b[0m\r\n",
      "\u001b[1m        open_dataset\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        References\u001b[0m\r\n",
      "\u001b[1m        ----------\u001b[0m\r\n",
      "\u001b[1m        .. [1] http://xarray.pydata.org/en/stable/dask.html\u001b[0m\r\n",
      "\u001b[1m        .. [2] http://xarray.pydata.org/en/stable/dask.html#chunking-and-performance\u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if isinstance(paths, basestring):\u001b[0m\r\n",
      "\u001b[1m            if is_remote_uri(paths):\u001b[0m\r\n",
      "\u001b[1m                raise ValueError(\u001b[0m\r\n",
      "\u001b[1m                    'cannot do wild-card matching for paths that are remote URLs: '\u001b[0m\r\n",
      "\u001b[1m                    '{!r}. Instead, supply paths as an explicit list of strings.'\u001b[0m\r\n",
      "\u001b[1m                    .format(paths))\u001b[0m\r\n",
      "\u001b[1m            paths = sorted(glob(paths))\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            paths = [str(p) if isinstance(p, path_type) else p for p in paths]\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if not paths:\u001b[0m\r\n",
      "\u001b[1m            raise IOError('no files to open')\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if lock is None:\u001b[0m\r\n",
      "\u001b[1m            lock = _default_lock(paths[0], engine)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        open_kwargs = dict(engine=engine, chunks=chunks or {}, lock=lock,\u001b[0m\r\n",
      "\u001b[1m                           autoclose=autoclose, **kwargs)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if parallel:\u001b[0m\r\n",
      "\u001b[1m            import dask\u001b[0m\r\n",
      "\u001b[1m            # wrap the open_dataset, getattr, and preprocess with delayed\u001b[0m\r\n",
      "\u001b[1m            open_ = dask.delayed(open_dataset)\u001b[0m\r\n",
      "\u001b[1m            getattr_ = dask.delayed(getattr)\u001b[0m\r\n",
      "\u001b[1m            if preprocess is not None:\u001b[0m\r\n",
      "\u001b[1m                preprocess = dask.delayed(preprocess)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            open_ = open_dataset\u001b[0m\r\n",
      "\u001b[1m            getattr_ = getattr\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m>       datasets = [open_(p, **open_kwargs) for p in paths]\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m:624: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      ".0 = <list_iterator object at 0x1c16af9668>\r\n",
      "\r\n",
      "\u001b[1m>   datasets = [open_(p, **open_kwargs) for p in paths]\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m:624: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "filename_or_obj = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo/temp-2872.nc'\r\n",
      "group = None, decode_cf = True, mask_and_scale = True, decode_times = True\r\n",
      "autoclose = False, concat_characters = True, decode_coords = True\r\n",
      "engine = 'netcdf4', chunks = {}\r\n",
      "lock = <SerializableLock: 96447843-0a01-4500-8c9d-e714f8748475>, cache = False\r\n",
      "drop_variables = None, backend_kwargs = {}\r\n",
      "\r\n",
      "\u001b[1m    def open_dataset(filename_or_obj, group=None, decode_cf=True,\u001b[0m\r\n",
      "\u001b[1m                     mask_and_scale=None, decode_times=True, autoclose=False,\u001b[0m\r\n",
      "\u001b[1m                     concat_characters=True, decode_coords=True, engine=None,\u001b[0m\r\n",
      "\u001b[1m                     chunks=None, lock=None, cache=None, drop_variables=None,\u001b[0m\r\n",
      "\u001b[1m                     backend_kwargs=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Load and decode a dataset from a file or file-like object.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        Parameters\u001b[0m\r\n",
      "\u001b[1m        ----------\u001b[0m\r\n",
      "\u001b[1m        filename_or_obj : str, Path, file or xarray.backends.*DataStore\u001b[0m\r\n",
      "\u001b[1m            Strings and Path objects are interpreted as a path to a netCDF file\u001b[0m\r\n",
      "\u001b[1m            or an OpenDAP URL and opened with python-netCDF4, unless the filename\u001b[0m\r\n",
      "\u001b[1m            ends with .gz, in which case the file is gunzipped and opened with\u001b[0m\r\n",
      "\u001b[1m            scipy.io.netcdf (only netCDF3 supported). File-like objects are opened\u001b[0m\r\n",
      "\u001b[1m            with scipy.io.netcdf (only netCDF3 supported).\u001b[0m\r\n",
      "\u001b[1m        group : str, optional\u001b[0m\r\n",
      "\u001b[1m            Path to the netCDF4 group in the given file to open (only works for\u001b[0m\r\n",
      "\u001b[1m            netCDF4 files).\u001b[0m\r\n",
      "\u001b[1m        decode_cf : bool, optional\u001b[0m\r\n",
      "\u001b[1m            Whether to decode these variables, assuming they were saved according\u001b[0m\r\n",
      "\u001b[1m            to CF conventions.\u001b[0m\r\n",
      "\u001b[1m        mask_and_scale : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, replace array values equal to `_FillValue` with NA and scale\u001b[0m\r\n",
      "\u001b[1m            values according to the formula `original_values * scale_factor +\u001b[0m\r\n",
      "\u001b[1m            add_offset`, where `_FillValue`, `scale_factor` and `add_offset` are\u001b[0m\r\n",
      "\u001b[1m            taken from variable attributes (if they exist).  If the `_FillValue` or\u001b[0m\r\n",
      "\u001b[1m            `missing_value` attribute contains multiple values a warning will be\u001b[0m\r\n",
      "\u001b[1m            issued and all array values matching one of the multiple values will\u001b[0m\r\n",
      "\u001b[1m            be replaced by NA. mask_and_scale defaults to True except for the\u001b[0m\r\n",
      "\u001b[1m            pseudonetcdf backend.\u001b[0m\r\n",
      "\u001b[1m        decode_times : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, decode times encoded in the standard NetCDF datetime format\u001b[0m\r\n",
      "\u001b[1m            into datetime objects. Otherwise, leave them encoded as numbers.\u001b[0m\r\n",
      "\u001b[1m        autoclose : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, automatically close files to avoid OS Error of too many files\u001b[0m\r\n",
      "\u001b[1m            being open.  However, this option doesn't work with streams, e.g.,\u001b[0m\r\n",
      "\u001b[1m            BytesIO.\u001b[0m\r\n",
      "\u001b[1m        concat_characters : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, concatenate along the last dimension of character arrays to\u001b[0m\r\n",
      "\u001b[1m            form string arrays. Dimensions will only be concatenated over (and\u001b[0m\r\n",
      "\u001b[1m            removed) if they have no corresponding variable and if they are only\u001b[0m\r\n",
      "\u001b[1m            used as the last dimension of character arrays.\u001b[0m\r\n",
      "\u001b[1m        decode_coords : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, decode the 'coordinates' attribute to identify coordinates in\u001b[0m\r\n",
      "\u001b[1m            the resulting dataset.\u001b[0m\r\n",
      "\u001b[1m        engine : {'netcdf4', 'scipy', 'pydap', 'h5netcdf', 'pynio', 'pseudonetcdf'}, optional\u001b[0m\r\n",
      "\u001b[1m            Engine to use when reading files. If not provided, the default engine\u001b[0m\r\n",
      "\u001b[1m            is chosen based on available dependencies, with a preference for\u001b[0m\r\n",
      "\u001b[1m            'netcdf4'.\u001b[0m\r\n",
      "\u001b[1m        chunks : int or dict, optional\u001b[0m\r\n",
      "\u001b[1m            If chunks is provided, it used to load the new dataset into dask\u001b[0m\r\n",
      "\u001b[1m            arrays. ``chunks={}`` loads the dataset with dask using a single\u001b[0m\r\n",
      "\u001b[1m            chunk for all arrays.\u001b[0m\r\n",
      "\u001b[1m        lock : False, True or threading.Lock, optional\u001b[0m\r\n",
      "\u001b[1m            If chunks is provided, this argument is passed on to\u001b[0m\r\n",
      "\u001b[1m            :py:func:`dask.array.from_array`. By default, a global lock is\u001b[0m\r\n",
      "\u001b[1m            used when reading data from netCDF files with the netcdf4 and h5netcdf\u001b[0m\r\n",
      "\u001b[1m            engines to avoid issues with concurrent access when using dask's\u001b[0m\r\n",
      "\u001b[1m            multithreaded backend.\u001b[0m\r\n",
      "\u001b[1m        cache : bool, optional\u001b[0m\r\n",
      "\u001b[1m            If True, cache data loaded from the underlying datastore in memory as\u001b[0m\r\n",
      "\u001b[1m            NumPy arrays when accessed to avoid reading from the underlying data-\u001b[0m\r\n",
      "\u001b[1m            store multiple times. Defaults to True unless you specify the `chunks`\u001b[0m\r\n",
      "\u001b[1m            argument to use dask, in which case it defaults to False. Does not\u001b[0m\r\n",
      "\u001b[1m            change the behavior of coordinates corresponding to dimensions, which\u001b[0m\r\n",
      "\u001b[1m            always load their data from disk into a ``pandas.Index``.\u001b[0m\r\n",
      "\u001b[1m        drop_variables: string or iterable, optional\u001b[0m\r\n",
      "\u001b[1m            A variable or list of variables to exclude from being parsed from the\u001b[0m\r\n",
      "\u001b[1m            dataset. This may be useful to drop variables with problems or\u001b[0m\r\n",
      "\u001b[1m            inconsistent values.\u001b[0m\r\n",
      "\u001b[1m        backend_kwargs: dictionary, optional\u001b[0m\r\n",
      "\u001b[1m            A dictionary of keyword arguments to pass on to the backend. This\u001b[0m\r\n",
      "\u001b[1m            may be useful when backend options would improve performance or\u001b[0m\r\n",
      "\u001b[1m            allow user control of dataset processing.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        Returns\u001b[0m\r\n",
      "\u001b[1m        -------\u001b[0m\r\n",
      "\u001b[1m        dataset : Dataset\u001b[0m\r\n",
      "\u001b[1m            The newly created dataset.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        See Also\u001b[0m\r\n",
      "\u001b[1m        --------\u001b[0m\r\n",
      "\u001b[1m        open_mfdataset\u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if mask_and_scale is None:\u001b[0m\r\n",
      "\u001b[1m            mask_and_scale = not engine == 'pseudonetcdf'\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if not decode_cf:\u001b[0m\r\n",
      "\u001b[1m            mask_and_scale = False\u001b[0m\r\n",
      "\u001b[1m            decode_times = False\u001b[0m\r\n",
      "\u001b[1m            concat_characters = False\u001b[0m\r\n",
      "\u001b[1m            decode_coords = False\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if cache is None:\u001b[0m\r\n",
      "\u001b[1m            cache = chunks is None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if backend_kwargs is None:\u001b[0m\r\n",
      "\u001b[1m            backend_kwargs = {}\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        def maybe_decode_store(store, lock=False):\u001b[0m\r\n",
      "\u001b[1m            ds = conventions.decode_cf(\u001b[0m\r\n",
      "\u001b[1m                store, mask_and_scale=mask_and_scale, decode_times=decode_times,\u001b[0m\r\n",
      "\u001b[1m                concat_characters=concat_characters, decode_coords=decode_coords,\u001b[0m\r\n",
      "\u001b[1m                drop_variables=drop_variables)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            _protect_dataset_variables_inplace(ds, cache)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            if chunks is not None:\u001b[0m\r\n",
      "\u001b[1m                from dask.base import tokenize\u001b[0m\r\n",
      "\u001b[1m                # if passed an actual file path, augment the token with\u001b[0m\r\n",
      "\u001b[1m                # the file modification time\u001b[0m\r\n",
      "\u001b[1m                if (isinstance(filename_or_obj, basestring) and\u001b[0m\r\n",
      "\u001b[1m                        not is_remote_uri(filename_or_obj)):\u001b[0m\r\n",
      "\u001b[1m                    mtime = os.path.getmtime(filename_or_obj)\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    mtime = None\u001b[0m\r\n",
      "\u001b[1m                token = tokenize(filename_or_obj, mtime, group, decode_cf,\u001b[0m\r\n",
      "\u001b[1m                                 mask_and_scale, decode_times, concat_characters,\u001b[0m\r\n",
      "\u001b[1m                                 decode_coords, engine, chunks, drop_variables)\u001b[0m\r\n",
      "\u001b[1m                name_prefix = 'open_dataset-%s' % token\u001b[0m\r\n",
      "\u001b[1m                ds2 = ds.chunk(chunks, name_prefix=name_prefix, token=token,\u001b[0m\r\n",
      "\u001b[1m                               lock=lock)\u001b[0m\r\n",
      "\u001b[1m                ds2._file_obj = ds._file_obj\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                ds2 = ds\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            # protect so that dataset store isn't necessarily closed, e.g.,\u001b[0m\r\n",
      "\u001b[1m            # streams like BytesIO  can't be reopened\u001b[0m\r\n",
      "\u001b[1m            # datastore backend is responsible for determining this capability\u001b[0m\r\n",
      "\u001b[1m            if store._autoclose:\u001b[0m\r\n",
      "\u001b[1m                store.close()\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            return ds2\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if isinstance(filename_or_obj, path_type):\u001b[0m\r\n",
      "\u001b[1m            filename_or_obj = str(filename_or_obj)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if isinstance(filename_or_obj, backends.AbstractDataStore):\u001b[0m\r\n",
      "\u001b[1m            store = filename_or_obj\u001b[0m\r\n",
      "\u001b[1m        elif isinstance(filename_or_obj, basestring):\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            if (isinstance(filename_or_obj, bytes) and\u001b[0m\r\n",
      "\u001b[1m                    filename_or_obj.startswith(b'\\x89HDF')):\u001b[0m\r\n",
      "\u001b[1m                raise ValueError('cannot read netCDF4/HDF5 file images')\u001b[0m\r\n",
      "\u001b[1m            elif (isinstance(filename_or_obj, bytes) and\u001b[0m\r\n",
      "\u001b[1m                    filename_or_obj.startswith(b'CDF')):\u001b[0m\r\n",
      "\u001b[1m                # netCDF3 file images are handled by scipy\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m            elif isinstance(filename_or_obj, basestring):\u001b[0m\r\n",
      "\u001b[1m                filename_or_obj = _normalize_path(filename_or_obj)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            if filename_or_obj.endswith('.gz'):\u001b[0m\r\n",
      "\u001b[1m                if engine is not None and engine != 'scipy':\u001b[0m\r\n",
      "\u001b[1m                    raise ValueError('can only read gzipped netCDF files with '\u001b[0m\r\n",
      "\u001b[1m                                     \"default engine or engine='scipy'\")\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    engine = 'scipy'\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            if engine is None:\u001b[0m\r\n",
      "\u001b[1m                engine = _get_default_engine(filename_or_obj,\u001b[0m\r\n",
      "\u001b[1m                                             allow_remote=True)\u001b[0m\r\n",
      "\u001b[1m            if engine == 'netcdf4':\u001b[0m\r\n",
      "\u001b[1m                store = backends.NetCDF4DataStore.open(filename_or_obj,\u001b[0m\r\n",
      "\u001b[1m                                                       group=group,\u001b[0m\r\n",
      "\u001b[1m                                                       autoclose=autoclose,\u001b[0m\r\n",
      "\u001b[1m>                                                      **backend_kwargs)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m:320: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "cls = <class 'xarray.backends.netCDF4_.NetCDF4DataStore'>\r\n",
      "filename = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo/temp-2872.nc'\r\n",
      "mode = 'r', format = 'NETCDF4', group = None, writer = None, clobber = True\r\n",
      "diskless = False, persist = False, autoclose = False\r\n",
      "lock = <SerializableLock: 96447843-0a01-4500-8c9d-e714f8748475>\r\n",
      "\r\n",
      "\u001b[1m    @classmethod\u001b[0m\r\n",
      "\u001b[1m    def open(cls, filename, mode='r', format='NETCDF4', group=None,\u001b[0m\r\n",
      "\u001b[1m             writer=None, clobber=True, diskless=False, persist=False,\u001b[0m\r\n",
      "\u001b[1m             autoclose=False, lock=HDF5_LOCK):\u001b[0m\r\n",
      "\u001b[1m        import netCDF4 as nc4\u001b[0m\r\n",
      "\u001b[1m        if (len(filename) == 88 and\u001b[0m\r\n",
      "\u001b[1m                LooseVersion(nc4.__version__) < \"1.3.1\"):\u001b[0m\r\n",
      "\u001b[1m            warnings.warn(\u001b[0m\r\n",
      "\u001b[1m                'A segmentation fault may occur when the '\u001b[0m\r\n",
      "\u001b[1m                'file path has exactly 88 characters as it does '\u001b[0m\r\n",
      "\u001b[1m                'in this case. The issue is known to occur with '\u001b[0m\r\n",
      "\u001b[1m                'version 1.2.4 of netCDF4 and can be addressed by '\u001b[0m\r\n",
      "\u001b[1m                'upgrading netCDF4 to at least version 1.3.1. '\u001b[0m\r\n",
      "\u001b[1m                'More details can be found here: '\u001b[0m\r\n",
      "\u001b[1m                'https://github.com/pydata/xarray/issues/1745')\u001b[0m\r\n",
      "\u001b[1m        if format is None:\u001b[0m\r\n",
      "\u001b[1m            format = 'NETCDF4'\u001b[0m\r\n",
      "\u001b[1m        opener = functools.partial(_open_netcdf4_group, filename, mode=mode,\u001b[0m\r\n",
      "\u001b[1m                                   group=group, clobber=clobber,\u001b[0m\r\n",
      "\u001b[1m                                   diskless=diskless, persist=persist,\u001b[0m\r\n",
      "\u001b[1m                                   format=format)\u001b[0m\r\n",
      "\u001b[1m>       ds = opener()\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m:331: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "filename = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo/temp-2872.nc'\r\n",
      "mode = 'r', group = None\r\n",
      "kwargs = {'clobber': True, 'diskless': False, 'format': 'NETCDF4', 'persist': False}\r\n",
      "nc4 = <module 'netCDF4' from '/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/netCDF4/__init__.py'>\r\n",
      "\r\n",
      "\u001b[1m    def _open_netcdf4_group(filename, mode, group=None, **kwargs):\u001b[0m\r\n",
      "\u001b[1m        import netCDF4 as nc4\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m>       ds = nc4.Dataset(filename, mode=mode, **kwargs)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m:230: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "\u001b[1m>   ???\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31mnetCDF4/_netCDF4.pyx\u001b[0m:2123: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "\u001b[1m>   ???\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE   OSError: [Errno 24] Too many open files: b'/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo/temp-2872.nc'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31mnetCDF4/_netCDF4.pyx\u001b[0m:1743: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16d3de48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab5c0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16d3de48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptqaa4qs3'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c19556048>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptqaa4qs3'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c19556048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptqaa4qs3'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c19556048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptqaa4qs3'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16dc7a88>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabc50>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16dc7a88>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphj7bpwj0'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc268>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphj7bpwj0'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphj7bpwj0'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphj7bpwj0'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e69908>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab6d8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e69908>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptrr9vfla'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc488>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptrr9vfla'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc488>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptrr9vfla'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc488>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptrr9vfla'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e69108>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab8d0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e69108>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpeuzk9r2d'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc0d0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpeuzk9r2d'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc0d0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpeuzk9r2d'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc0d0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpeuzk9r2d'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c1954a348>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabcc0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c1954a348>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdv_552s7'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc378>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdv_552s7'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdv_552s7'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dbc378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdv_552s7'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c1954a0c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabc88>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c1954a0c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpsx65dih1'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2bf8>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpsx65dih1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2bf8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpsx65dih1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2bf8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpsx65dih1'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16dcc308>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab9e8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16dcc308>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8ueekphe'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2620>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8ueekphe'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2620>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8ueekphe'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2620>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8ueekphe'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c167ff888>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab748>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c167ff888>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd7p25udo'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2488>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd7p25udo'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2488>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd7p25udo'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2488>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd7p25udo'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16df6308>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab3c8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16df6308>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphkv63nys'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2a60>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphkv63nys'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2a60>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphkv63nys'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2a60>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphkv63nys'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16aa14c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabd30>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16aa14c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpigrnru27'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2378>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpigrnru27'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpigrnru27'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpigrnru27'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16ddff48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab550>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16ddff48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdvdstl24'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2048>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdvdstl24'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdvdstl24'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpdvdstl24'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e02748>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab320>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e02748>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5t53kl_u'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2730>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5t53kl_u'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2730>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5t53kl_u'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2730>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5t53kl_u'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16de2cc8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aaba58>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16de2cc8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnx1fi_mp'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2840>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnx1fi_mp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2840>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnx1fi_mp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2840>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnx1fi_mp'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16de1848>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabb38>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16de1848>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmprtz16ix6'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2158>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmprtz16ix6'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmprtz16ix6'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmprtz16ix6'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16d78108>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab588>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16d78108>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwxmnxqpq'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2268>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwxmnxqpq'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwxmnxqpq'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16dd2268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwxmnxqpq'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16ded448>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabcf8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16ded448>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5toi9ghl'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91620>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5toi9ghl'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91620>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5toi9ghl'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91620>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp5toi9ghl'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e14548>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab438>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e14548>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpbv1uewyf'\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91598>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpbv1uewyf'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91598>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpbv1uewyf'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91598>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpbv1uewyf'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16a94ec8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabe80>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16a94ec8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8il9u20v'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91d08>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8il9u20v'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91d08>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8il9u20v'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91d08>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp8il9u20v'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16a749c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab390>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16a749c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpcj_vtgb3'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91158>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpcj_vtgb3'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpcj_vtgb3'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a91158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpcj_vtgb3'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e12208>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabef0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e12208>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptt6lc5sh'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16aea158>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptt6lc5sh'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16aea158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptt6lc5sh'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16aea158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmptt6lc5sh'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e8be08>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab128>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e8be08>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpb52q473z'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16aea0d0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpb52q473z'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16aea0d0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpb52q473z'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16aea0d0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpb52q473z'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16da9bc8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabdd8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16da9bc8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpylqerqnk'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a82950>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpylqerqnk'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a82950>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpylqerqnk'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a82950>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpylqerqnk'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16acc748>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab630>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16acc748>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpixqw42d6'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a82378>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpixqw42d6'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a82378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpixqw42d6'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a82378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpixqw42d6'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16a8fe48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab2e8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16a8fe48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpr91p12d_'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a821e0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpr91p12d_'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a821e0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpr91p12d_'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a821e0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpr91p12d_'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16d57e88>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab240>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16d57e88>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpm7zmr3kp'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18048>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpm7zmr3kp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpm7zmr3kp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpm7zmr3kp'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16ab6688>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aaba20>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16ab6688>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3__k818w'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18e18>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3__k818w'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18e18>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3__k818w'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18e18>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3__k818w'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19564548>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab278>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19564548>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp6jfqh0tp'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18c80>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp6jfqh0tp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18c80>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp6jfqh0tp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a18c80>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp6jfqh0tp'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19564d08>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aabfd0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19564d08>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp4r9fxzws'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a188c8>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp4r9fxzws'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a188c8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp4r9fxzws'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16a188c8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp4r9fxzws'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19545d88>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab710>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19545d88>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpro1hhzr1'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3158>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpro1hhzr1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpro1hhzr1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3158>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpro1hhzr1'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19545148>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab6a0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19545148>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpni4w5j3z'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3b70>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpni4w5j3z'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3b70>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpni4w5j3z'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3b70>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpni4w5j3z'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16db1a48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab9b0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16db1a48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpthih_qur'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3400>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpthih_qur'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3400>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpthih_qur'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3400>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpthih_qur'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16db1788>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab7b8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16db1788>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpn5b_n115'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3378>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpn5b_n115'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpn5b_n115'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3378>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpn5b_n115'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e21208>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab5f8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e21208>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpyvwixkef'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3ae8>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpyvwixkef'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3ae8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpyvwixkef'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3ae8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpyvwixkef'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e21888>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16aab4e0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e21888>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp30c5q053'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3ea0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp30c5q053'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3ea0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp30c5q053'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3ea0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp30c5q053'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e21808>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1160>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e21808>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp59rrx5q1'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3c80>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp59rrx5q1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3c80>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp59rrx5q1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3c80>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp59rrx5q1'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e66f08>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1048>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e66f08>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpoirtfwll'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3488>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpoirtfwll'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3488>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpoirtfwll'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3488>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpoirtfwll'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e18648>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1d30>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e18648>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp9j2b2v1_'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3598>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp9j2b2v1_'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3598>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp9j2b2v1_'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3598>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp9j2b2v1_'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e68d08>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1a90>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e68d08>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpc3r2gjfv'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3a60>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpc3r2gjfv'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3a60>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpc3r2gjfv'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3a60>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpc3r2gjfv'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e68288>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1dd8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e68288>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphp_v8ptg'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db39d8>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphp_v8ptg'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db39d8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphp_v8ptg'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db39d8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmphp_v8ptg'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16dfccc8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1438>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16dfccc8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpshy8quxk'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3f28>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpshy8quxk'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3f28>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpshy8quxk'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3f28>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpshy8quxk'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16dfc6c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee10b8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16dfc6c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpt1dcv1y_'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3510>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpt1dcv1y_'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3510>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpt1dcv1y_'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3510>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpt1dcv1y_'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16dfcec8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1f28>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16dfcec8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3m0w6fqe'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db38c8>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3m0w6fqe'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db38c8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3m0w6fqe'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db38c8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3m0w6fqe'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16d678c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c0bee1be0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16d678c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd88kj4z2'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3048>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd88kj4z2'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd88kj4z2'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3048>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpd88kj4z2'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16d67bc8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33518>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16d67bc8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwkh_8uek'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3620>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwkh_8uek'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3620>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwkh_8uek'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3620>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpwkh_8uek'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56d88>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33c88>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16f56d88>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpybfw97h1'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3268>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpybfw97h1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpybfw97h1'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpybfw97h1'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e22c48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33e48>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e22c48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpxy2u2g98'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db30d0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpxy2u2g98'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db30d0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpxy2u2g98'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db30d0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpxy2u2g98'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e9edc8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33be0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e9edc8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpvzpljzpw'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db37b8>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpvzpljzpw'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db37b8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpvzpljzpw'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db37b8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpvzpljzpw'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e9ef48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d336a0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e9ef48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3xkw0fbb'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3d08>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3xkw0fbb'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3d08>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3xkw0fbb'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3d08>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp3xkw0fbb'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e9e248>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33748>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e9e248>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpswydcjhr'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3840>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpswydcjhr'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3840>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpswydcjhr'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3840>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpswydcjhr'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e9ea48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33668>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e9ea48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaz94jdre'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3d90>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaz94jdre'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3d90>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaz94jdre'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3d90>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaz94jdre'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e9e1c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33cc0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e9e1c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpap130rwm'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db32f0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpap130rwm'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db32f0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpap130rwm'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db32f0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpap130rwm'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16b89908>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33ba8>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16b89908>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpu5r5p2d4'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3e18>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpu5r5p2d4'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3e18>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpu5r5p2d4'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3e18>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpu5r5p2d4'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19569fc8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33d68>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19569fc8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaqun3nwo'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db31e0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaqun3nwo'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db31e0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaqun3nwo'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db31e0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpaqun3nwo'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c195691c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33860>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c195691c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnquuksjp'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3950>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnquuksjp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3950>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnquuksjp'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16db3950>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpnquuksjp'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19569288>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33780>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19569288>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d941e0>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d941e0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d941e0>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp1qetjroo'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19569888>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33da0>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19569888>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpab5oekuh'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d94268>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpab5oekuh'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d94268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpab5oekuh'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d94268>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpab5oekuh'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c19569b48>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33940>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c19569b48>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp77i9yqxm'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d948c8>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp77i9yqxm'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d948c8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp77i9yqxm'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d948c8>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmp77i9yqxm'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           yield path\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib.ExitStack object at 0x1c16af97b8>\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16f56688>)\r\n",
      "received_exc = True\r\n",
      "_fix_exception_context = <function ExitStack.__exit__.<locals>._fix_exception_context at 0x1c1cae3510>\r\n",
      "suppressed_exc = False\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, *exc_details):\u001b[0m\r\n",
      "\u001b[1m        received_exc = exc_details[0] is not None\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # We manipulate the exception state so it behaves as though\u001b[0m\r\n",
      "\u001b[1m        # we were actually nesting multiple with statements\u001b[0m\r\n",
      "\u001b[1m        frame_exc = sys.exc_info()[1]\u001b[0m\r\n",
      "\u001b[1m        def _fix_exception_context(new_exc, old_exc):\u001b[0m\r\n",
      "\u001b[1m            # Context may not be correct, so find the end of the chain\u001b[0m\r\n",
      "\u001b[1m            while 1:\u001b[0m\r\n",
      "\u001b[1m                exc_context = new_exc.__context__\u001b[0m\r\n",
      "\u001b[1m                if exc_context is old_exc:\u001b[0m\r\n",
      "\u001b[1m                    # Context is already set correctly (see issue 20317)\u001b[0m\r\n",
      "\u001b[1m                    return\u001b[0m\r\n",
      "\u001b[1m                if exc_context is None or exc_context is frame_exc:\u001b[0m\r\n",
      "\u001b[1m                    break\u001b[0m\r\n",
      "\u001b[1m                new_exc = exc_context\u001b[0m\r\n",
      "\u001b[1m            # Change the end of the chain to point to the exception\u001b[0m\r\n",
      "\u001b[1m            # we expect it to reference\u001b[0m\r\n",
      "\u001b[1m            new_exc.__context__ = old_exc\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # Callbacks are invoked in LIFO order to match the behaviour of\u001b[0m\r\n",
      "\u001b[1m        # nested context managers\u001b[0m\r\n",
      "\u001b[1m        suppressed_exc = False\u001b[0m\r\n",
      "\u001b[1m        pending_raise = False\u001b[0m\r\n",
      "\u001b[1m        while self._exit_callbacks:\u001b[0m\r\n",
      "\u001b[1m            cb = self._exit_callbacks.pop()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               if cb(*exc_details):\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "exc_details = (<class 'OSError'>, OSError(24, 'Too many open files'), <traceback object at 0x1c16e094c8>)\r\n",
      "\r\n",
      "\u001b[1m    def _exit_wrapper(*exc_details):\u001b[0m\r\n",
      "\u001b[1m>       return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "self = <contextlib._GeneratorContextManager object at 0x1c16d33828>\r\n",
      "type = <class 'OSError'>, value = OSError(24, 'Too many open files')\r\n",
      "traceback = <traceback object at 0x1c16e094c8>\r\n",
      "\r\n",
      "\u001b[1m    def __exit__(self, type, value, traceback):\u001b[0m\r\n",
      "\u001b[1m        if type is None:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                next(self.gen)\u001b[0m\r\n",
      "\u001b[1m            except StopIteration:\u001b[0m\r\n",
      "\u001b[1m                return False\u001b[0m\r\n",
      "\u001b[1m            else:\u001b[0m\r\n",
      "\u001b[1m                raise RuntimeError(\"generator didn't stop\")\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m            if value is None:\u001b[0m\r\n",
      "\u001b[1m                # Need to force instantiation so we can reliably\u001b[0m\r\n",
      "\u001b[1m                # tell if we get the same exception back\u001b[0m\r\n",
      "\u001b[1m                value = type()\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "suffix = '.nc', allow_cleanup_failure = False\r\n",
      "\r\n",
      "\u001b[1m    @contextlib.contextmanager\u001b[0m\r\n",
      "\u001b[1m    def create_tmp_file(suffix='.nc', allow_cleanup_failure=False):\u001b[0m\r\n",
      "\u001b[1m        temp_dir = tempfile.mkdtemp()\u001b[0m\r\n",
      "\u001b[1m        path = os.path.join(temp_dir, 'temp-%s%s' % (next(_counter), suffix))\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            yield path\u001b[0m\r\n",
      "\u001b[1m        finally:\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m>               shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpzqfmiu9q'\r\n",
      "ignore_errors = False\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d94950>\r\n",
      "\r\n",
      "\u001b[1m    def rmtree(path, ignore_errors=False, onerror=None):\u001b[0m\r\n",
      "\u001b[1m        \"\"\"Recursively delete a directory tree.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        If ignore_errors is set, errors are ignored; otherwise, if onerror\u001b[0m\r\n",
      "\u001b[1m        is set, it is called to handle the error with arguments (func,\u001b[0m\r\n",
      "\u001b[1m        path, exc_info) where func is platform and implementation dependent;\u001b[0m\r\n",
      "\u001b[1m        path is the argument to that function that caused it to fail; and\u001b[0m\r\n",
      "\u001b[1m        exc_info is a tuple returned by sys.exc_info().  If ignore_errors\u001b[0m\r\n",
      "\u001b[1m        is false and onerror is None, an exception is raised.\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        \"\"\"\u001b[0m\r\n",
      "\u001b[1m        if ignore_errors:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                pass\u001b[0m\r\n",
      "\u001b[1m        elif onerror is None:\u001b[0m\r\n",
      "\u001b[1m            def onerror(*args):\u001b[0m\r\n",
      "\u001b[1m                raise\u001b[0m\r\n",
      "\u001b[1m        if _use_fd_functions:\u001b[0m\r\n",
      "\u001b[1m            # While the unsafe rmtree works fine on bytes, the fd based does not.\u001b[0m\r\n",
      "\u001b[1m            if isinstance(path, bytes):\u001b[0m\r\n",
      "\u001b[1m                path = os.fsdecode(path)\u001b[0m\r\n",
      "\u001b[1m            # Note: To guard against symlink races, we use the standard\u001b[0m\r\n",
      "\u001b[1m            # lstat()/open()/fstat() trick.\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                orig_st = os.lstat(path)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                fd = os.open(path, os.O_RDONLY)\u001b[0m\r\n",
      "\u001b[1m            except Exception:\u001b[0m\r\n",
      "\u001b[1m                onerror(os.lstat, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                return\u001b[0m\r\n",
      "\u001b[1m            try:\u001b[0m\r\n",
      "\u001b[1m                if os.path.samestat(orig_st, os.fstat(fd)):\u001b[0m\r\n",
      "\u001b[1m                    _rmtree_safe_fd(fd, path, onerror)\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        os.rmdir(path)\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.rmdir, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m                else:\u001b[0m\r\n",
      "\u001b[1m                    try:\u001b[0m\r\n",
      "\u001b[1m                        # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                        raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m                    except OSError:\u001b[0m\r\n",
      "\u001b[1m                        onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            finally:\u001b[0m\r\n",
      "\u001b[1m                os.close(fd)\u001b[0m\r\n",
      "\u001b[1m        else:\u001b[0m\r\n",
      "\u001b[1m>           return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpzqfmiu9q'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d94950>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m>           onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpzqfmiu9q'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d94950>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpzqfmiu9q'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\r\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "readengine = 'netcdf4', nfiles = 100, autoclose = False, parallel = False\r\n",
      "chunks = None\r\n",
      "\r\n",
      "\u001b[1m    def test_open_mfdataset_manyfiles(readengine, nfiles, autoclose, parallel,\u001b[0m\r\n",
      "\u001b[1m                                      chunks):\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        # skip certain combinations\u001b[0m\r\n",
      "\u001b[1m        skip_if_not_engine(readengine)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if not has_dask and parallel:\u001b[0m\r\n",
      "\u001b[1m            pytest.skip('parallel requires dask')\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if readengine == 'h5netcdf' and autoclose:\u001b[0m\r\n",
      "\u001b[1m            pytest.skip('h5netcdf does not support autoclose yet')\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        if ON_WINDOWS:\u001b[0m\r\n",
      "\u001b[1m            pytest.skip('Skipping on Windows')\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m        randdata = np.random.randn(nfiles)\u001b[0m\r\n",
      "\u001b[1m        original = Dataset({'foo': ('x', randdata)})\u001b[0m\r\n",
      "\u001b[1m        # test standard open_mfdataset approach with too many files\u001b[0m\r\n",
      "\u001b[1m        with create_tmp_files(nfiles) as tmpfiles:\u001b[0m\r\n",
      "\u001b[1m            writeengine = (readengine if readengine != 'pynio' else 'netcdf4')\u001b[0m\r\n",
      "\u001b[1m            # split into multiple sets of temp files\u001b[0m\r\n",
      "\u001b[1m            for ii in original.x.values:\u001b[0m\r\n",
      "\u001b[1m                subds = original.isel(x=slice(ii, ii + 1))\u001b[0m\r\n",
      "\u001b[1m                subds.to_netcdf(tmpfiles[ii], engine=writeengine)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            # check that calculation on opened datasets works properly\u001b[0m\r\n",
      "\u001b[1m            actual = open_mfdataset(tmpfiles, engine=readengine, parallel=parallel,\u001b[0m\r\n",
      "\u001b[1m                                    autoclose=autoclose, chunks=chunks)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m            # check that using open_mfdataset returns dask arrays for variables\u001b[0m\r\n",
      "\u001b[1m            assert isinstance(actual['foo'].data, dask_array_type)\u001b[0m\r\n",
      "\u001b[1m    \u001b[0m\r\n",
      "\u001b[1m>           assert_identical(original, actual)\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:1984: \r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: in __exit__\r\n",
      "\u001b[1m    self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:900: in create_tmp_files\r\n",
      "\u001b[1m    yield files\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:380: in __exit__\r\n",
      "\u001b[1m    raise exc_details[1]\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: in __exit__\r\n",
      "\u001b[1m    self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:885: in create_tmp_file\r\n",
      "\u001b[1m    yield path\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:365: in __exit__\r\n",
      "\u001b[1m    if cb(*exc_details):\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:284: in _exit_wrapper\r\n",
      "\u001b[1m    return cm_exit(cm, *exc_details)\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/contextlib.py\u001b[0m:99: in __exit__\r\n",
      "\u001b[1m    self.gen.throw(type, value, traceback)\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/site-packages/xarray/tests/test_backends.py\u001b[0m:888: in create_tmp_file\r\n",
      "\u001b[1m    shutil.rmtree(temp_dir)\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:494: in rmtree\r\n",
      "\u001b[1m    return _rmtree_unsafe(path, onerror)\u001b[0m\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:376: in _rmtree_unsafe\r\n",
      "\u001b[1m    onerror(os.listdir, path, sys.exc_info())\u001b[0m\r\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n",
      "\r\n",
      "path = '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpk_brdh2c'\r\n",
      "onerror = <function rmtree.<locals>.onerror at 0x1c16d94400>\r\n",
      "\r\n",
      "\u001b[1m    def _rmtree_unsafe(path, onerror):\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m            if os.path.islink(path):\u001b[0m\r\n",
      "\u001b[1m                # symlinks to directories are forbidden, see bug #1669\u001b[0m\r\n",
      "\u001b[1m                raise OSError(\"Cannot call rmtree on a symbolic link\")\u001b[0m\r\n",
      "\u001b[1m        except OSError:\u001b[0m\r\n",
      "\u001b[1m            onerror(os.path.islink, path, sys.exc_info())\u001b[0m\r\n",
      "\u001b[1m            # can't continue even if onerror hook returns\u001b[0m\r\n",
      "\u001b[1m            return\u001b[0m\r\n",
      "\u001b[1m        names = []\u001b[0m\r\n",
      "\u001b[1m        try:\u001b[0m\r\n",
      "\u001b[1m>           names = os.listdir(path)\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE           OSError: [Errno 24] Too many open files: '/var/folders/wd/6mcc6nzd4qx7cd_y1brbrsqc0000gn/T/tmpk_brdh2c'\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31m../../anaconda3/lib/python3.6/shutil.py\u001b[0m:374: OSError\r\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/scipy/io/netcdf.py:317: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\r\n",
      "  ), category=RuntimeWarning)\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/coding/cftimeindex.py:160: FutureWarning: CFTimeIndex.data is deprecated and will be removed in a future version\r\n",
      "  if self.data:\r\n",
      "\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/tests/test_ufuncs.py:179: PendingDeprecationWarning: xarray.ufuncs will be deprecated when xarray no longer supports versions of numpy older than v1.13. Instead, use numpy ufuncs directly.\r\n",
      "  assert_identical(cos_pickled(a), xu.cos(a))\r\n",
      "/Users/saviosebastian/anaconda3/lib/python3.6/site-packages/xarray/tests/test_ufuncs.py:179: PendingDeprecationWarning: xarray.ufuncs will be deprecated when xarray no longer supports versions of numpy older than v1.13. Instead, use numpy ufuncs directly.\r\n",
      "  assert_identical(cos_pickled(a), xu.cos(a))\r\n",
      "\r\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\r\n",
      "\u001b[31m\u001b[1m 1 failed, 6258 passed, 586 skipped, 10 xfailed, 4 xpassed, 262 warnings in 102.68 seconds \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!py.test --pyargs xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = {'IA','IL','IN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range('2000-01-01',periods=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = xr.DataArray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (dim_0: 4, dim_1: 3)>\n",
       "array([[0.044718, 0.88526 , 0.037472],\n",
       "       [0.675666, 0.76201 , 0.280924],\n",
       "       [0.915302, 0.959431, 0.235292],\n",
       "       [0.638675, 0.634544, 0.397106]])\n",
       "Dimensions without coordinates: dim_0, dim_1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0447175 , 0.88526036, 0.03747247],\n",
       "       [0.67566618, 0.76201022, 0.28092354],\n",
       "       [0.91530234, 0.95943051, 0.23529179],\n",
       "       [0.63867499, 0.63454428, 0.39710628]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dim_0', 'dim_1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "    *empty*"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.name='foo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = xr.DataArray('MYD03.A2002185.0000.061.2017362174430.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray ()>\n",
       "array('MYD03.A2002185.0000.061.2017362174430.hdf', dtype='<U41')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('MYD03.A2002185.0000.061.2017362174430.hdf', dtype='<U41')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDimensionsError",
     "evalue": "'Scan Type' has more than 1-dimension and the same name as one of its dimensions ('nscans', 'Scan Type'). xarray disallows such variables because they conflict with the coordinates used to label dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDimensionsError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-44a62cca9f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MYD03.A2002185.0000.061.2017362174430.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_decode_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mmaybe_decode_store\u001b[0;34m(store, lock)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mconcat_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_coords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             drop_variables=drop_variables)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0m_protect_dataset_variables_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/conventions.py\u001b[0m in \u001b[0;36mdecode_cf\u001b[0;34m(obj, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         decode_coords, drop_variables=drop_variables)\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_vars, coords, attrs, compat)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_init_vars_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_set_init_vars_and_dims\u001b[0;34m(self, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         variables, coord_names, dims = merge_data_and_coords(\n\u001b[0;32m--> 383\u001b[0;31m             data_vars, coords, compat=compat)\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data, coords, compat, join)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return merge_core(objs, compat, join, explicit_coords=explicit_coords,\n\u001b[0;32m--> 370\u001b[0;31m                       indexes=indexes)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_variable_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mcoord_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoncoord_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mexpand_variable_dicts\u001b[0;34m(list_of_variable_dicts)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mvar_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0msanitized_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mas_variable\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;34m'dimensions %r. xarray disallows such variables because they '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;34m'conflict with the coordinates used to label '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 'dimensions.' % (name, obj.dims))\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_index_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingDimensionsError\u001b[0m: 'Scan Type' has more than 1-dimension and the same name as one of its dimensions ('nscans', 'Scan Type'). xarray disallows such variables because they conflict with the coordinates used to label dimensions."
     ]
    }
   ],
   "source": [
    "fio = xr.open_dataset('MYD03.A2002185.0000.061.2017362174430.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8a5fa38bd53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MYD03.A2002185.0000.061.2017362174430.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_vars, coords, attrs, compat)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_init_vars_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_set_init_vars_and_dims\u001b[0;34m(self, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         variables, coord_names, dims = merge_data_and_coords(\n\u001b[0;32m--> 383\u001b[0;31m             data_vars, coords, compat=compat)\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data, coords, compat, join)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return merge_core(objs, compat, join, explicit_coords=explicit_coords,\n\u001b[0;32m--> 370\u001b[0;31m                       indexes=indexes)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0m_assert_compat_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_variable_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mcoerce_pandas_values\u001b[0;34m(objects)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "gem=xr.Dataset('MYD03.A2002185.0000.061.2017362174430.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = xr.save_mfdataset('/Users/saviosebastian/Desktop/XArraysTest/MYD03.A2002185.0000.061.2017362174430.hdf',paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['%s.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import sys\n",
    "\n",
    "num_args = len(sys.argv)\n",
    "if (num_args < 3) : \n",
    "\tprint (\"Insufficient arguments\")\n",
    "\texit()\n",
    "\n",
    "mod03_name = 'MYD03.A2002185.0000.061.2017362174430.hdf'\n",
    "mod06_name = 'MYD06_L2.A2002185.0000.061.2018003215042.hdf'\n",
    "\n",
    "print(mod03_name)\n",
    "print(mod06_name)\n",
    "\n",
    "rootgrp = Dataset(mod03_name, \"r\", format=\"NETCDF3\")\n",
    "latitude = rootgrp.variables[\"Latitude\"][:,:] \n",
    "longitude = rootgrp.variables[\"Longitude\"][:,:]\n",
    "print(\"------------------------------------\")\n",
    "print (longitude)\n",
    "print(\"------------------------------------\")\n",
    "print (longitude.size)\n",
    "print(\"------------------------------------\")\n",
    "data_ht = latitude.shape[0]\n",
    "data_wid = longitude.shape[1]\n",
    "print (data_wid)\n",
    "print (data_ht)\n",
    "\n",
    "print (rootgrp.variables.keys())\n",
    "\n",
    "#for name, variable in rootgrp.variables.items():\n",
    "#\tprint(\"=== VARNAME: \", name, \" =======\")\n",
    "#\tfor attrname in variable.ncattrs():\n",
    "#\t\tprint(\"{} -- {}\".format(attrname, getattr(variable, attrname)))\n",
    "\n",
    "\n",
    "rootgrp.close()\n",
    "\n",
    "rootgrp = Dataset(mod06_name, \"r\", format=\"NETCDF3\")\n",
    "cloud_mask_allbytes = rootgrp.variables[\"Cloud_Mask_1km\"][:,:,:] \n",
    "print(cloud_mask_allbytes.shape)\n",
    "print(\"------------------------------------\")\n",
    "print (rootgrp.variables.keys())\n",
    "rootgrp.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine for open_dataset: 'netCDF4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6a47f61caf0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MYD03.A2002185.0000.061.2017362174430.hdf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'netCDF4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             raise ValueError('unrecognized engine for open_dataset: %r'\n\u001b[0;32m--> 341\u001b[0;31m                              % engine)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized engine for open_dataset: 'netCDF4'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "ds = xr.open_dataset('MYD03.A2002185.0000.061.2017362174430.hdf',engine='netCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDimensionsError",
     "evalue": "'Scan Type' has more than 1-dimension and the same name as one of its dimensions ('nscans', 'Scan Type'). xarray disallows such variables because they conflict with the coordinates used to label dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDimensionsError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ddf0e69faf3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_disk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MYD03.A2002185.0000.061.2017362174430.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_decode_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mmaybe_decode_store\u001b[0;34m(store, lock)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mconcat_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_coords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             drop_variables=drop_variables)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0m_protect_dataset_variables_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/conventions.py\u001b[0m in \u001b[0;36mdecode_cf\u001b[0;34m(obj, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         decode_coords, drop_variables=drop_variables)\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_vars, coords, attrs, compat)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_init_vars_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_set_init_vars_and_dims\u001b[0;34m(self, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         variables, coord_names, dims = merge_data_and_coords(\n\u001b[0;32m--> 383\u001b[0;31m             data_vars, coords, compat=compat)\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data, coords, compat, join)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return merge_core(objs, compat, join, explicit_coords=explicit_coords,\n\u001b[0;32m--> 370\u001b[0;31m                       indexes=indexes)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_variable_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mcoord_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoncoord_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mexpand_variable_dicts\u001b[0;34m(list_of_variable_dicts)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mvar_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0msanitized_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mas_variable\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;34m'dimensions %r. xarray disallows such variables because they '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;34m'conflict with the coordinates used to label '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 'dimensions.' % (name, obj.dims))\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_index_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingDimensionsError\u001b[0m: 'Scan Type' has more than 1-dimension and the same name as one of its dimensions ('nscans', 'Scan Type'). xarray disallows such variables because they conflict with the coordinates used to label dimensions."
     ]
    }
   ],
   "source": [
    "ds_disk = xr.open_dataset('MYD03.A2002185.0000.061.2017362174430.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MYD03.A2002185.0000.061.2017362174430.hdf\r\n",
      "MYD06_L2.A2002185.0000.061.2018003215042.hdf\r\n",
      "SamVersionOfSavioCode.ipynb\r\n",
      "SamVersionOfSavioCode1.ipynb\r\n",
      "XArray-Test.ipynb\r\n",
      "amsre_l2a_hdf4_eos_to_netcdf_converter.ipynb\r\n",
      "h4tonccf_nc4.exe\r\n",
      "sresa1b_ncar_ccsm3-example.nc\r\n",
      "test_echam_spectral.nc\r\n",
      "test_hgroups.nc\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_disk = xr.open_dataset('sresa1b_ncar_ccsm3-example.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (bnds: 2, lat: 128, lon: 256, plev: 17, time: 1)\n",
       "Coordinates:\n",
       "  * lat        (lat) float32 -88.927734 -87.538704 ... 87.538704 88.927734\n",
       "  * lon        (lon) float32 0.0 1.40625 2.8125 ... 355.78125 357.1875 358.59375\n",
       "  * plev       (plev) float64 1e+05 9.25e+04 8.5e+04 7e+04 ... 3e+03 2e+03 1e+03\n",
       "  * time       (time) datetime64[ns] 2000-05-16T12:00:00\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    area       (lat, lon) float32 ...\n",
       "    lat_bnds   (lat, bnds) float64 ...\n",
       "    lon_bnds   (lon, bnds) float64 ...\n",
       "    msk_rgn    (lat, lon) int32 ...\n",
       "    pr         (time, lat, lon) float32 ...\n",
       "    tas        (time, lat, lon) float32 ...\n",
       "    time_bnds  (time, bnds) float64 ...\n",
       "    ua         (time, plev, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    CVS_Id:              $Id$\n",
       "    creation_date:       \n",
       "    prg_ID:              Source file unknown Version unknown Date unknown\n",
       "    cmd_ln:              bds -x 256 -y 128 -m 23 -o /data/zender/data/dst_T85.nc\n",
       "    history:             Tue Oct 25 15:08:51 2005: ncks -O -x -v va -m sresa1...\n",
       "    table_id:            Table A1\n",
       "    title:               model output prepared for IPCC AR4\n",
       "    institution:         NCAR (National Center for Atmospheric \\nResearch, Bo...\n",
       "    source:              CCSM3.0, version beta19 (2004): \\natmosphere: CAM3.0...\n",
       "    contact:             ccsm@ucar.edu\n",
       "    project_id:          IPCC Fourth Assessment\n",
       "    Conventions:         CF-1.0\n",
       "    references:          Collins, W.D., et al., 2005:\\n The Community Climate...\n",
       "    acknowledgment:       Any use of CCSM data should acknowledge the contrib...\n",
       "    realization:         1\n",
       "    experiment_id:       720 ppm stabilization experiment (SRESA1B)\n",
       "    comment:             This simulation was initiated from year 2000 of \\n C...\n",
       "    model_name_english:  NCAR CCSM"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2c6e18dae348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MYD03.A2002185.0000.061.2017362174430.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "ds.to_netcdf('MYD03.A2002185.0000.061.2017362174430.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDimensionsError",
     "evalue": "'Scan Type' has more than 1-dimension and the same name as one of its dimensions ('nscans', 'Scan Type'). xarray disallows such variables because they conflict with the coordinates used to label dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDimensionsError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ec574047ceba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MYD03.A2002185.0000.061.2017362174430.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_decode_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mmaybe_decode_store\u001b[0;34m(store, lock)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mconcat_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_coords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             drop_variables=drop_variables)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0m_protect_dataset_variables_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/conventions.py\u001b[0m in \u001b[0;36mdecode_cf\u001b[0;34m(obj, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         decode_coords, drop_variables=drop_variables)\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_vars, coords, attrs, compat)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_init_vars_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_set_init_vars_and_dims\u001b[0;34m(self, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         variables, coord_names, dims = merge_data_and_coords(\n\u001b[0;32m--> 383\u001b[0;31m             data_vars, coords, compat=compat)\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data, coords, compat, join)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return merge_core(objs, compat, join, explicit_coords=explicit_coords,\n\u001b[0;32m--> 370\u001b[0;31m                       indexes=indexes)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_variable_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mcoord_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoncoord_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mexpand_variable_dicts\u001b[0;34m(list_of_variable_dicts)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mvar_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0msanitized_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mas_variable\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;34m'dimensions %r. xarray disallows such variables because they '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;34m'conflict with the coordinates used to label '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 'dimensions.' % (name, obj.dims))\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_index_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingDimensionsError\u001b[0m: 'Scan Type' has more than 1-dimension and the same name as one of its dimensions ('nscans', 'Scan Type'). xarray disallows such variables because they conflict with the coordinates used to label dimensions."
     ]
    }
   ],
   "source": [
    "foo = xr.open_dataset('MYD03.A2002185.0000.061.2017362174430.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000164"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.nbytes / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_dataset in module xarray.tutorial:\n",
      "\n",
      "load_dataset(name, cache=True, cache_dir='~/.xarray_tutorial_data', github_url='https://github.com/pydata/xarray-data', branch='master', **kws)\n",
      "    Load a dataset from the online repository (requires internet).\n",
      "    \n",
      "    If a local copy is found then always use that to avoid network traffic.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    name : str\n",
      "        Name of the netcdf file containing the dataset\n",
      "        ie. 'air_temperature'\n",
      "    cache_dir : string, optional\n",
      "        The directory in which to search for and write cached data.\n",
      "    cache : boolean, optional\n",
      "        If True, then cache data locally for use on subsequent calls\n",
      "    github_url : string\n",
      "        Github repository where the data is stored\n",
      "    branch : string\n",
      "        The git branch to download from\n",
      "    kws : dict, optional\n",
      "        Passed to xarray.open_dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xr.tutorial.load_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c6cae244df9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MYD03.A2002185.0000.061.2017362174430.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/tutorial.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(name, cache, cache_dir, github_url, branch, **kws)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocalfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "fim = xr.tutorial.load_dataset('MYD03.A2002185.0000.061.2017362174430.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import os,datetime,sys,fnmatch\n",
    "from jdcal import gcal2jd\n",
    "#from plot_global_map import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOD03_path = '/Users/saviosebastian/Desktop/XArraysTest/'\n",
    "MOD06_path = '/Users/saviosebastian/Desktop/XArraysTest/'\n",
    "satellite = 'Aqua'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOD03_fp = 'MYD03.A*.hdf'\n",
    "MOD06_fp = 'MYD06_L2.A*.hdf'\n",
    "MOD03_fn, MOD06_fn =[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading level 2 geolocation and cloud data\n",
      "MYD06_L2.A2002185.0000.061.2018003215042.hdf\n",
      "/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf\n",
      "/Users/saviosebastian/Desktop/XArraysTest/MYD03.A2002185.0000.061.2017362174430.hdf\n",
      "reading the cloud mask from MOD06_L2 product\n",
      "-----------------------------------------------\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF4):\n",
      "    HDFEOSVersion: HDFEOS_V2.19\n",
      "    StructMetadata.0: GROUP=SwathStructure\n",
      "\tGROUP=SWATH_1\n",
      "\t\tSwathName=\"mod06\"\n",
      "\t\tGROUP=Dimension\n",
      "\t\t\tOBJECT=Dimension_1\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_5km\"\n",
      "\t\t\t\tSize=270\n",
      "\t\t\tEND_OBJECT=Dimension_1\n",
      "\t\t\tOBJECT=Dimension_2\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_5km\"\n",
      "\t\t\t\tSize=408\n",
      "\t\t\tEND_OBJECT=Dimension_2\n",
      "\t\t\tOBJECT=Dimension_3\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_1km\"\n",
      "\t\t\t\tSize=1354\n",
      "\t\t\tEND_OBJECT=Dimension_3\n",
      "\t\t\tOBJECT=Dimension_4\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_1km\"\n",
      "\t\t\t\tSize=2040\n",
      "\t\t\tEND_OBJECT=Dimension_4\n",
      "\t\t\tOBJECT=Dimension_5\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_hkm\"\n",
      "\t\t\t\tSize=2708\n",
      "\t\t\tEND_OBJECT=Dimension_5\n",
      "\t\t\tOBJECT=Dimension_6\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_hkm\"\n",
      "\t\t\t\tSize=4060\n",
      "\t\t\tEND_OBJECT=Dimension_6\n",
      "\t\t\tOBJECT=Dimension_7\n",
      "\t\t\t\tDimensionName=\"Band_Number\"\n",
      "\t\t\t\tSize=7\n",
      "\t\t\tEND_OBJECT=Dimension_7\n",
      "\t\t\tOBJECT=Dimension_8\n",
      "\t\t\t\tDimensionName=\"Band_Ratio\"\n",
      "\t\t\t\tSize=5\n",
      "\t\t\tEND_OBJECT=Dimension_8\n",
      "\t\t\tOBJECT=Dimension_9\n",
      "\t\t\t\tDimensionName=\"Band_Forcing\"\n",
      "\t\t\t\tSize=5\n",
      "\t\t\tEND_OBJECT=Dimension_9\n",
      "\t\t\tOBJECT=Dimension_10\n",
      "\t\t\t\tDimensionName=\"Band_Difference\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_10\n",
      "\t\t\tOBJECT=Dimension_11\n",
      "\t\t\t\tDimensionName=\"QA_Parameter_5km\"\n",
      "\t\t\t\tSize=10\n",
      "\t\t\tEND_OBJECT=Dimension_11\n",
      "\t\t\tOBJECT=Dimension_12\n",
      "\t\t\t\tDimensionName=\"QA_Parameter_1km\"\n",
      "\t\t\t\tSize=9\n",
      "\t\t\tEND_OBJECT=Dimension_12\n",
      "\t\t\tOBJECT=Dimension_13\n",
      "\t\t\t\tDimensionName=\"Cloud_Mask_1km_Num_Bytes\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_13\n",
      "\t\t\tOBJECT=Dimension_14\n",
      "\t\t\t\tDimensionName=\"Cloud_Mask_5km_Num_Bytes\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_14\n",
      "\t\t\tOBJECT=Dimension_15\n",
      "\t\t\t\tDimensionName=\"RadTran_NWL\"\n",
      "\t\t\t\tSize=7\n",
      "\t\t\tEND_OBJECT=Dimension_15\n",
      "\t\t\tOBJECT=Dimension_16\n",
      "\t\t\t\tDimensionName=\"RadTran_NRE_Ice\"\n",
      "\t\t\t\tSize=12\n",
      "\t\t\tEND_OBJECT=Dimension_16\n",
      "\t\t\tOBJECT=Dimension_17\n",
      "\t\t\t\tDimensionName=\"RadTran_NRE_Liq\"\n",
      "\t\t\t\tSize=18\n",
      "\t\t\tEND_OBJECT=Dimension_17\n",
      "\t\t\tOBJECT=Dimension_18\n",
      "\t\t\t\tDimensionName=\"SPI_nband\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_18\n",
      "\t\t\tOBJECT=Dimension_19\n",
      "\t\t\t\tDimensionName=\"RFM_nband\"\n",
      "\t\t\t\tSize=3\n",
      "\t\t\tEND_OBJECT=Dimension_19\n",
      "\t\t\tOBJECT=Dimension_20\n",
      "\t\t\t\tDimensionName=\"ACR_nband\"\n",
      "\t\t\t\tSize=6\n",
      "\t\t\tEND_OBJECT=Dimension_20\n",
      "\t\t\tOBJECT=Dimension_21\n",
      "\t\t\t\tDimensionName=\"Statistic_Parameter_1km\"\n",
      "\t\t\t\tSize=17\n",
      "\t\t\tEND_OBJECT=Dimension_21\n",
      "\t\tEND_GROUP=Dimension\n",
      "\t\tGROUP=DimensionMap\n",
      "\t\t\tOBJECT=DimensionMap_1\n",
      "\t\t\t\tGeoDimension=\"Cell_Across_Swath_5km\"\n",
      "\t\t\t\tDataDimension=\"Cell_Across_Swath_1km\"\n",
      "\t\t\t\tOffset=2\n",
      "\t\t\t\tIncrement=5\n",
      "\t\t\tEND_OBJECT=DimensionMap_1\n",
      "\t\t\tOBJECT=DimensionMap_2\n",
      "\t\t\t\tGeoDimension=\"Cell_Along_Swath_5km\"\n",
      "\t\t\t\tDataDimension=\"Cell_Along_Swath_1km\"\n",
      "\t\t\t\tOffset=2\n",
      "\t\t\t\tIncrement=5\n",
      "\t\t\tEND_OBJECT=DimensionMap_2\n",
      "\t\tEND_GROUP=DimensionMap\n",
      "\t\tGROUP=IndexDimensionMap\n",
      "\t\tEND_GROUP=IndexDimensionMap\n",
      "\t\tGROUP=GeoField\n",
      "\t\t\tOBJECT=GeoField_1\n",
      "\t\t\t\tGeoFieldName=\"Latitude\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=GeoField_1\n",
      "\t\t\tOBJECT=GeoField_2\n",
      "\t\t\t\tGeoFieldName=\"Longitude\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=GeoField_2\n",
      "\t\tEND_GROUP=GeoField\n",
      "\t\tGROUP=DataField\n",
      "\t\t\tOBJECT=DataField_1\n",
      "\t\t\t\tDataFieldName=\"Band_Number\"\n",
      "\t\t\t\tDataType=DFNT_INT32\n",
      "\t\t\t\tDimList=(\"Band_Number\")\n",
      "\t\t\tEND_OBJECT=DataField_1\n",
      "\t\t\tOBJECT=DataField_2\n",
      "\t\t\t\tDataFieldName=\"Statistics_1km\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Statistic_Parameter_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_2\n",
      "\t\t\tOBJECT=DataField_3\n",
      "\t\t\t\tDataFieldName=\"Scan_Start_Time\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT64\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_3\n",
      "\t\t\tOBJECT=DataField_4\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_4\n",
      "\t\t\tOBJECT=DataField_5\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_5\n",
      "\t\t\tOBJECT=DataField_6\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_6\n",
      "\t\t\tOBJECT=DataField_7\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_7\n",
      "\t\t\tOBJECT=DataField_8\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_8\n",
      "\t\t\tOBJECT=DataField_9\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_9\n",
      "\t\t\tOBJECT=DataField_10\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_10\n",
      "\t\t\tOBJECT=DataField_11\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_11\n",
      "\t\t\tOBJECT=DataField_12\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_12\n",
      "\t\t\tOBJECT=DataField_13\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_13\n",
      "\t\t\tOBJECT=DataField_14\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_14\n",
      "\t\t\tOBJECT=DataField_15\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_15\n",
      "\t\t\tOBJECT=DataField_16\n",
      "\t\t\t\tDataFieldName=\"Brightness_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Number\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_16\n",
      "\t\t\tOBJECT=DataField_17\n",
      "\t\t\t\tDataFieldName=\"Surface_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_17\n",
      "\t\t\tOBJECT=DataField_18\n",
      "\t\t\t\tDataFieldName=\"Surface_Pressure\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_18\n",
      "\t\t\tOBJECT=DataField_19\n",
      "\t\t\t\tDataFieldName=\"Cloud_Height_Method\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_19\n",
      "\t\t\tOBJECT=DataField_20\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_20\n",
      "\t\t\tOBJECT=DataField_21\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_21\n",
      "\t\t\tOBJECT=DataField_22\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_22\n",
      "\t\t\tOBJECT=DataField_23\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_23\n",
      "\t\t\tOBJECT=DataField_24\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_24\n",
      "\t\t\tOBJECT=DataField_25\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_25\n",
      "\t\t\tOBJECT=DataField_26\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_26\n",
      "\t\t\tOBJECT=DataField_27\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_27\n",
      "\t\t\tOBJECT=DataField_28\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_28\n",
      "\t\t\tOBJECT=DataField_29\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_29\n",
      "\t\t\tOBJECT=DataField_30\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_30\n",
      "\t\t\tOBJECT=DataField_31\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_31\n",
      "\t\t\tOBJECT=DataField_32\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_32\n",
      "\t\t\tOBJECT=DataField_33\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_33\n",
      "\t\t\tOBJECT=DataField_34\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_34\n",
      "\t\t\tOBJECT=DataField_35\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_35\n",
      "\t\t\tOBJECT=DataField_36\n",
      "\t\t\t\tDataFieldName=\"Tropopause_Height\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_36\n",
      "\t\t\tOBJECT=DataField_37\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_37\n",
      "\t\t\tOBJECT=DataField_38\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_38\n",
      "\t\t\tOBJECT=DataField_39\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_39\n",
      "\t\t\tOBJECT=DataField_40\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_40\n",
      "\t\t\tOBJECT=DataField_41\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_41\n",
      "\t\t\tOBJECT=DataField_42\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_42\n",
      "\t\t\tOBJECT=DataField_43\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_43\n",
      "\t\t\tOBJECT=DataField_44\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_44\n",
      "\t\t\tOBJECT=DataField_45\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_45\n",
      "\t\t\tOBJECT=DataField_46\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_46\n",
      "\t\t\tOBJECT=DataField_47\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_47\n",
      "\t\t\tOBJECT=DataField_48\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_48\n",
      "\t\t\tOBJECT=DataField_49\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Infrared\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_49\n",
      "\t\t\tOBJECT=DataField_50\n",
      "\t\t\t\tDataFieldName=\"Spectral_Cloud_Forcing\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Forcing\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_50\n",
      "\t\t\tOBJECT=DataField_51\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_From_Ratios\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Ratio\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_51\n",
      "\t\t\tOBJECT=DataField_52\n",
      "\t\t\t\tDataFieldName=\"Radiance_Variance\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_52\n",
      "\t\t\tOBJECT=DataField_53\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_53\n",
      "\t\t\tOBJECT=DataField_54\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_54\n",
      "\t\t\tOBJECT=DataField_55\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_55\n",
      "\t\t\tOBJECT=DataField_56\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_56\n",
      "\t\t\tOBJECT=DataField_57\n",
      "\t\t\t\tDataFieldName=\"IRP_CTH_Consistency_Flag_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_57\n",
      "\t\t\tOBJECT=DataField_58\n",
      "\t\t\t\tDataFieldName=\"os_top_flag_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_58\n",
      "\t\t\tOBJECT=DataField_59\n",
      "\t\t\t\tDataFieldName=\"cloud_top_pressure_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_59\n",
      "\t\t\tOBJECT=DataField_60\n",
      "\t\t\t\tDataFieldName=\"cloud_top_height_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_60\n",
      "\t\t\tOBJECT=DataField_61\n",
      "\t\t\t\tDataFieldName=\"cloud_top_temperature_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_61\n",
      "\t\t\tOBJECT=DataField_62\n",
      "\t\t\t\tDataFieldName=\"cloud_emissivity_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_62\n",
      "\t\t\tOBJECT=DataField_63\n",
      "\t\t\t\tDataFieldName=\"cloud_top_method_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_63\n",
      "\t\t\tOBJECT=DataField_64\n",
      "\t\t\t\tDataFieldName=\"surface_temperature_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_64\n",
      "\t\t\tOBJECT=DataField_65\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss11_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_65\n",
      "\t\t\tOBJECT=DataField_66\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss12_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_66\n",
      "\t\t\tOBJECT=DataField_67\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss13_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_67\n",
      "\t\t\tOBJECT=DataField_68\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss85_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_68\n",
      "\t\t\tOBJECT=DataField_69\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_69\n",
      "\t\t\tOBJECT=DataField_70\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_70\n",
      "\t\t\tOBJECT=DataField_71\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_71\n",
      "\t\t\tOBJECT=DataField_72\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_72\n",
      "\t\t\tOBJECT=DataField_73\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_73\n",
      "\t\t\tOBJECT=DataField_74\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_74\n",
      "\t\t\tOBJECT=DataField_75\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_75\n",
      "\t\t\tOBJECT=DataField_76\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_76\n",
      "\t\t\tOBJECT=DataField_77\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_77\n",
      "\t\t\tOBJECT=DataField_78\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_78\n",
      "\t\t\tOBJECT=DataField_79\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_79\n",
      "\t\t\tOBJECT=DataField_80\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_80\n",
      "\t\t\tOBJECT=DataField_81\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_81\n",
      "\t\t\tOBJECT=DataField_82\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_82\n",
      "\t\t\tOBJECT=DataField_83\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_83\n",
      "\t\t\tOBJECT=DataField_84\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_84\n",
      "\t\t\tOBJECT=DataField_85\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_85\n",
      "\t\t\tOBJECT=DataField_86\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_86\n",
      "\t\t\tOBJECT=DataField_87\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_87\n",
      "\t\t\tOBJECT=DataField_88\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_88\n",
      "\t\t\tOBJECT=DataField_89\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_89\n",
      "\t\t\tOBJECT=DataField_90\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_90\n",
      "\t\t\tOBJECT=DataField_91\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_91\n",
      "\t\t\tOBJECT=DataField_92\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_92\n",
      "\t\t\tOBJECT=DataField_93\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_93\n",
      "\t\t\tOBJECT=DataField_94\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_94\n",
      "\t\t\tOBJECT=DataField_95\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_95\n",
      "\t\t\tOBJECT=DataField_96\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_96\n",
      "\t\t\tOBJECT=DataField_97\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_97\n",
      "\t\t\tOBJECT=DataField_98\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_98\n",
      "\t\t\tOBJECT=DataField_99\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_99\n",
      "\t\t\tOBJECT=DataField_100\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_100\n",
      "\t\t\tOBJECT=DataField_101\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_101\n",
      "\t\t\tOBJECT=DataField_102\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_102\n",
      "\t\t\tOBJECT=DataField_103\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_103\n",
      "\t\t\tOBJECT=DataField_104\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_104\n",
      "\t\t\tOBJECT=DataField_105\n",
      "\t\t\t\tDataFieldName=\"Above_Cloud_Water_Vapor_094\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_105\n",
      "\t\t\tOBJECT=DataField_106\n",
      "\t\t\t\tDataFieldName=\"IRW_Low_Cloud_Temperature_From_COP\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_106\n",
      "\t\t\tOBJECT=DataField_107\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Optical_Properties\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_107\n",
      "\t\t\tOBJECT=DataField_108\n",
      "\t\t\t\tDataFieldName=\"Cloud_Multi_Layer_Flag\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_108\n",
      "\t\t\tOBJECT=DataField_109\n",
      "\t\t\t\tDataFieldName=\"Cirrus_Reflectance\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_109\n",
      "\t\t\tOBJECT=DataField_110\n",
      "\t\t\t\tDataFieldName=\"Cirrus_Reflectance_Flag\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_110\n",
      "\t\t\tOBJECT=DataField_111\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_5km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\",\"Cloud_Mask_5km_Num_Bytes\")\n",
      "\t\t\tEND_OBJECT=DataField_111\n",
      "\t\t\tOBJECT=DataField_112\n",
      "\t\t\t\tDataFieldName=\"Quality_Assurance_5km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\",\"QA_Parameter_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_112\n",
      "\t\t\tOBJECT=DataField_113\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"Cloud_Mask_1km_Num_Bytes\")\n",
      "\t\t\tEND_OBJECT=DataField_113\n",
      "\t\t\tOBJECT=DataField_114\n",
      "\t\t\t\tDataFieldName=\"Extinction_Efficiency_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_114\n",
      "\t\t\tOBJECT=DataField_115\n",
      "\t\t\t\tDataFieldName=\"Asymmetry_Parameter_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_115\n",
      "\t\t\tOBJECT=DataField_116\n",
      "\t\t\t\tDataFieldName=\"Single_Scatter_Albedo_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_116\n",
      "\t\t\tOBJECT=DataField_117\n",
      "\t\t\t\tDataFieldName=\"Extinction_Efficiency_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_117\n",
      "\t\t\tOBJECT=DataField_118\n",
      "\t\t\t\tDataFieldName=\"Asymmetry_Parameter_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_118\n",
      "\t\t\tOBJECT=DataField_119\n",
      "\t\t\t\tDataFieldName=\"Single_Scatter_Albedo_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_119\n",
      "\t\t\tOBJECT=DataField_120\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_SPI\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"SPI_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_120\n",
      "\t\t\tOBJECT=DataField_121\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_121\n",
      "\t\t\tOBJECT=DataField_122\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_122\n",
      "\t\t\tOBJECT=DataField_123\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_123\n",
      "\t\t\tOBJECT=DataField_124\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_124\n",
      "\t\t\tOBJECT=DataField_125\n",
      "\t\t\t\tDataFieldName=\"Atm_Corr_Refl\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"ACR_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_125\n",
      "\t\t\tOBJECT=DataField_126\n",
      "\t\t\t\tDataFieldName=\"Quality_Assurance_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"QA_Parameter_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_126\n",
      "\t\tEND_GROUP=DataField\n",
      "\t\tGROUP=MergedFields\n",
      "\t\tEND_GROUP=MergedFields\n",
      "\tEND_GROUP=SWATH_1\n",
      "END_GROUP=SwathStructure\n",
      "GROUP=GridStructure\n",
      "END_GROUP=GridStructure\n",
      "GROUP=PointStructure\n",
      "END_GROUP=PointStructure\n",
      "END\n",
      "\n",
      "    Number_of_Instrument_Scans: 2040\n",
      "    Maximum_Number_of_1km_Frames: 1354\n",
      "    history: $Id: MOD06_L2.CDL.fs,v 1.13 2013/06/19 15:38:46 wind Exp $                          \n",
      "\n",
      "    title: MODIS Level 2 Cloud Properties                                                      \n",
      "\n",
      "    CoreMetadata.0: \n",
      "GROUP                  = INVENTORYMETADATA\n",
      "  GROUPTYPE            = MASTERGROUP\n",
      "\n",
      "  GROUP                  = ECSDATAGRANULE\n",
      "\n",
      "    OBJECT                 = REPROCESSINGPLANNED\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"further update is anticipated\"\n",
      "    END_OBJECT             = REPROCESSINGPLANNED\n",
      "\n",
      "    OBJECT                 = REPROCESSINGACTUAL\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"processed once\"\n",
      "    END_OBJECT             = REPROCESSINGACTUAL\n",
      "\n",
      "    OBJECT                 = LOCALGRANULEID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MYD06_L2.A2002185.0000.061.2018003215042.hdf\"\n",
      "    END_OBJECT             = LOCALGRANULEID\n",
      "\n",
      "    OBJECT                 = DAYNIGHTFLAG\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"Night\"\n",
      "    END_OBJECT             = DAYNIGHTFLAG\n",
      "\n",
      "    OBJECT                 = PRODUCTIONDATETIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2018-01-03T21:50:42.000Z\"\n",
      "    END_OBJECT             = PRODUCTIONDATETIME\n",
      "\n",
      "    OBJECT                 = LOCALVERSIONID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"061\"\n",
      "    END_OBJECT             = LOCALVERSIONID\n",
      "\n",
      "  END_GROUP              = ECSDATAGRANULE\n",
      "\n",
      "  GROUP                  = MEASUREDPARAMETER\n",
      "\n",
      "    OBJECT                 = MEASUREDPARAMETERCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = PARAMETERNAME\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"Cloud_Top_Pressure\"\n",
      "      END_OBJECT             = PARAMETERNAME\n",
      "\n",
      "      GROUP                  = QAFLAGS\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = AUTOMATICQUALITYFLAG\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"Passed\"\n",
      "        END_OBJECT             = AUTOMATICQUALITYFLAG\n",
      "\n",
      "        OBJECT                 = AUTOMATICQUALITYFLAGEXPLANATION\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"Passed: >10% useable; Failed: <10% useable\"\n",
      "        END_OBJECT             = AUTOMATICQUALITYFLAGEXPLANATION\n",
      "\n",
      "        OBJECT                 = SCIENCEQUALITYFLAG\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = \"Not Investigated\"\n",
      "          CLASS                = \"1\"\n",
      "        END_OBJECT             = SCIENCEQUALITYFLAG\n",
      "\n",
      "        OBJECT                 = SCIENCEQUALITYFLAGEXPLANATION\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = \"See http://modis-atmos.gsfc.nasa.gov/validation.html for more details on MODIS Atmosphere data quality.\"\n",
      "          CLASS                = \"1\"\n",
      "        END_OBJECT             = SCIENCEQUALITYFLAGEXPLANATION\n",
      "\n",
      "      END_GROUP              = QAFLAGS\n",
      "\n",
      "      GROUP                  = QASTATS\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = QAPERCENTMISSINGDATA\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = 63\n",
      "        END_OBJECT             = QAPERCENTMISSINGDATA\n",
      "\n",
      "      END_GROUP              = QASTATS\n",
      "\n",
      "    END_OBJECT             = MEASUREDPARAMETERCONTAINER\n",
      "\n",
      "  END_GROUP              = MEASUREDPARAMETER\n",
      "\n",
      "  GROUP                  = ORBITCALCULATEDSPATIALDOMAIN\n",
      "\n",
      "    OBJECT                 = ORBITCALCULATEDSPATIALDOMAINCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ORBITNUMBER\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = 885\n",
      "      END_OBJECT             = ORBITNUMBER\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGLONGITUDE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = 20.4199118302919\n",
      "      END_OBJECT             = EQUATORCROSSINGLONGITUDE\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGTIME\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"00:12:58.823356\"\n",
      "      END_OBJECT             = EQUATORCROSSINGTIME\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGDATE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"2002-07-04\"\n",
      "      END_OBJECT             = EQUATORCROSSINGDATE\n",
      "\n",
      "    END_OBJECT             = ORBITCALCULATEDSPATIALDOMAINCONTAINER\n",
      "\n",
      "  END_GROUP              = ORBITCALCULATEDSPATIALDOMAIN\n",
      "\n",
      "  GROUP                  = COLLECTIONDESCRIPTIONCLASS\n",
      "\n",
      "    OBJECT                 = SHORTNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MYD06_L2\"\n",
      "    END_OBJECT             = SHORTNAME\n",
      "\n",
      "    OBJECT                 = VERSIONID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = 61\n",
      "    END_OBJECT             = VERSIONID\n",
      "\n",
      "  END_GROUP              = COLLECTIONDESCRIPTIONCLASS\n",
      "\n",
      "  GROUP                  = INPUTGRANULE\n",
      "\n",
      "    OBJECT                 = INPUTPOINTER\n",
      "      NUM_VAL              = 50\n",
      "      VALUE                = (\"MYD021KM.A2002185.0000.061.2017363141721.hdf\", \"MYD03.A2002185.0000.061.2017362174430.hdf\", \"MYD35_L2.A2002185.0000.061.2017363141846.hdf\", \"gdas1.PGrbF00.020704.00z\", \"oisst.20020703\", \"goge1_2_img.v1\", \"modisdet.dry.101.lit_end.v3\", \"\n",
      "          modisdet.ozo.101.lit_end.v3\", \"modisdet.wts.101.lit_end.v3\", \"modisdet.wtl.101.lit_end.v3\", \"modisdet.wco.101.lit_end.v3\", \"MYDCSR_B.A2002185.061.2017363154239.hdf\", \"gdas1.PGrbF00.020704.06z\", \"eng.020704\", \"NISE_SSMIF13_20020704.HDFEOS\", \"MODIS_Ice_library.hdf.v5\", \"\n",
      "          MODIS_Water_library.hdf.v4\", \"MODIS_Ice_library_ws3.hdf.v3\", \"MODIS_Ice_library_ws3sd.hdf.v4\", \"MODIS_Ice_library_ws7.hdf.v3\", \"MODIS_Ice_library_ws7sd.hdf.v4\", \"MODIS_Ice_library_ws15.hdf.v3\", \"MODIS_Ice_library_ws15sd.hdf.v4\", \"MODIS_Water_library_ws3.hdf.v2\", \"\n",
      "          MODIS_Water_library_ws3sd.hdf.v3\", \"MODIS_Water_library_ws7.hdf.v2\", \"MODIS_Water_library_ws7sd.hdf.v3\", \"MODIS_Water_library_ws15.hdf.v2\", \"MODIS_Water_library_ws15sd.hdf.v3\", \"MODIS_Ice_WaterPhaseFunc.hdf.v3\", \"Transmittance.hdf.v2\", \"IGBP.EcoMap.NtoS.2004.149.v004.hdf\", \"\n",
      "          AlbSnwStst.ByNISE.W90.D90.WS.Hemi.2000-2004.YrAvg.hdf\", \"MCD43GF_wsa_Band1_185_2002_V006.hdf\", \"MCD43GF_wsa_Band2_185_2002_V006.hdf\", \"MCD43GF_wsa_Band5_185_2002_V006.hdf\", \"MCD43GF_wsa_Band6_185_2002_V006.hdf\", \"MCD43GF_wsa_Band7_185_2002_V006.hdf\")\n",
      "    END_OBJECT             = INPUTPOINTER\n",
      "\n",
      "  END_GROUP              = INPUTGRANULE\n",
      "\n",
      "  GROUP                  = SPATIALDOMAINCONTAINER\n",
      "\n",
      "    GROUP                  = HORIZONTALSPATIALDOMAINCONTAINER\n",
      "\n",
      "      GROUP                  = BOUNDINGRECTANGLE\n",
      "\n",
      "        OBJECT                 = WESTBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 15.0125121267976\n",
      "        END_OBJECT             = WESTBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = NORTHBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 47.4712121222453\n",
      "        END_OBJECT             = NORTHBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = EASTBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 46.3027701461145\n",
      "        END_OBJECT             = EASTBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = SOUTHBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 26.6036189855835\n",
      "        END_OBJECT             = SOUTHBOUNDINGCOORDINATE\n",
      "\n",
      "      END_GROUP              = BOUNDINGRECTANGLE\n",
      "\n",
      "    END_GROUP              = HORIZONTALSPATIALDOMAINCONTAINER\n",
      "\n",
      "  END_GROUP              = SPATIALDOMAINCONTAINER\n",
      "\n",
      "  GROUP                  = RANGEDATETIME\n",
      "\n",
      "    OBJECT                 = RANGEBEGINNINGDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2002-07-04\"\n",
      "    END_OBJECT             = RANGEBEGINNINGDATE\n",
      "\n",
      "    OBJECT                 = RANGEBEGINNINGTIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"00:00:00.000000\"\n",
      "    END_OBJECT             = RANGEBEGINNINGTIME\n",
      "\n",
      "    OBJECT                 = RANGEENDINGDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2002-07-04\"\n",
      "    END_OBJECT             = RANGEENDINGDATE\n",
      "\n",
      "    OBJECT                 = RANGEENDINGTIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"00:05:00.000000\"\n",
      "    END_OBJECT             = RANGEENDINGTIME\n",
      "\n",
      "  END_GROUP              = RANGEDATETIME\n",
      "\n",
      "  GROUP                  = PGEVERSIONCLASS\n",
      "\n",
      "    OBJECT                 = PGEVERSION\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"6.1.4\"\n",
      "    END_OBJECT             = PGEVERSION\n",
      "\n",
      "  END_GROUP              = PGEVERSIONCLASS\n",
      "\n",
      "  GROUP                  = ANCILLARYINPUTGRANULE\n",
      "\n",
      "    OBJECT                 = ANCILLARYINPUTGRANULECONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ANCILLARYINPUTTYPE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"Geolocation\"\n",
      "      END_OBJECT             = ANCILLARYINPUTTYPE\n",
      "\n",
      "      OBJECT                 = ANCILLARYINPUTPOINTER\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"MYD03.A2002185.0000.061.2017362174430.hdf\"\n",
      "      END_OBJECT             = ANCILLARYINPUTPOINTER\n",
      "\n",
      "    END_OBJECT             = ANCILLARYINPUTGRANULECONTAINER\n",
      "\n",
      "  END_GROUP              = ANCILLARYINPUTGRANULE\n",
      "\n",
      "  GROUP                  = ASSOCIATEDPLATFORMINSTRUMENTSENSOR\n",
      "\n",
      "    OBJECT                 = ASSOCIATEDPLATFORMINSTRUMENTSENSORCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDSENSORSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MODIS\"\n",
      "      END_OBJECT             = ASSOCIATEDSENSORSHORTNAME\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDPLATFORMSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"Aqua\"\n",
      "      END_OBJECT             = ASSOCIATEDPLATFORMSHORTNAME\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDINSTRUMENTSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MODIS\"\n",
      "      END_OBJECT             = ASSOCIATEDINSTRUMENTSHORTNAME\n",
      "\n",
      "    END_OBJECT             = ASSOCIATEDPLATFORMINSTRUMENTSENSORCONTAINER\n",
      "\n",
      "  END_GROUP              = ASSOCIATEDPLATFORMINSTRUMENTSENSOR\n",
      "\n",
      "  GROUP                  = ADDITIONALATTRIBUTES\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SuccessCloudTopPropRtrPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"   36.98\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"2\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"2\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SuccessCloudPhaseRtrPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"2\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"2\"\n",
      "          VALUE                = \"   36.66\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"4\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"4\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"LowCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"4\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"4\"\n",
      "          VALUE                = \"   32.12\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"5\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"5\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MidCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"5\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"5\"\n",
      "          VALUE                = \"    2.40\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"6\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"6\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"HighCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"6\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"6\"\n",
      "          VALUE                = \"    2.45\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"7\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"7\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"ThinCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"7\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"7\"\n",
      "          VALUE                = \"    9.74\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"8\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"8\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"ThickCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"8\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"8\"\n",
      "          VALUE                = \"   10.37\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"9\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"9\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"OpaqueCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"9\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"9\"\n",
      "          VALUE                = \"   16.86\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"10\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"10\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"CirrusCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"10\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"10\"\n",
      "          VALUE                = \"   20.12\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"11\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"11\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"IceCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"11\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"11\"\n",
      "          VALUE                = \"    1.27\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"12\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"12\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"WaterCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"12\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"12\"\n",
      "          VALUE                = \"   32.99\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"13\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"13\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MixedCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"13\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"13\"\n",
      "          VALUE                = \"    0.00\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"14\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"14\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"CloudPhaseUncertainPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"14\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"14\"\n",
      "          VALUE                = \"    2.40\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"15\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"15\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"OceanCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"15\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"15\"\n",
      "          VALUE                = \"   45.11\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"16\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"16\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"LandCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"16\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"16\"\n",
      "          VALUE                = \"   54.89\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"17\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"17\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SnowCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"17\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"17\"\n",
      "          VALUE                = \"    0.06\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"18\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"18\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"identifier_product_doi\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"18\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"18\"\n",
      "          VALUE                = \"10.5067/MODIS/MYD06_L2.061\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"19\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"19\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"identifier_product_doi_authority\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"19\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"19\"\n",
      "          VALUE                = \"http://dx.doi.org\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "  END_GROUP              = ADDITIONALATTRIBUTES\n",
      "\n",
      "END_GROUP              = INVENTORYMETADATA\n",
      "\n",
      "END\n",
      "\n",
      "    ArchiveMetadata.0: \n",
      "GROUP                  = ARCHIVEDMETADATA\n",
      "  GROUPTYPE            = MASTERGROUP\n",
      "\n",
      "  OBJECT                 = PROCESSINGENVIRONMENT\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"Linux minion7260 3.10.0-693.11.1.el7.x86_64 #1 SMP Mon Dec 4 23:52:40 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\"\n",
      "  END_OBJECT             = PROCESSINGENVIRONMENT\n",
      "\n",
      "  GROUP                  = ALGORITHMPACKAGE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEACCEPTANCEDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"June 1997\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEACCEPTANCEDATE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEMATURITYCODE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"at-launch\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEMATURITYCODE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGENAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"ATBD-MOD-04 and ATBD-MOD-05\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGENAME\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEVERSION\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEVERSION\n",
      "\n",
      "    OBJECT                 = INSTRUMENTNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"Moderate Resolution Imaging Spectroradiometer\"\n",
      "    END_OBJECT             = INSTRUMENTNAME\n",
      "\n",
      "    OBJECT                 = LONGNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MODIS/Aqua Clouds 5-Min L2 Swath 1km and 5km\"\n",
      "    END_OBJECT             = LONGNAME\n",
      "\n",
      "    OBJECT                 = LOCALINPUTGRANULEID\n",
      "      NUM_VAL              = 20\n",
      "      VALUE                = (\"MYD021KM.A2002185.0000.061.2017363141721.hdf\", \"MYD03.A2002185.0000.061.2017362174430.hdf\", \"MYD35_L2.A2002185.0000.061.2017363141846.hdf\", \"MYDCSR_B.A2002185.061.2017363154239.hdf\")\n",
      "    END_OBJECT             = LOCALINPUTGRANULEID\n",
      "\n",
      "  END_GROUP              = ALGORITHMPACKAGE\n",
      "\n",
      "  GROUP                  = GPOLYGON\n",
      "\n",
      "    OBJECT                 = GPOLYGONCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      GROUP                  = GRING\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = EXCLUSIONGRINGFLAG\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"N\"\n",
      "        END_OBJECT             = EXCLUSIONGRINGFLAG\n",
      "\n",
      "      END_GROUP              = GRING\n",
      "\n",
      "      GROUP                  = GRINGPOINT\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = GRINGPOINTLONGITUDE\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (16.6802142122724, 46.3037511907536, 38.7590005022001, 14.9898525858698)\n",
      "        END_OBJECT             = GRINGPOINTLONGITUDE\n",
      "\n",
      "        OBJECT                 = GRINGPOINTLATITUDE\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (47.4897565211684, 43.2358532665263, 26.5236230538033, 29.7440219071349)\n",
      "        END_OBJECT             = GRINGPOINTLATITUDE\n",
      "\n",
      "        OBJECT                 = GRINGPOINTSEQUENCENO\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (1, 2, 3, 4)\n",
      "        END_OBJECT             = GRINGPOINTSEQUENCENO\n",
      "\n",
      "      END_GROUP              = GRINGPOINT\n",
      "\n",
      "    END_OBJECT             = GPOLYGONCONTAINER\n",
      "\n",
      "  END_GROUP              = GPOLYGON\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_TOP_PROPERTY_IR\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_TOP_PROPERTY_IR\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_PHASE_IR\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_PHASE_IR\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_PROPERTY_VIS\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_PROPERTY_VIS\n",
      "\n",
      "  OBJECT                 = DESCRREVISION\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"6.1\"\n",
      "  END_OBJECT             = DESCRREVISION\n",
      "\n",
      "  OBJECT                 = PRODUCTIONHISTORY\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"PGE06:6.1.4\"\n",
      "  END_OBJECT             = PRODUCTIONHISTORY\n",
      "\n",
      "END_GROUP              = ARCHIVEDMETADATA\n",
      "\n",
      "END\n",
      "\n",
      "    Clear_Sky_Restoral_Status: y\n",
      "    Collection_4_Phase_Used: n\n",
      "    Ice_Phase_Forced: n\n",
      "    Water_Phase_Forced: n\n",
      "    identifier_product_doi: 10.5067/MODIS/MYD06_L2.061\n",
      "    identifier_product_doi_authority: http://dx.doi.org\n",
      "    dimensions(sizes): Cell_Along_Swath_5km:mod06(408), Cell_Across_Swath_5km:mod06(270), Band_Number:mod06(7), Band_Forcing:mod06(5), Band_Ratio:mod06(5), Cell_Along_Swath_1km:mod06(2040), Cell_Across_Swath_1km:mod06(1354), Cloud_Mask_5km_Num_Bytes:mod06(2), QA_Parameter_5km:mod06(10), Cloud_Mask_1km_Num_Bytes:mod06(2), RadTran_NRE_Ice:mod06(12), RadTran_NWL:mod06(7), RadTran_NRE_Liq:mod06(18), SPI_nband:mod06(2), RFM_nband:mod06(3), ACR_nband:mod06(6), QA_Parameter_1km:mod06(9), fakeDim17(17)\n",
      "    variables(dimensions): >f4 \u001b[4mLatitude\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >f4 \u001b[4mLongitude\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >f8 \u001b[4mScan_Start_Time\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mBrightness_Temperature\u001b[0m(Band_Number:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSurface_Temperature\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSurface_Pressure\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Height_Method\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mTropopause_Height\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Infrared\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSpectral_Cloud_Forcing\u001b[0m(Band_Forcing:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_From_Ratios\u001b[0m(Band_Ratio:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mRadiance_Variance\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mIRP_CTH_Consistency_Flag_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mos_top_flag_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_pressure_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_height_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_temperature_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mcloud_emissivity_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mcloud_top_method_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4msurface_temperature_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss11_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss12_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss13_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss85_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mAbove_Cloud_Water_Vapor_094\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mIRW_Low_Cloud_Temperature_From_COP\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Phase_Optical_Properties\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Multi_Layer_Flag\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCirrus_Reflectance\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCirrus_Reflectance_Flag\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Mask_5km\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06,Cloud_Mask_5km_Num_Bytes:mod06), int8 \u001b[4mQuality_Assurance_5km\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06,QA_Parameter_5km:mod06), int8 \u001b[4mCloud_Mask_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,Cloud_Mask_1km_Num_Bytes:mod06), >f4 \u001b[4mExtinction_Efficiency_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mAsymmetry_Parameter_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mSingle_Scatter_Albedo_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mExtinction_Efficiency_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >f4 \u001b[4mAsymmetry_Parameter_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >f4 \u001b[4mSingle_Scatter_Albedo_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >i2 \u001b[4mCloud_Mask_SPI\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,SPI_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mAtm_Corr_Refl\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,ACR_nband:mod06), int8 \u001b[4mQuality_Assurance_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,QA_Parameter_1km:mod06), >f4 \u001b[4mStatistics_1km_sds\u001b[0m(fakeDim17)\n",
      "    groups: \n",
      "\n",
      "-----------------------------------------------\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int8 Cloud_Mask_1km(Cell_Along_Swath_1km:mod06, Cell_Across_Swath_1km:mod06, Cloud_Mask_1km_Num_Bytes:mod06)\n",
      "    valid_range: [ 0 -1]\n",
      "    _FillValue: 0\n",
      "    long_name: MODIS Cloud Mask, L2 MOD06 QA Plan\n",
      "    units: none\n",
      "    scale_factor: 1.0\n",
      "    add_offset: 0.0\n",
      "    Parameter_Type: MODIS Input\n",
      "    Cell_Along_Swath_Sampling: [   1 2040    1]\n",
      "    Cell_Across_Swath_Sampling: [   1 1354    1]\n",
      "    Geolocation_Pointer: External MODIS geolocation product\n",
      "    description: See MODIS atmosphere QA plan for details                                            \n",
      "\n",
      "unlimited dimensions: \n",
      "current shape = (2040, 1354, 2)\n",
      "filling on\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level-2 cloud mask array shape (2040, 1354)\n",
      "reading the lat-lon from MOD03 product\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      ">f4 Latitude(nscans*10:MODIS_Swath_Type_GEO, mframes:MODIS_Swath_Type_GEO)\n",
      "    units: degrees\n",
      "    valid_range: [-90.  90.]\n",
      "    _FillValue: -999.0\n",
      "unlimited dimensions: \n",
      "current shape = (2040, 1354)\n",
      "filling on\n",
      "level-2 lat-lon array shape (2040, 1354)\n",
      "Total Number of pixels in this granule (cloud mask CM>=0) 2762160\n",
      "Total Number of cloudy pixels (cloud mask CM<=1) 897662\n",
      "cloud fraction of this granule 0.3249855185796623\n",
      "projecting granule on level3 lat lon grids\n",
      "[ -361  -361  -361 ... 41978 41978 41978]\n",
      "computing simple level3 statistics\n",
      "this granule occupies 527 1x1 degree box\n",
      "derive the averaged Level-3 cloud fraction\n",
      "210.3164908220871\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import os,datetime,sys,fnmatch\n",
    "from jdcal import gcal2jd\n",
    "#from plot_global_map import *\n",
    "import math\n",
    "\n",
    "def read_MODIS_level2_data(MOD06_file,MOD03_file):\n",
    "    print(MOD06_file)\n",
    "    print(MOD03_file)\n",
    "    print('reading the cloud mask from MOD06_L2 product')\n",
    "    MOD06 = Dataset(MOD06_file, 'r')\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(MOD06)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    CM1km = MOD06.variables['Cloud_Mask_1km']\n",
    "    print(CM1km)\n",
    "    CM   = (np.array(CM1km[:,:,0],dtype='byte') & 0b00000110) >>1\n",
    "    print('level-2 cloud mask array shape',CM.shape)\n",
    "\n",
    "    MOD03 = Dataset(MOD03_file,'r')\n",
    "    print('reading the lat-lon from MOD03 product')\n",
    "    lat  = MOD03.variables['Latitude']\n",
    "    print(lat)\n",
    "    lon  = MOD03.variables['Longitude']\n",
    "    print('level-2 lat-lon array shape',lat.shape)\n",
    "\n",
    "    return lat,lon,CM\n",
    "\n",
    "def value_locate(refx, x):\n",
    "    refx = np.array(refx)\n",
    "    x = np.array(x)\n",
    "    loc = np.zeros(len(x), dtype='int')\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        ix = x[i]\n",
    "        ind = ((refx - ix) <= 0).nonzero()[0]\n",
    "        if len(ind) == 0:\n",
    "            loc[i] = -1\n",
    "        else: loc[i] = ind[-1]\n",
    "\n",
    "    return loc\n",
    "\n",
    "def division(n, d):\n",
    "\n",
    "    div = np.zeros(len(d))\n",
    "    for i in range(len(d)):\n",
    "        if d[i] >0:\n",
    "          div[i]=n[i]/d[i]\n",
    "        else: div[i]=None \n",
    "\n",
    "    return div\n",
    "\n",
    "\n",
    "# beginning of the program\n",
    "if __name__ == '__main__':\n",
    "    import itertools\n",
    "    MOD03_path = '/Users/saviosebastian/Desktop/XArraysTest/'\n",
    "    MOD06_path = '/Users/saviosebastian/Desktop/XArraysTest/'\n",
    "    satellite = 'Aqua'\n",
    "\n",
    "    yr = [2008]\n",
    "    mn = [1] #np.arange(1,13)  #[1]\n",
    "    dy = [1] #np.arange(1,32) # [1] #np.arange(1,31)\n",
    "    # latitude and longtitude boundaries of level-3 grid\n",
    "    lat_bnd = np.arange(-90,91,1)\n",
    "    lon_bnd = np.arange(-180,180,1)\n",
    "    nlat = 180\n",
    "    nlon = 360\n",
    "\n",
    "    TOT_pix      = np.zeros(nlat*nlon)\n",
    "    CLD_pix      = np.zeros(nlat*nlon)\n",
    "\n",
    "    #for y,m,d in  itertools.product(yr,mn, dy):\n",
    "        #-------------find the MODIS prodcts--------------#\n",
    "    #    date = datetime.datetime(y,m,d)\n",
    "    #    JD01, JD02 = gcal2jd(y,1,1)\n",
    "    #    JD1, JD2 = gcal2jd(y,m,d)\n",
    "    #    JD = np.int((JD2+JD1)-(JD01+JD02) + 1)\n",
    "    #    granule_time = datetime.datetime(y,m,d,0,0)\n",
    "    #    while granule_time <= datetime.datetime(y,m,d,23,55):  # 23,55\n",
    "    #        print('granule time:',granule_time)\n",
    "    MOD03_fp = 'MYD03.A*.hdf'\n",
    "    MOD06_fp = 'MYD06_L2.A*.hdf'\n",
    "    MOD03_fn, MOD06_fn =[],[]\n",
    "    for MOD06_flist in  os.listdir(MOD06_path):\n",
    "        if fnmatch.fnmatch(MOD06_flist, MOD06_fp):\n",
    "           MOD06_fn = MOD06_flist\n",
    "    for MOD03_flist in  os.listdir(MOD03_path):\n",
    "        if fnmatch.fnmatch(MOD03_flist, MOD03_fp):\n",
    "           MOD03_fn = MOD03_flist\n",
    "    if MOD03_fn and MOD06_fn: # if both MOD06 and MOD03 products are in the directory\n",
    "                print('reading level 2 geolocation and cloud data')\n",
    "                print(MOD06_fn)\n",
    "                Lat,Lon,CM = read_MODIS_level2_data(MOD06_path+MOD06_fn,MOD03_path+MOD03_fn)\n",
    "                Lat=np.ravel(Lat)\n",
    "                Lon=np.ravel(Lon)\n",
    "                CM=np.ravel(CM)\n",
    "                print('Total Number of pixels in this granule (cloud mask CM>=0)',np.sum(CM>=0))\n",
    "                print('Total Number of cloudy pixels (cloud mask CM<=1)',np.sum(CM<=1))\n",
    "                print('cloud fraction of this granule',np.sum(CM<=1)/np.sum(CM>=0))\n",
    "                print('projecting granule on level3 lat lon grids')\n",
    "                lat_index = value_locate(lat_bnd,Lat)\n",
    "                lon_index = value_locate(lon_bnd,Lon)\n",
    "                latlon_index = lat_index*nlon + lon_index\n",
    "                print(latlon_index)\n",
    "                print('computing simple level3 statistics')\n",
    "                latlon_index_unique = np.unique(latlon_index)\n",
    "                print('this granule occupies',latlon_index_unique.size,'1x1 degree box')\n",
    "                for i in np.arange(latlon_index_unique.size):\n",
    "                    j=latlon_index_unique[i]\n",
    "                    TOT_pix[j] = TOT_pix[j]+np.sum(CM[np.where(latlon_index == j)]>=0)\n",
    "                    CLD_pix[j] = CLD_pix[j]+np.sum(CM[np.where(latlon_index == j)]<=1) \n",
    "                \n",
    "                #granule_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    print('derive the averaged Level-3 cloud fraction')\n",
    "    total_cloud_fraction  =  division(CLD_pix,TOT_pix).reshape([nlat,nlon])\n",
    "    print(np.nansum(total_cloud_fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int8 Cloud_Mask_1km(Cell_Along_Swath_1km:mod06, Cell_Across_Swath_1km:mod06, Cloud_Mask_1km_Num_Bytes:mod06)\n",
      "    valid_range: [ 0 -1]\n",
      "    _FillValue: 0\n",
      "    long_name: MODIS Cloud Mask, L2 MOD06 QA Plan\n",
      "    units: none\n",
      "    scale_factor: 1.0\n",
      "    add_offset: 0.0\n",
      "    Parameter_Type: MODIS Input\n",
      "    Cell_Along_Swath_Sampling: [   1 2040    1]\n",
      "    Cell_Across_Swath_Sampling: [   1 1354    1]\n",
      "    Geolocation_Pointer: External MODIS geolocation product\n",
      "    description: See MODIS atmosphere QA plan for details                                            \n",
      "\n",
      "unlimited dimensions: \n",
      "current shape = (2040, 1354, 2)\n",
      "filling on\n"
     ]
    }
   ],
   "source": [
    "MOD06 = Dataset('/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf', 'r')\n",
    "CM1km = MOD06.variables['Cloud_Mask_1km']\n",
    "print(CM1km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int8 Cloud_Mask_1km(Cell_Along_Swath_1km:mod06, Cell_Across_Swath_1km:mod06, Cloud_Mask_1km_Num_Bytes:mod06)\n",
      "    valid_range: [ 0 -1]\n",
      "    _FillValue: 0\n",
      "    long_name: MODIS Cloud Mask, L2 MOD06 QA Plan\n",
      "    units: none\n",
      "    scale_factor: 1.0\n",
      "    add_offset: 0.0\n",
      "    Parameter_Type: MODIS Input\n",
      "    Cell_Along_Swath_Sampling: [   1 2040    1]\n",
      "    Cell_Across_Swath_Sampling: [   1 1354    1]\n",
      "    Geolocation_Pointer: External MODIS geolocation product\n",
      "    description: See MODIS atmosphere QA plan for details                                            \n",
      "\n",
      "unlimited dimensions: \n",
      "current shape = (2040, 1354, 2)\n",
      "filling on\n"
     ]
    }
   ],
   "source": [
    "print(CM1km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Cell_Along_Swath_5km:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Cell_Along_Swath_5km:mod06', size = 408\n",
      "), ('Cell_Across_Swath_5km:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Cell_Across_Swath_5km:mod06', size = 270\n",
      "), ('Band_Number:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Band_Number:mod06', size = 7\n",
      "), ('Band_Forcing:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Band_Forcing:mod06', size = 5\n",
      "), ('Band_Ratio:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Band_Ratio:mod06', size = 5\n",
      "), ('Cell_Along_Swath_1km:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Cell_Along_Swath_1km:mod06', size = 2040\n",
      "), ('Cell_Across_Swath_1km:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Cell_Across_Swath_1km:mod06', size = 1354\n",
      "), ('Cloud_Mask_5km_Num_Bytes:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Cloud_Mask_5km_Num_Bytes:mod06', size = 2\n",
      "), ('QA_Parameter_5km:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'QA_Parameter_5km:mod06', size = 10\n",
      "), ('Cloud_Mask_1km_Num_Bytes:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'Cloud_Mask_1km_Num_Bytes:mod06', size = 2\n",
      "), ('RadTran_NRE_Ice:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'RadTran_NRE_Ice:mod06', size = 12\n",
      "), ('RadTran_NWL:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'RadTran_NWL:mod06', size = 7\n",
      "), ('RadTran_NRE_Liq:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'RadTran_NRE_Liq:mod06', size = 18\n",
      "), ('SPI_nband:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'SPI_nband:mod06', size = 2\n",
      "), ('RFM_nband:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'RFM_nband:mod06', size = 3\n",
      "), ('ACR_nband:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'ACR_nband:mod06', size = 6\n",
      "), ('QA_Parameter_1km:mod06', <class 'netCDF4._netCDF4.Dimension'>: name = 'QA_Parameter_1km:mod06', size = 9\n",
      "), ('fakeDim17', <class 'netCDF4._netCDF4.Dimension'>: name = 'fakeDim17', size = 17\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(MOD06.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    "print(MOD06.file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIS Level 2 Cloud Properties                                                      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MOD06.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module xarray.core.dataset:\n",
      "\n",
      "class Dataset(collections.abc.Mapping, xarray.core.common.ImplementsDatasetReduce, xarray.core.common.DataWithCoords, xarray.core.formatting.ReprMixin)\n",
      " |  A multi-dimensional, in memory, array database.\n",
      " |  \n",
      " |  A dataset resembles an in-memory representation of a NetCDF file, and\n",
      " |  consists of variables, coordinates and attributes which together form a\n",
      " |  self describing dataset.\n",
      " |  \n",
      " |  Dataset implements the mapping interface with keys given by variable names\n",
      " |  and values given by DataArray objects for each variable name.\n",
      " |  \n",
      " |  One dimensional variables with name equal to their dimension are index\n",
      " |  coordinates used for label based indexing.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      collections.abc.Mapping\n",
      " |      collections.abc.Collection\n",
      " |      collections.abc.Sized\n",
      " |      collections.abc.Iterable\n",
      " |      collections.abc.Container\n",
      " |      xarray.core.common.ImplementsDatasetReduce\n",
      " |      xarray.core.common.DataWithCoords\n",
      " |      xarray.core.arithmetic.SupportsArithmetic\n",
      " |      xarray.core.common.AttrAccessMixin\n",
      " |      xarray.core.formatting.ReprMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __abs__ = abs(...)\n",
      " |      abs(a) -- Same as abs(a).\n",
      " |  \n",
      " |  __add__ = add(...)\n",
      " |      add(a, b) -- Same as a + b.\n",
      " |  \n",
      " |  __and__ = and_(...)\n",
      " |      and_(a, b) -- Same as a & b.\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      The 'in' operator will return true or false depending on whether\n",
      " |      'key' is an array in the dataset or not.\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |  \n",
      " |  __dask_graph__(self)\n",
      " |  \n",
      " |  __dask_keys__(self)\n",
      " |  \n",
      " |  __dask_postcompute__(self)\n",
      " |  \n",
      " |  __dask_postpersist__(self)\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Remove a variable from this dataset.\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __eq__ = array_eq(self, other)\n",
      " |  \n",
      " |  __floordiv__ = floordiv(...)\n",
      " |      floordiv(a, b) -- Same as a // b.\n",
      " |  \n",
      " |  __ge__ = ge(...)\n",
      " |      ge(a, b) -- Same as a>=b.\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      Access variables or coordinates this dataset as a\n",
      " |      :py:class:`~xarray.DataArray`.\n",
      " |      \n",
      " |      Indexing with a list of names will return a new ``Dataset`` object.\n",
      " |  \n",
      " |  __gt__ = gt(...)\n",
      " |      gt(a, b) -- Same as a>b.\n",
      " |  \n",
      " |  __iadd__ = iadd(...)\n",
      " |      a = iadd(a, b) -- Same as a += b.\n",
      " |  \n",
      " |  __iand__ = iand(...)\n",
      " |      a = iand(a, b) -- Same as a &= b.\n",
      " |  \n",
      " |  __ifloordiv__ = ifloordiv(...)\n",
      " |      a = ifloordiv(a, b) -- Same as a //= b.\n",
      " |  \n",
      " |  __imod__ = imod(...)\n",
      " |      a = imod(a, b) -- Same as a %= b.\n",
      " |  \n",
      " |  __imul__ = imul(...)\n",
      " |      a = imul(a, b) -- Same as a *= b.\n",
      " |  \n",
      " |  __init__(self, data_vars=None, coords=None, attrs=None, compat='broadcast_equals')\n",
      " |      To load data from a file or file-like object, use the `open_dataset`\n",
      " |      function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data_vars : dict-like, optional\n",
      " |          A mapping from variable names to :py:class:`~xarray.DataArray`\n",
      " |          objects, :py:class:`~xarray.Variable` objects or tuples of the\n",
      " |          form ``(dims, data[, attrs])`` which can be used as arguments to\n",
      " |          create a new ``Variable``. Each dimension must have the same length\n",
      " |          in all variables in which it appears.\n",
      " |      coords : dict-like, optional\n",
      " |          Another mapping in the same form as the `variables` argument,\n",
      " |          except the each item is saved on the dataset as a \"coordinate\".\n",
      " |          These variables have an associated meaning: they describe\n",
      " |          constant/fixed/independent quantities, unlike the\n",
      " |          varying/measured/dependent quantities that belong in `variables`.\n",
      " |          Coordinates values may be given by 1-dimensional arrays or scalars,\n",
      " |          in which case `dims` do not need to be supplied: 1D arrays will be\n",
      " |          assumed to give index values along the dimension with the same\n",
      " |          name.\n",
      " |      attrs : dict-like, optional\n",
      " |          Global attributes to save on this dataset.\n",
      " |      compat : {'broadcast_equals', 'equals', 'identical'}, optional\n",
      " |          String indicating how to compare variables of the same name for\n",
      " |          potential conflicts when initializing this dataset:\n",
      " |      \n",
      " |          - 'broadcast_equals': all values must be equal when variables are\n",
      " |            broadcast against each other to ensure common dimensions.\n",
      " |          - 'equals': all values and dimensions must be the same.\n",
      " |          - 'identical': all values, dimensions and attributes must be the\n",
      " |            same.\n",
      " |  \n",
      " |  __invert__ = invert(...)\n",
      " |      invert(a) -- Same as ~a.\n",
      " |  \n",
      " |  __ior__ = ior(...)\n",
      " |      a = ior(a, b) -- Same as a |= b.\n",
      " |  \n",
      " |  __ipow__ = ipow(...)\n",
      " |      a = ipow(a, b) -- Same as a **= b.\n",
      " |  \n",
      " |  __isub__ = isub(...)\n",
      " |      a = isub(a, b) -- Same as a -= b.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __itruediv__ = itruediv(...)\n",
      " |      a = itruediv(a, b) -- Same as a /= b\n",
      " |  \n",
      " |  __ixor__ = ixor(...)\n",
      " |      a = ixor(a, b) -- Same as a ^= b.\n",
      " |  \n",
      " |  __le__ = le(...)\n",
      " |      le(a, b) -- Same as a<=b.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __lt__ = lt(...)\n",
      " |      lt(a, b) -- Same as a<b.\n",
      " |  \n",
      " |  __mod__ = mod(...)\n",
      " |      mod(a, b) -- Same as a % b.\n",
      " |  \n",
      " |  __mul__ = mul(...)\n",
      " |      mul(a, b) -- Same as a * b.\n",
      " |  \n",
      " |  __ne__ = array_ne(self, other)\n",
      " |  \n",
      " |  __neg__ = neg(...)\n",
      " |      neg(a) -- Same as -a.\n",
      " |  \n",
      " |  __or__ = or_(...)\n",
      " |      or_(a, b) -- Same as a | b.\n",
      " |  \n",
      " |  __pos__ = pos(...)\n",
      " |      pos(a) -- Same as +a.\n",
      " |  \n",
      " |  __pow__ = pow(...)\n",
      " |      pow(a, b) -- Same as a ** b.\n",
      " |  \n",
      " |  __radd__ = add(...)\n",
      " |      add(a, b) -- Same as a + b.\n",
      " |  \n",
      " |  __rand__ = and_(...)\n",
      " |      and_(a, b) -- Same as a & b.\n",
      " |  \n",
      " |  __rfloordiv__ = floordiv(...)\n",
      " |      floordiv(a, b) -- Same as a // b.\n",
      " |  \n",
      " |  __rmod__ = mod(...)\n",
      " |      mod(a, b) -- Same as a % b.\n",
      " |  \n",
      " |  __rmul__ = mul(...)\n",
      " |      mul(a, b) -- Same as a * b.\n",
      " |  \n",
      " |  __ror__ = or_(...)\n",
      " |      or_(a, b) -- Same as a | b.\n",
      " |  \n",
      " |  __rpow__ = pow(...)\n",
      " |      pow(a, b) -- Same as a ** b.\n",
      " |  \n",
      " |  __rsub__ = sub(...)\n",
      " |      sub(a, b) -- Same as a - b.\n",
      " |  \n",
      " |  __rtruediv__ = truediv(...)\n",
      " |      truediv(a, b) -- Same as a / b.\n",
      " |  \n",
      " |  __rxor__ = xor(...)\n",
      " |      xor(a, b) -- Same as a ^ b.\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |      Add an array to this dataset.\n",
      " |      \n",
      " |      If value is a `DataArray`, call its `select_vars()` method, rename it\n",
      " |      to `key` and merge the contents of the resulting dataset into this\n",
      " |      dataset.\n",
      " |      \n",
      " |      If value is an `Variable` object (or tuple of form\n",
      " |      ``(dims, data[, attrs])``), add it to this dataset as a new\n",
      " |      variable.\n",
      " |  \n",
      " |  __sub__ = sub(...)\n",
      " |      sub(a, b) -- Same as a - b.\n",
      " |  \n",
      " |  __truediv__ = truediv(...)\n",
      " |      truediv(a, b) -- Same as a / b.\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |  \n",
      " |  __xor__ = xor(...)\n",
      " |      xor(a, b) -- Same as a ^ b.\n",
      " |  \n",
      " |  all(self, dim=None, keep_attrs=False, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `all` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `all`.  By default `all` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `all` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `all` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  any(self, dim=None, keep_attrs=False, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `any` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `any`.  By default `any` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `any` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `any` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  apply(self, func, keep_attrs=False, args=(), **kwargs)\n",
      " |      Apply a function over the data variables in this dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function which can be called in the form `f(x, **kwargs)` to\n",
      " |          transform each DataArray `x` in this dataset into another\n",
      " |          DataArray.\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the dataset's attributes (`attrs`) will be copied from\n",
      " |          the original object to the new one. If False, the new object will\n",
      " |          be returned without attributes.\n",
      " |      args : tuple, optional\n",
      " |          Positional arguments passed on to `func`.\n",
      " |      **kwargs : dict\n",
      " |          Keyword arguments passed on to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Dataset\n",
      " |          Resulting dataset from applying ``func`` over each data variable.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> da = xr.DataArray(np.random.randn(2, 3))\n",
      " |      >>> ds = xr.Dataset({'foo': da, 'bar': ('x', [-1, 2])})\n",
      " |      >>> ds\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (dim_0: 2, dim_1: 3, x: 2)\n",
      " |      Dimensions without coordinates: dim_0, dim_1, x\n",
      " |      Data variables:\n",
      " |          foo      (dim_0, dim_1) float64 -0.3751 -1.951 -1.945 0.2948 0.711 -0.3948\n",
      " |          bar      (x) int64 -1 2\n",
      " |      >>> ds.apply(np.fabs)\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (dim_0: 2, dim_1: 3, x: 2)\n",
      " |      Dimensions without coordinates: dim_0, dim_1, x\n",
      " |      Data variables:\n",
      " |          foo      (dim_0, dim_1) float64 0.3751 1.951 1.945 0.2948 0.711 0.3948\n",
      " |          bar      (x) float64 1.0 2.0\n",
      " |  \n",
      " |  argmax(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `argmax` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `argmax`.  By default `argmax` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `argmax` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `argmax` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  argmin(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `argmin` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `argmin`.  By default `argmin` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `argmin` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `argmin` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  argsort(self, *args, **kwargs)\n",
      " |      a.argsort(axis=-1, kind='quicksort', order=None)\n",
      " |      \n",
      " |      Returns the indices that would sort this array.\n",
      " |      \n",
      " |      Refer to `numpy.argsort` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argsort : equivalent function\n",
      " |  \n",
      " |  assign(self, variables=None, **variables_kwargs)\n",
      " |      Assign new data variables to a Dataset, returning a new object\n",
      " |      with all the original variables in addition to the new ones.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      variables : mapping, value pairs\n",
      " |          Mapping from variables names to the new values. If the new values\n",
      " |          are callable, they are computed on the Dataset and assigned to new\n",
      " |          data variables. If the values are not callable, (e.g. a DataArray,\n",
      " |          scalar, or array), they are simply assigned.\n",
      " |      **variables_kwargs:\n",
      " |          The keyword arguments form of ``variables``.\n",
      " |          One of variables or variables_kwarg must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ds : Dataset\n",
      " |          A new Dataset with the new variables in addition to all the\n",
      " |          existing variables.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Since ``kwargs`` is a dictionary, the order of your arguments may not\n",
      " |      be preserved, and so the order of the new variables is not well\n",
      " |      defined. Assigning multiple variables within the same ``assign`` is\n",
      " |      possible, but you cannot reference other variables created within the\n",
      " |      same ``assign`` call.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.assign\n",
      " |  \n",
      " |  astype(self, *args, **kwargs)\n",
      " |      a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n",
      " |      \n",
      " |      Copy of the array, cast to a specified type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or dtype\n",
      " |          Typecode or data-type to which the array is cast.\n",
      " |      order : {'C', 'F', 'A', 'K'}, optional\n",
      " |          Controls the memory layout order of the result.\n",
      " |          'C' means C order, 'F' means Fortran order, 'A'\n",
      " |          means 'F' order if all the arrays are Fortran contiguous,\n",
      " |          'C' order otherwise, and 'K' means as close to the\n",
      " |          order the array elements appear in memory as possible.\n",
      " |          Default is 'K'.\n",
      " |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      " |          Controls what kind of data casting may occur. Defaults to 'unsafe'\n",
      " |          for backwards compatibility.\n",
      " |      \n",
      " |            * 'no' means the data types should not be cast at all.\n",
      " |            * 'equiv' means only byte-order changes are allowed.\n",
      " |            * 'safe' means only casts which can preserve values are allowed.\n",
      " |            * 'same_kind' means only safe casts or casts within a kind,\n",
      " |              like float64 to float32, are allowed.\n",
      " |            * 'unsafe' means any data conversions may be done.\n",
      " |      subok : bool, optional\n",
      " |          If True, then sub-classes will be passed-through (default), otherwise\n",
      " |          the returned array will be forced to be a base-class array.\n",
      " |      copy : bool, optional\n",
      " |          By default, astype always returns a newly allocated array. If this\n",
      " |          is set to false, and the `dtype`, `order`, and `subok`\n",
      " |          requirements are satisfied, the input array is returned instead\n",
      " |          of a copy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr_t : ndarray\n",
      " |          Unless `copy` is False and the other conditions for returning the input\n",
      " |          array are satisfied (see description for `copy` input parameter), `arr_t`\n",
      " |          is a new array of the same shape as the input array, with dtype, order\n",
      " |          given by `dtype`, `order`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Starting in NumPy 1.9, astype method now returns an error if the string\n",
      " |      dtype to cast to is not long enough in 'safe' casting mode to hold the max\n",
      " |      value of integer/float array that is being casted. Previously the casting\n",
      " |      was allowed even if the result was truncated.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ComplexWarning\n",
      " |          When casting from complex to float or int. To avoid this,\n",
      " |          one should use ``a.real.astype(t)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> x = np.array([1, 2, 2.5])\n",
      " |      >>> x\n",
      " |      array([ 1. ,  2. ,  2.5])\n",
      " |      \n",
      " |      >>> x.astype(int)\n",
      " |      array([1, 2, 2])\n",
      " |  \n",
      " |  bfill(self, dim, limit=None)\n",
      " |      Fill NaN values by propogating values backward\n",
      " |      \n",
      " |      *Requires bottleneck.*\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str\n",
      " |          Specifies the dimension along which to propagate values when\n",
      " |          filling.\n",
      " |      limit : int, default None\n",
      " |          The maximum number of consecutive NaN values to backward fill. In\n",
      " |          other words, if there is a gap with more than this number of\n",
      " |          consecutive NaNs, it will only be partially filled. Must be greater\n",
      " |          than 0 or None for no limit.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |  \n",
      " |  broadcast_equals(self, other)\n",
      " |      Two Datasets are broadcast equal if they are equal after\n",
      " |      broadcasting all variables against each other.\n",
      " |      \n",
      " |      For example, variables that are scalar in one dataset but non-scalar in\n",
      " |      the other dataset can still be broadcast equal if the the non-scalar\n",
      " |      variable is a constant.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.equals\n",
      " |      Dataset.identical\n",
      " |  \n",
      " |  chunk(self, chunks=None, name_prefix='xarray-', token=None, lock=False)\n",
      " |      Coerce all arrays in this dataset into dask arrays with the given\n",
      " |      chunks.\n",
      " |      \n",
      " |      Non-dask arrays in this dataset will be converted to dask arrays. Dask\n",
      " |      arrays will be rechunked to the given chunk sizes.\n",
      " |      \n",
      " |      If neither chunks is not provided for one or more dimensions, chunk\n",
      " |      sizes along that dimension will not be updated; non-dask arrays will be\n",
      " |      converted into dask arrays with a single block.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunks : int or dict, optional\n",
      " |          Chunk sizes along each dimension, e.g., ``5`` or\n",
      " |          ``{'x': 5, 'y': 5}``.\n",
      " |      name_prefix : str, optional\n",
      " |          Prefix for the name of any new dask arrays.\n",
      " |      token : str, optional\n",
      " |          Token uniquely identifying this dataset.\n",
      " |      lock : optional\n",
      " |          Passed on to :py:func:`dask.array.from_array`, if the array is not\n",
      " |          already as dask array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chunked : xarray.Dataset\n",
      " |  \n",
      " |  clip(self, *args, **kwargs)\n",
      " |      a.clip(min=None, max=None, out=None)\n",
      " |      \n",
      " |      Return an array whose values are limited to ``[min, max]``.\n",
      " |      One of max or min must be given.\n",
      " |      \n",
      " |      Refer to `numpy.clip` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.clip : equivalent function\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine two Datasets, default to data_vars of self.\n",
      " |      \n",
      " |      The new coordinates follow the normal broadcasting and alignment rules\n",
      " |      of ``join='outer'``.  Vacant cells in the expanded coordinates are\n",
      " |      filled with np.nan.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataArray\n",
      " |          Used to fill all matching missing values in this array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataArray\n",
      " |  \n",
      " |  compute(self, **kwargs)\n",
      " |      Manually trigger loading of this dataset's data from disk or a\n",
      " |      remote source into memory and return a new dataset. The original is\n",
      " |      left unaltered.\n",
      " |      \n",
      " |      Normally, it should not be necessary to call this method in user code,\n",
      " |      because all xarray functions should either work on deferred data or\n",
      " |      load data automatically. However, this method can be necessary when\n",
      " |      working with many file objects on disk.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to ``dask.array.compute``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dask.array.compute\n",
      " |  \n",
      " |  conj(self, *args, **kwargs)\n",
      " |      a.conj()\n",
      " |      \n",
      " |      Complex-conjugate all elements.\n",
      " |      \n",
      " |      Refer to `numpy.conjugate` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.conjugate : equivalent function\n",
      " |  \n",
      " |  conjugate(self, *args, **kwargs)\n",
      " |      a.conjugate()\n",
      " |      \n",
      " |      Return the complex conjugate, element-wise.\n",
      " |      \n",
      " |      Refer to `numpy.conjugate` for full documentation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.conjugate : equivalent function\n",
      " |  \n",
      " |  copy(self, deep=False, data=None)\n",
      " |      Returns a copy of this dataset.\n",
      " |      \n",
      " |      If `deep=True`, a deep copy is made of each of the component variables.\n",
      " |      Otherwise, a shallow copy of each of the component variable is made, so\n",
      " |      that the underlying memory region of the new dataset is the same as in\n",
      " |      the original dataset.\n",
      " |      \n",
      " |      Use `data` to create a new object with the same structure as\n",
      " |      original but entirely new data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, optional\n",
      " |          Whether each component variable is loaded into memory and copied onto\n",
      " |          the new object. Default is True.\n",
      " |      data : dict-like, optional\n",
      " |          Data to use in the new object. Each item in `data` must have same\n",
      " |          shape as corresponding data variable in original. When `data` is\n",
      " |          used, `deep` is ignored for the data variables and only used for\n",
      " |          coords.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : Dataset\n",
      " |          New object with dimensions, attributes, coordinates, name, encoding,\n",
      " |          and optionally data copied from original.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Shallow copy versus deep copy\n",
      " |      \n",
      " |      >>> da = xr.DataArray(np.random.randn(2, 3))\n",
      " |      >>> ds = xr.Dataset({'foo': da, 'bar': ('x', [-1, 2])}, \n",
      " |                          coords={'x': ['one', 'two']})\n",
      " |      >>> ds.copy()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (dim_0: 2, dim_1: 3, x: 2)\n",
      " |      Coordinates:\n",
      " |      * x        (x) <U3 'one' 'two'\n",
      " |      Dimensions without coordinates: dim_0, dim_1\n",
      " |      Data variables:\n",
      " |          foo      (dim_0, dim_1) float64 -0.8079 0.3897 -1.862 -0.6091 -1.051 -0.3003\n",
      " |          bar      (x) int64 -1 2\n",
      " |      >>> ds_0 = ds.copy(deep=False)\n",
      " |      >>> ds_0['foo'][0, 0] = 7\n",
      " |      >>> ds_0\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (dim_0: 2, dim_1: 3, x: 2)\n",
      " |      Coordinates:\n",
      " |      * x        (x) <U3 'one' 'two'\n",
      " |      Dimensions without coordinates: dim_0, dim_1\n",
      " |      Data variables:\n",
      " |          foo      (dim_0, dim_1) float64 7.0 0.3897 -1.862 -0.6091 -1.051 -0.3003\n",
      " |          bar      (x) int64 -1 2\n",
      " |      >>> ds\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (dim_0: 2, dim_1: 3, x: 2)\n",
      " |      Coordinates:\n",
      " |      * x        (x) <U3 'one' 'two'\n",
      " |      Dimensions without coordinates: dim_0, dim_1\n",
      " |      Data variables:\n",
      " |          foo      (dim_0, dim_1) float64 7.0 0.3897 -1.862 -0.6091 -1.051 -0.3003\n",
      " |          bar      (x) int64 -1 2\n",
      " |      \n",
      " |      Changing the data using the ``data`` argument maintains the \n",
      " |      structure of the original object, but with the new data. Original\n",
      " |      object is unaffected.\n",
      " |      \n",
      " |      >>> ds.copy(data={'foo': np.arange(6).reshape(2, 3), 'bar': ['a', 'b']})\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (dim_0: 2, dim_1: 3, x: 2)\n",
      " |      Coordinates:\n",
      " |      * x        (x) <U3 'one' 'two'\n",
      " |      Dimensions without coordinates: dim_0, dim_1\n",
      " |      Data variables:\n",
      " |          foo      (dim_0, dim_1) int64 0 1 2 3 4 5\n",
      " |          bar      (x) <U1 'a' 'b'\n",
      " |      >>> ds\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (dim_0: 2, dim_1: 3, x: 2)\n",
      " |      Coordinates:\n",
      " |      * x        (x) <U3 'one' 'two'\n",
      " |      Dimensions without coordinates: dim_0, dim_1\n",
      " |      Data variables:\n",
      " |          foo      (dim_0, dim_1) float64 7.0 0.3897 -1.862 -0.6091 -1.051 -0.3003\n",
      " |          bar      (x) int64 -1 2\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.copy\n",
      " |  \n",
      " |  count(self, dim=None, keep_attrs=False, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `count` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `count`.  By default `count` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `count` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `count` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  cumprod(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Apply `cumprod` along some dimension of Dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension over which to apply `cumprod`.\n",
      " |              axis : int or sequence of int, optional\n",
      " |                  Axis over which to apply `cumprod`. Only one of the 'dim'\n",
      " |                  and 'axis' arguments can be supplied.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to `cumprod`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumvalue : Dataset\n",
      " |          New Dataset object with `cumprod` applied to its data along the\n",
      " |          indicated dimension.\n",
      " |  \n",
      " |  cumsum(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Apply `cumsum` along some dimension of Dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension over which to apply `cumsum`.\n",
      " |              axis : int or sequence of int, optional\n",
      " |                  Axis over which to apply `cumsum`. Only one of the 'dim'\n",
      " |                  and 'axis' arguments can be supplied.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to `cumsum`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumvalue : Dataset\n",
      " |          New Dataset object with `cumsum` applied to its data along the\n",
      " |          indicated dimension.\n",
      " |  \n",
      " |  diff(self, dim, n=1, label='upper')\n",
      " |      Calculate the n-th order discrete difference along given axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str, optional\n",
      " |          Dimension over which to calculate the finite difference.\n",
      " |      n : int, optional\n",
      " |          The number of times values are differenced.\n",
      " |      label : str, optional\n",
      " |          The new coordinate in dimension ``dim`` will have the\n",
      " |          values of either the minuend's or subtrahend's coordinate\n",
      " |          for values 'upper' and 'lower', respectively.  Other\n",
      " |          values are not supported.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      difference : same type as caller\n",
      " |          The n-th order finite difference of this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ds = xr.Dataset({'foo': ('x', [5, 5, 6, 6])})\n",
      " |      >>> ds.diff('x')\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (x: 3)\n",
      " |      Coordinates:\n",
      " |        * x        (x) int64 1 2 3\n",
      " |      Data variables:\n",
      " |          foo      (x) int64 0 1 0\n",
      " |      >>> ds.diff('x', 2)\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (x: 2)\n",
      " |      Coordinates:\n",
      " |      * x        (x) int64 2 3\n",
      " |      Data variables:\n",
      " |      foo      (x) int64 1 -1\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.differentiate\n",
      " |  \n",
      " |  differentiate(self, coord, edge_order=1, datetime_unit=None)\n",
      " |      Differentiate with the second order accurate central\n",
      " |      differences.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This feature is limited to simple cartesian geometry, i.e. coord\n",
      " |          must be one dimensional.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      coord: str\n",
      " |          The coordinate to be used to compute the gradient.\n",
      " |      edge_order: 1 or 2. Default 1\n",
      " |          N-th order accurate differences at the boundaries.\n",
      " |      datetime_unit: None or any of {'Y', 'M', 'W', 'D', 'h', 'm', 's', 'ms',\n",
      " |          'us', 'ns', 'ps', 'fs', 'as'}\n",
      " |          Unit to compute gradient. Only valid for datetime coordinate.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      differentiated: Dataset\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.gradient: corresponding numpy function\n",
      " |  \n",
      " |  drop(self, labels, dim=None)\n",
      " |      Drop variables or index labels from this dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : scalar or list of scalars\n",
      " |          Name(s) of variables or index labels to drop.\n",
      " |      dim : None or str, optional\n",
      " |          Dimension along which to drop index labels. By default (if\n",
      " |          ``dim is None``), drops variables rather than index labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : Dataset\n",
      " |  \n",
      " |  dropna(self, dim, how='any', thresh=None, subset=None)\n",
      " |      Returns a new dataset with dropped labels for missing values along\n",
      " |      the provided dimension.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str\n",
      " |          Dimension along which to drop missing values. Dropping along\n",
      " |          multiple dimensions simultaneously is not yet supported.\n",
      " |      how : {'any', 'all'}, optional\n",
      " |          * any : if any NA values are present, drop that label\n",
      " |          * all : if all values are NA, drop that label\n",
      " |      thresh : int, default None\n",
      " |          If supplied, require this many non-NA values.\n",
      " |      subset : sequence, optional\n",
      " |          Subset of variables to check for missing values. By default, all\n",
      " |          variables in the dataset are checked.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |  \n",
      " |  dump_to_store(self, store, encoder=None, sync=True, encoding=None, unlimited_dims=None, compute=True)\n",
      " |      Store dataset contents to a backends.*DataStore object.\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Two Datasets are equal if they have matching variables and\n",
      " |      coordinates, all of which are equal.\n",
      " |      \n",
      " |      Datasets can still be equal (like pandas objects) if they have NaN\n",
      " |      values in the same locations.\n",
      " |      \n",
      " |      This method is necessary because `v1 == v2` for ``Dataset``\n",
      " |      does element-wise comparisons (like numpy.ndarrays).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.broadcast_equals\n",
      " |      Dataset.identical\n",
      " |  \n",
      " |  expand_dims(self, dim, axis=None)\n",
      " |      Return a new object with an additional axis (or axes) inserted at the\n",
      " |      corresponding position in the array shape.\n",
      " |      \n",
      " |      If dim is already a scalar coordinate, it will be promoted to a 1D\n",
      " |      coordinate consisting of a single value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str.\n",
      " |          Dimensions to include on the new variable.\n",
      " |          dimensions are inserted with length 1.\n",
      " |      axis : integer, list (or tuple) of integers, or None\n",
      " |          Axis position(s) where new axis is to be inserted (position(s) on\n",
      " |          the result array). If a list (or tuple) of integers is passed,\n",
      " |          multiple axes are inserted. In this case, dim arguments should be\n",
      " |          the same length list. If axis=None is passed, all the axes will\n",
      " |          be inserted to the start of the result array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      expanded : same type as caller\n",
      " |          This object, but with an additional dimension(s).\n",
      " |  \n",
      " |  ffill(self, dim, limit=None)\n",
      " |      Fill NaN values by propogating values forward\n",
      " |      \n",
      " |      *Requires bottleneck.*\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str\n",
      " |          Specifies the dimension along which to propagate values when\n",
      " |          filling.\n",
      " |      limit : int, default None\n",
      " |          The maximum number of consecutive NaN values to forward fill. In\n",
      " |          other words, if there is a gap with more than this number of\n",
      " |          consecutive NaNs, it will only be partially filled. Must be greater\n",
      " |          than 0 or None for no limit.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |  \n",
      " |  fillna(self, value)\n",
      " |      Fill missing values in this object.\n",
      " |      \n",
      " |      This operation follows the normal broadcasting and alignment rules that\n",
      " |      xarray uses for binary arithmetic, except the result is aligned to this\n",
      " |      object (``join='left'``) instead of aligned to the intersection of\n",
      " |      index coordinates (``join='inner'``).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, ndarray, DataArray, dict or Dataset\n",
      " |          Used to fill all matching missing values in this dataset's data\n",
      " |          variables. Scalars, ndarrays or DataArrays arguments are used to\n",
      " |          fill all data with aligned coordinates (for DataArrays).\n",
      " |          Dictionaries or datasets match data variables and then align\n",
      " |          coordinates if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |  \n",
      " |  filter_by_attrs(self, **kwargs)\n",
      " |      Returns a ``Dataset`` with variables that match specific conditions.\n",
      " |      \n",
      " |      Can pass in ``key=value`` or ``key=callable``.  A Dataset is returned\n",
      " |      containing only the variables for which all the filter tests pass.\n",
      " |      These tests are either ``key=value`` for which the attribute ``key``\n",
      " |      has the exact value ``value`` or the callable passed into\n",
      " |      ``key=callable`` returns True. The callable will be passed a single\n",
      " |      value, either the value of the attribute ``key`` or ``None`` if the\n",
      " |      DataArray does not have an attribute with the name ``key``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : key=value\n",
      " |          key : str\n",
      " |              Attribute name.\n",
      " |          value : callable or obj\n",
      " |              If value is a callable, it should return a boolean in the form\n",
      " |              of bool = func(attr) where attr is da.attrs[key].\n",
      " |              Otherwise, value will be compared to the each\n",
      " |              DataArray's attrs[key].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new : Dataset\n",
      " |          New dataset with variables filtered by attribute.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> # Create an example dataset:\n",
      " |      >>> import numpy as np\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import xarray as xr\n",
      " |      >>> temp = 15 + 8 * np.random.randn(2, 2, 3)\n",
      " |      >>> precip = 10 * np.random.rand(2, 2, 3)\n",
      " |      >>> lon = [[-99.83, -99.32], [-99.79, -99.23]]\n",
      " |      >>> lat = [[42.25, 42.21], [42.63, 42.59]]\n",
      " |      >>> dims = ['x', 'y', 'time']\n",
      " |      >>> temp_attr = dict(standard_name='air_potential_temperature')\n",
      " |      >>> precip_attr = dict(standard_name='convective_precipitation_flux')\n",
      " |      >>> ds = xr.Dataset({\n",
      " |      ...         'temperature': (dims,  temp, temp_attr),\n",
      " |      ...         'precipitation': (dims, precip, precip_attr)},\n",
      " |      ...                 coords={\n",
      " |      ...         'lon': (['x', 'y'], lon),\n",
      " |      ...         'lat': (['x', 'y'], lat),\n",
      " |      ...         'time': pd.date_range('2014-09-06', periods=3),\n",
      " |      ...         'reference_time': pd.Timestamp('2014-09-05')})\n",
      " |      >>> # Get variables matching a specific standard_name.\n",
      " |      >>> ds.filter_by_attrs(standard_name='convective_precipitation_flux')\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:         (time: 3, x: 2, y: 2)\n",
      " |      Coordinates:\n",
      " |        * x               (x) int64 0 1\n",
      " |        * time            (time) datetime64[ns] 2014-09-06 2014-09-07 2014-09-08\n",
      " |          lat             (x, y) float64 42.25 42.21 42.63 42.59\n",
      " |        * y               (y) int64 0 1\n",
      " |          reference_time  datetime64[ns] 2014-09-05\n",
      " |          lon             (x, y) float64 -99.83 -99.32 -99.79 -99.23\n",
      " |      Data variables:\n",
      " |          precipitation   (x, y, time) float64 4.178 2.307 6.041 6.046 0.06648 ...\n",
      " |      >>> # Get all variables that have a standard_name attribute.\n",
      " |      >>> standard_name = lambda v: v is not None\n",
      " |      >>> ds.filter_by_attrs(standard_name=standard_name)\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:         (time: 3, x: 2, y: 2)\n",
      " |      Coordinates:\n",
      " |          lon             (x, y) float64 -99.83 -99.32 -99.79 -99.23\n",
      " |          lat             (x, y) float64 42.25 42.21 42.63 42.59\n",
      " |        * x               (x) int64 0 1\n",
      " |        * y               (y) int64 0 1\n",
      " |        * time            (time) datetime64[ns] 2014-09-06 2014-09-07 2014-09-08\n",
      " |          reference_time  datetime64[ns] 2014-09-05\n",
      " |      Data variables:\n",
      " |          temperature     (x, y, time) float64 25.86 20.82 6.954 23.13 10.25 11.68 ...\n",
      " |          precipitation   (x, y, time) float64 5.702 0.9422 2.075 1.178 3.284 ...\n",
      " |  \n",
      " |  identical(self, other)\n",
      " |      Like equals, but also checks all dataset attributes and the\n",
      " |      attributes on all variables and coordinates.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.broadcast_equals\n",
      " |      Dataset.equals\n",
      " |  \n",
      " |  info(self, buf=None)\n",
      " |      Concise summary of a Dataset variables and attributes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.assign\n",
      " |      netCDF's ncdump\n",
      " |  \n",
      " |  interp(self, coords=None, method='linear', assume_sorted=False, kwargs={}, **coords_kwargs)\n",
      " |      Multidimensional interpolation of Dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      coords : dict, optional\n",
      " |          Mapping from dimension names to the new coordinates.\n",
      " |          New coordinate can be a scalar, array-like or DataArray.\n",
      " |          If DataArrays are passed as new coordates, their dimensions are\n",
      " |          used for the broadcasting.\n",
      " |      method: string, optional.\n",
      " |          {'linear', 'nearest'} for multidimensional array,\n",
      " |          {'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'}\n",
      " |          for 1-dimensional array. 'linear' is used by default.\n",
      " |      assume_sorted: boolean, optional\n",
      " |          If False, values of coordinates that are interpolated over can be\n",
      " |          in any order and they are sorted first. If True, interpolated\n",
      " |          coordinates are assumed to be an array of monotonically increasing\n",
      " |          values.\n",
      " |      kwargs: dictionary, optional\n",
      " |          Additional keyword passed to scipy's interpolator.\n",
      " |      **coords_kwarg : {dim: coordinate, ...}, optional\n",
      " |          The keyword arguments form of ``coords``.\n",
      " |          One of coords or coords_kwargs must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      interpolated: xr.Dataset\n",
      " |          New dataset on the new coordinates.\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      scipy is required.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.interpolate.interp1d\n",
      " |      scipy.interpolate.interpn\n",
      " |  \n",
      " |  interp_like(self, other, method='linear', assume_sorted=False, kwargs={})\n",
      " |      Interpolate this object onto the coordinates of another object,\n",
      " |      filling the out of range values with NaN.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Dataset or DataArray\n",
      " |          Object with an 'indexes' attribute giving a mapping from dimension\n",
      " |          names to an 1d array-like, which provides coordinates upon\n",
      " |          which to index the variables in this dataset.\n",
      " |      method: string, optional.\n",
      " |          {'linear', 'nearest'} for multidimensional array,\n",
      " |          {'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'}\n",
      " |          for 1-dimensional array. 'linear' is used by default.\n",
      " |      assume_sorted: boolean, optional\n",
      " |          If False, values of coordinates that are interpolated over can be\n",
      " |          in any order and they are sorted first. If True, interpolated\n",
      " |          coordinates are assumed to be an array of monotonically increasing\n",
      " |          values.\n",
      " |      kwargs: dictionary, optional\n",
      " |          Additional keyword passed to scipy's interpolator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      interpolated: xr.Dataset\n",
      " |          Another dataset by interpolating this dataset's data along the\n",
      " |          coordinates of the other object.\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      scipy is required.\n",
      " |      If the dataset has object-type coordinates, reindex is used for these\n",
      " |      coordinates instead of the interpolation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.interp\n",
      " |      Dataset.reindex_like\n",
      " |  \n",
      " |  interpolate_na(self, dim=None, method='linear', limit=None, use_coordinate=True, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str\n",
      " |          Specifies the dimension along which to interpolate.\n",
      " |      method : {'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |                'polynomial', 'barycentric', 'krog', 'pchip',\n",
      " |                'spline'}, optional\n",
      " |          String indicating which method to use for interpolation:\n",
      " |      \n",
      " |          - 'linear': linear interpolation (Default). Additional keyword\n",
      " |            arguments are passed to ``numpy.interp``\n",
      " |          - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'polynomial': are passed to ``scipy.interpolate.interp1d``. If\n",
      " |            method=='polynomial', the ``order`` keyword argument must also be\n",
      " |            provided.\n",
      " |          - 'barycentric', 'krog', 'pchip', 'spline': use their respective\n",
      " |            ``scipy.interpolate`` classes.\n",
      " |      use_coordinate : boolean or str, default True\n",
      " |          Specifies which index to use as the x values in the interpolation\n",
      " |          formulated as `y = f(x)`. If False, values are treated as if\n",
      " |          eqaully-spaced along `dim`. If True, the IndexVariable `dim` is\n",
      " |          used. If use_coordinate is a string, it specifies the name of a\n",
      " |          coordinate variariable to use as the index.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0\n",
      " |          or None for no limit.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.interp\n",
      " |      scipy.interpolate\n",
      " |  \n",
      " |  isel(self, indexers=None, drop=False, **indexers_kwargs)\n",
      " |      Returns a new dataset with each array indexed along the specified\n",
      " |      dimension(s).\n",
      " |      \n",
      " |      This method selects values from each array using its `__getitem__`\n",
      " |      method, except this method does not require knowing the order of\n",
      " |      each array's dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indexers : dict, optional\n",
      " |          A dict with keys matching dimensions and values given\n",
      " |          by integers, slice objects or arrays.\n",
      " |          indexer can be a integer, slice, array-like or DataArray.\n",
      " |          If DataArrays are passed as indexers, xarray-style indexing will be\n",
      " |          carried out. See :ref:`indexing` for the details.\n",
      " |          One of indexers or indexers_kwargs must be provided.\n",
      " |      drop : bool, optional\n",
      " |          If ``drop=True``, drop coordinates variables indexed by integers\n",
      " |          instead of making them scalar.\n",
      " |      **indexers_kwarg : {dim: indexer, ...}, optional\n",
      " |          The keyword arguments form of ``indexers``.\n",
      " |          One of indexers or indexers_kwargs must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : Dataset\n",
      " |          A new Dataset with the same contents as this dataset, except each\n",
      " |          array and dimension is indexed by the appropriate indexers.\n",
      " |          If indexer DataArrays have coordinates that do not conflict with\n",
      " |          this object, then these coordinates will be attached.\n",
      " |          In general, each array's data will be a view of the array's data\n",
      " |          in this dataset, unless vectorized indexing was triggered by using\n",
      " |          an array indexer, in which case the data will be a copy.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.sel\n",
      " |      DataArray.isel\n",
      " |  \n",
      " |  isel_points(self, dim='points', **indexers)\n",
      " |      Returns a new dataset with each array indexed pointwise along the\n",
      " |      specified dimension(s).\n",
      " |      \n",
      " |      This method selects pointwise values from each array and is akin to\n",
      " |      the NumPy indexing behavior of `arr[[0, 1], [0, 1]]`, except this\n",
      " |      method does not require knowing the order of each array's dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or DataArray or pandas.Index or other list-like object, optional\n",
      " |          Name of the dimension to concatenate along. If dim is provided as a\n",
      " |          string, it must be a new dimension name, in which case it is added\n",
      " |          along axis=0. If dim is provided as a DataArray or Index or\n",
      " |          list-like object, its name, which must not be present in the\n",
      " |          dataset, is used as the dimension to concatenate along and the\n",
      " |          values are added as a coordinate.\n",
      " |      **indexers : {dim: indexer, ...}\n",
      " |          Keyword arguments with names matching dimensions and values given\n",
      " |          by array-like objects. All indexers must be the same length and\n",
      " |          1 dimensional.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : Dataset\n",
      " |          A new Dataset with the same contents as this dataset, except each\n",
      " |          array and dimension is indexed by the appropriate indexers. With\n",
      " |          pointwise indexing, the new Dataset will always be a copy of the\n",
      " |          original.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.sel\n",
      " |      Dataset.isel\n",
      " |      Dataset.sel_points\n",
      " |      DataArray.isel_points\n",
      " |  \n",
      " |  isnull(self, *args, **kwargs)\n",
      " |  \n",
      " |  load(self, **kwargs)\n",
      " |      Manually trigger loading of this dataset's data from disk or a\n",
      " |      remote source into memory and return this dataset.\n",
      " |      \n",
      " |      Normally, it should not be necessary to call this method in user code,\n",
      " |      because all xarray functions should either work on deferred data or\n",
      " |      load data automatically. However, this method can be necessary when\n",
      " |      working with many file objects on disk.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to ``dask.array.compute``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dask.array.compute\n",
      " |  \n",
      " |  max(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `max` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `max`.  By default `max` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `max` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `max` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  mean(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `mean` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `mean`.  By default `mean` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `mean` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `mean` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  median(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `median` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `median`.  By default `median` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `median` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `median` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  merge(self, other, inplace=False, overwrite_vars=frozenset(), compat='no_conflicts', join='outer')\n",
      " |      Merge the arrays of two datasets into a single dataset.\n",
      " |      \n",
      " |      This method generally not allow for overriding data, with the exception\n",
      " |      of attributes, which are ignored on the second dataset. Variables with\n",
      " |      the same name are checked for conflicts via the equals or identical\n",
      " |      methods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Dataset or castable to Dataset\n",
      " |          Dataset or variables to merge with this dataset.\n",
      " |      inplace : bool, optional\n",
      " |          If True, merge the other dataset into this dataset in-place.\n",
      " |          Otherwise, return a new dataset object.\n",
      " |      overwrite_vars : str or sequence, optional\n",
      " |          If provided, update variables of these name(s) without checking for\n",
      " |          conflicts in this dataset.\n",
      " |      compat : {'broadcast_equals', 'equals', 'identical',\n",
      " |                'no_conflicts'}, optional\n",
      " |          String indicating how to compare variables of the same name for\n",
      " |          potential conflicts:\n",
      " |      \n",
      " |          - 'broadcast_equals': all values must be equal when variables are\n",
      " |            broadcast against each other to ensure common dimensions.\n",
      " |          - 'equals': all values and dimensions must be the same.\n",
      " |          - 'identical': all values, dimensions and attributes must be the\n",
      " |            same.\n",
      " |          - 'no_conflicts': only values which are not null in both datasets\n",
      " |            must be equal. The returned dataset then contains the combination\n",
      " |            of all non-null values.\n",
      " |      join : {'outer', 'inner', 'left', 'right', 'exact'}, optional\n",
      " |          Method for joining ``self`` and ``other`` along shared dimensions:\n",
      " |      \n",
      " |          - 'outer': use the union of the indexes\n",
      " |          - 'inner': use the intersection of the indexes\n",
      " |          - 'left': use indexes from ``self``\n",
      " |          - 'right': use indexes from ``other``\n",
      " |          - 'exact': error instead of aligning non-equal indexes\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      merged : Dataset\n",
      " |          Merged dataset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      MergeError\n",
      " |          If any variables conflict (see ``compat``).\n",
      " |  \n",
      " |  min(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `min` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `min`.  By default `min` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `min` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `min` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  notnull(self, *args, **kwargs)\n",
      " |  \n",
      " |  persist(self, **kwargs)\n",
      " |      Trigger computation, keeping data as dask arrays\n",
      " |      \n",
      " |      This operation can be used to trigger computation on underlying dask\n",
      " |      arrays, similar to ``.compute()``.  However this operation keeps the\n",
      " |      data as dask arrays.  This is particularly useful when using the\n",
      " |      dask.distributed scheduler and you want to load a large amount of data\n",
      " |      into distributed memory.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to ``dask.persist``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dask.persist\n",
      " |  \n",
      " |  prod(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `prod` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `prod`.  By default `prod` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `prod` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `prod` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  quantile(self, q, dim=None, interpolation='linear', numeric_only=False, keep_attrs=False)\n",
      " |      Compute the qth quantile of the data along the specified dimension.\n",
      " |      \n",
      " |      Returns the qth quantiles(s) of the array elements for each variable\n",
      " |      in the Dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float in range of [0,1] (or sequence of floats)\n",
      " |          Quantile to compute, which must be between 0 and 1 inclusive.\n",
      " |      dim : str or sequence of str, optional\n",
      " |          Dimension(s) over which to apply quantile.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to\n",
      " |          use when the desired quantile lies between two data points\n",
      " |          ``i < j``:\n",
      " |      \n",
      " |              * linear: ``i + (j - i) * fraction``, where ``fraction`` is\n",
      " |                the fractional part of the index surrounded by ``i`` and\n",
      " |                ``j``.\n",
      " |              * lower: ``i``.\n",
      " |              * higher: ``j``.\n",
      " |              * nearest: ``i`` or ``j``, whichever is nearest.\n",
      " |              * midpoint: ``(i + j) / 2``.\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the dataset's attributes (`attrs`) will be copied from\n",
      " |          the original object to the new one.  If False (default), the new\n",
      " |          object will be returned without attributes.\n",
      " |      numeric_only : bool, optional\n",
      " |          If True, only apply ``func`` to variables with a numeric dtype.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Dataset\n",
      " |          If `q` is a single quantile, then the result is a scalar for each\n",
      " |          variable in data_vars. If multiple percentiles are given, first\n",
      " |          axis of the result corresponds to the quantile and a quantile\n",
      " |          dimension is added to the return Dataset. The other dimensions are\n",
      " |          the dimensions that remain after the reduction of the array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nanpercentile, pandas.Series.quantile, DataArray.quantile\n",
      " |  \n",
      " |  rank(self, dim, pct=False, keep_attrs=False)\n",
      " |      Ranks the data.\n",
      " |      \n",
      " |      Equal values are assigned a rank that is the average of the ranks that\n",
      " |      would have been otherwise assigned to all of the values within that set.\n",
      " |      Ranks begin at 1, not 0. If pct is True, computes percentage ranks.\n",
      " |      \n",
      " |      NaNs in the input array are returned as NaNs.\n",
      " |      \n",
      " |      The `bottleneck` library is required.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str\n",
      " |          Dimension over which to compute rank.\n",
      " |      pct : bool, optional\n",
      " |          If True, compute percentage ranks, otherwise compute integer ranks.\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the dataset's attributes (`attrs`) will be copied from\n",
      " |          the original object to the new one.  If False (default), the new\n",
      " |          object will be returned without attributes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranked : Dataset\n",
      " |          Variables that do not depend on `dim` are dropped.\n",
      " |  \n",
      " |  reduce(self, func, dim=None, keep_attrs=False, numeric_only=False, allow_lazy=False, **kwargs)\n",
      " |      Reduce this dataset by applying `func` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function which can be called in the form\n",
      " |          `f(x, axis=axis, **kwargs)` to return the result of reducing an\n",
      " |          np.ndarray over an integer valued axis.\n",
      " |      dim : str or sequence of str, optional\n",
      " |          Dimension(s) over which to apply `func`.  By default `func` is\n",
      " |          applied over all dimensions.\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the dataset's attributes (`attrs`) will be copied from\n",
      " |          the original object to the new one.  If False (default), the new\n",
      " |          object will be returned without attributes.\n",
      " |      numeric_only : bool, optional\n",
      " |          If True, only apply ``func`` to variables with a numeric dtype.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          Dataset with this object's DataArrays replaced with new DataArrays\n",
      " |          of summarized data and the indicated dimension(s) removed.\n",
      " |  \n",
      " |  reindex(self, indexers=None, method=None, tolerance=None, copy=True, **indexers_kwargs)\n",
      " |      Conform this object onto a new set of indexes, filling in\n",
      " |      missing values with NaN.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indexers : dict. optional\n",
      " |          Dictionary with keys given by dimension names and values given by\n",
      " |          arrays of coordinates tick labels. Any mis-matched coordinate values\n",
      " |          will be filled in with NaN, and any mis-matched dimension names will\n",
      " |          simply be ignored.\n",
      " |          One of indexers or indexers_kwargs must be provided.\n",
      " |      method : {None, 'nearest', 'pad'/'ffill', 'backfill'/'bfill'}, optional\n",
      " |          Method to use for filling index values in ``indexers`` not found in\n",
      " |          this dataset:\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid index value forward\n",
      " |          * backfill / bfill: propagate next valid index value backward\n",
      " |          * nearest: use nearest valid index value (requires pandas>=0.16)\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |          Requires pandas>=0.17.\n",
      " |      copy : bool, optional\n",
      " |          If ``copy=True``, data in the return value is always copied. If\n",
      " |          ``copy=False`` and reindexing is unnecessary, or can be performed\n",
      " |          with only slice operations, then the output may share memory with\n",
      " |          the input. In either case, a new xarray object is always returned.\n",
      " |      **indexers_kwarg : {dim: indexer, ...}, optional\n",
      " |          Keyword arguments in the same form as ``indexers``.\n",
      " |          One of indexers or indexers_kwargs must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Dataset\n",
      " |          Another dataset, with this dataset's data but replaced coordinates.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.reindex_like\n",
      " |      align\n",
      " |      pandas.Index.get_indexer\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, tolerance=None, copy=True)\n",
      " |      Conform this object onto the indexes of another object, filling\n",
      " |      in missing values with NaN.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Dataset or DataArray\n",
      " |          Object with an 'indexes' attribute giving a mapping from dimension\n",
      " |          names to pandas.Index objects, which provides coordinates upon\n",
      " |          which to index the variables in this dataset. The indexes on this\n",
      " |          other object need not be the same as the indexes on this\n",
      " |          dataset. Any mis-matched index values will be filled in with\n",
      " |          NaN, and any mis-matched dimension names will simply be ignored.\n",
      " |      method : {None, 'nearest', 'pad'/'ffill', 'backfill'/'bfill'}, optional\n",
      " |          Method to use for filling index values from other not found in this\n",
      " |          dataset:\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid index value forward\n",
      " |          * backfill / bfill: propagate next valid index value backward\n",
      " |          * nearest: use nearest valid index value (requires pandas>=0.16)\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |          Requires pandas>=0.17.\n",
      " |      copy : bool, optional\n",
      " |          If ``copy=True``, data in the return value is always copied. If\n",
      " |          ``copy=False`` and reindexing is unnecessary, or can be performed\n",
      " |          with only slice operations, then the output may share memory with\n",
      " |          the input. In either case, a new xarray object is always returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Dataset\n",
      " |          Another dataset, with this dataset's data but coordinates from the\n",
      " |          other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.reindex\n",
      " |      align\n",
      " |  \n",
      " |  rename(self, name_dict=None, inplace=False, **names)\n",
      " |      Returns a new object with renamed variables and dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name_dict : dict-like, optional\n",
      " |          Dictionary whose keys are current variable or dimension names and\n",
      " |          whose values are the desired names.\n",
      " |      inplace : bool, optional\n",
      " |          If True, rename variables and dimensions in-place. Otherwise,\n",
      " |          return a new dataset object.\n",
      " |      **names, optional\n",
      " |          Keyword form of ``name_dict``.\n",
      " |          One of name_dict or names must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Dataset\n",
      " |          Dataset with renamed variables and dimensions.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.swap_dims\n",
      " |      DataArray.rename\n",
      " |  \n",
      " |  reorder_levels(self, dim_order=None, inplace=False, **dim_order_kwargs)\n",
      " |      Rearrange index levels using input order.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim_order : optional\n",
      " |          Mapping from names matching dimensions and values given\n",
      " |          by lists representing new level orders. Every given dimension\n",
      " |          must have a multi-index.\n",
      " |      inplace : bool, optional\n",
      " |          If True, modify the dataset in-place. Otherwise, return a new\n",
      " |          DataArray object.\n",
      " |      **dim_order_kwargs: optional\n",
      " |          The keyword arguments form of ``dim_order``.\n",
      " |          One of dim_order or dim_order_kwargs must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : Dataset\n",
      " |          Another dataset, with this dataset's data but replaced\n",
      " |          coordinates.\n",
      " |  \n",
      " |  reset_coords(self, names=None, drop=False, inplace=False)\n",
      " |      Given names of coordinates, reset them to become variables\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      names : str or list of str, optional\n",
      " |          Name(s) of non-index coordinates in this dataset to reset into\n",
      " |          variables. By default, all non-index coordinates are reset.\n",
      " |      drop : bool, optional\n",
      " |          If True, remove coordinates instead of converting them into\n",
      " |          variables.\n",
      " |      inplace : bool, optional\n",
      " |          If True, modify this dataset inplace. Otherwise, create a new\n",
      " |          object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |  \n",
      " |  reset_index(self, dims_or_levels, drop=False, inplace=False)\n",
      " |      Reset the specified index(es) or multi-index level(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dims_or_levels : str or list\n",
      " |          Name(s) of the dimension(s) and/or multi-index level(s) that will\n",
      " |          be reset.\n",
      " |      drop : bool, optional\n",
      " |          If True, remove the specified indexes and/or multi-index levels\n",
      " |          instead of extracting them as new coordinates (default: False).\n",
      " |      inplace : bool, optional\n",
      " |          If True, modify the dataset in-place. Otherwise, return a new\n",
      " |          Dataset object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : Dataset\n",
      " |          Another dataset, with this dataset's data but replaced coordinates.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.set_index\n",
      " |  \n",
      " |  roll(self, shifts=None, roll_coords=None, **shifts_kwargs)\n",
      " |      Roll this dataset by an offset along one or more dimensions.\n",
      " |      \n",
      " |      Unlike shift, roll may rotate all variables, including coordinates\n",
      " |      if specified. The direction of rotation is consistent with\n",
      " |      :py:func:`numpy.roll`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      shifts : dict, optional\n",
      " |          A dict with keys matching dimensions and values given\n",
      " |          by integers to rotate each of the given dimensions. Positive\n",
      " |          offsets roll to the right; negative offsets roll to the left.\n",
      " |      roll_coords : bool\n",
      " |          Indicates whether to  roll the coordinates by the offset\n",
      " |          The current default of roll_coords (None, equivalent to True) is\n",
      " |          deprecated and will change to False in a future version.\n",
      " |          Explicitly pass roll_coords to silence the warning.\n",
      " |      **shifts_kwargs : {dim: offset, ...}, optional\n",
      " |          The keyword arguments form of ``shifts``.\n",
      " |          One of shifts or shifts_kwargs must be provided.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      rolled : Dataset\n",
      " |          Dataset with the same coordinates and attributes but rolled\n",
      " |          variables.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      shift\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> ds = xr.Dataset({'foo': ('x', list('abcde'))})\n",
      " |      >>> ds.roll(x=2)\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (x: 5)\n",
      " |      Coordinates:\n",
      " |        * x        (x) int64 3 4 0 1 2\n",
      " |      Data variables:\n",
      " |          foo      (x) object 'd' 'e' 'a' 'b' 'c'\n",
      " |  \n",
      " |  round(self, *args, **kwargs)\n",
      " |  \n",
      " |  sel(self, indexers=None, method=None, tolerance=None, drop=False, **indexers_kwargs)\n",
      " |      Returns a new dataset with each array indexed by tick labels\n",
      " |      along the specified dimension(s).\n",
      " |      \n",
      " |      In contrast to `Dataset.isel`, indexers for this method should use\n",
      " |      labels instead of integers.\n",
      " |      \n",
      " |      Under the hood, this method is powered by using pandas's powerful Index\n",
      " |      objects. This makes label based indexing essentially just as fast as\n",
      " |      using integer indexing.\n",
      " |      \n",
      " |      It also means this method uses pandas's (well documented) logic for\n",
      " |      indexing. This means you can use string shortcuts for datetime indexes\n",
      " |      (e.g., '2000-01' to select all values in January 2000). It also means\n",
      " |      that slices are treated as inclusive of both the start and stop values,\n",
      " |      unlike normal Python indexing.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indexers : dict, optional\n",
      " |          A dict with keys matching dimensions and values given\n",
      " |          by scalars, slices or arrays of tick labels. For dimensions with\n",
      " |          multi-index, the indexer may also be a dict-like object with keys\n",
      " |          matching index level names.\n",
      " |          If DataArrays are passed as indexers, xarray-style indexing will be\n",
      " |          carried out. See :ref:`indexing` for the details.\n",
      " |          One of indexers or indexers_kwargs must be provided.\n",
      " |      method : {None, 'nearest', 'pad'/'ffill', 'backfill'/'bfill'}, optional\n",
      " |          Method to use for inexact matches (requires pandas>=0.16):\n",
      " |      \n",
      " |          * None (default): only exact matches\n",
      " |          * pad / ffill: propagate last valid index value forward\n",
      " |          * backfill / bfill: propagate next valid index value backward\n",
      " |          * nearest: use nearest valid index value\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |          Requires pandas>=0.17.\n",
      " |      drop : bool, optional\n",
      " |          If ``drop=True``, drop coordinates variables in `indexers` instead\n",
      " |          of making them scalar.\n",
      " |      **indexers_kwarg : {dim: indexer, ...}, optional\n",
      " |          The keyword arguments form of ``indexers``.\n",
      " |          One of indexers or indexers_kwargs must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : Dataset\n",
      " |          A new Dataset with the same contents as this dataset, except each\n",
      " |          variable and dimension is indexed by the appropriate indexers.\n",
      " |          If indexer DataArrays have coordinates that do not conflict with\n",
      " |          this object, then these coordinates will be attached.\n",
      " |          In general, each array's data will be a view of the array's data\n",
      " |          in this dataset, unless vectorized indexing was triggered by using\n",
      " |          an array indexer, in which case the data will be a copy.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.isel\n",
      " |      DataArray.sel\n",
      " |  \n",
      " |  sel_points(self, dim='points', method=None, tolerance=None, **indexers)\n",
      " |      Returns a new dataset with each array indexed pointwise by tick\n",
      " |      labels along the specified dimension(s).\n",
      " |      \n",
      " |      In contrast to `Dataset.isel_points`, indexers for this method should\n",
      " |      use labels instead of integers.\n",
      " |      \n",
      " |      In contrast to `Dataset.sel`, this method selects points along the\n",
      " |      diagonal of multi-dimensional arrays, not the intersection.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or DataArray or pandas.Index or other list-like object, optional\n",
      " |          Name of the dimension to concatenate along. If dim is provided as a\n",
      " |          string, it must be a new dimension name, in which case it is added\n",
      " |          along axis=0. If dim is provided as a DataArray or Index or\n",
      " |          list-like object, its name, which must not be present in the\n",
      " |          dataset, is used as the dimension to concatenate along and the\n",
      " |          values are added as a coordinate.\n",
      " |      method : {None, 'nearest', 'pad'/'ffill', 'backfill'/'bfill'}, optional\n",
      " |          Method to use for inexact matches (requires pandas>=0.16):\n",
      " |      \n",
      " |          * None (default): only exact matches\n",
      " |          * pad / ffill: propagate last valid index value forward\n",
      " |          * backfill / bfill: propagate next valid index value backward\n",
      " |          * nearest: use nearest valid index value\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |          Requires pandas>=0.17.\n",
      " |      **indexers : {dim: indexer, ...}\n",
      " |          Keyword arguments with names matching dimensions and values given\n",
      " |          by array-like objects. All indexers must be the same length and\n",
      " |          1 dimensional.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : Dataset\n",
      " |          A new Dataset with the same contents as this dataset, except each\n",
      " |          array and dimension is indexed by the appropriate indexers. With\n",
      " |          pointwise indexing, the new Dataset will always be a copy of the\n",
      " |          original.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.sel\n",
      " |      Dataset.isel\n",
      " |      Dataset.isel_points\n",
      " |      DataArray.sel_points\n",
      " |  \n",
      " |  set_coords(self, names, inplace=False)\n",
      " |      Given names of one or more variables, set them as coordinates\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      names : str or list of str\n",
      " |          Name(s) of variables in this dataset to convert into coordinates.\n",
      " |      inplace : bool, optional\n",
      " |          If True, modify this dataset inplace. Otherwise, create a new\n",
      " |          object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |  \n",
      " |  set_index(self, indexes=None, append=False, inplace=False, **indexes_kwargs)\n",
      " |      Set Dataset (multi-)indexes using one or more existing coordinates or\n",
      " |      variables.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indexes : {dim: index, ...}\n",
      " |          Mapping from names matching dimensions and values given\n",
      " |          by (lists of) the names of existing coordinates or variables to set\n",
      " |          as new (multi-)index.\n",
      " |      append : bool, optional\n",
      " |          If True, append the supplied index(es) to the existing index(es).\n",
      " |          Otherwise replace the existing index(es) (default).\n",
      " |      inplace : bool, optional\n",
      " |          If True, set new index(es) in-place. Otherwise, return a new\n",
      " |          Dataset object.\n",
      " |      **indexes_kwargs: optional\n",
      " |          The keyword arguments form of ``indexes``.\n",
      " |          One of indexes or indexes_kwargs must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : Dataset\n",
      " |          Another dataset, with this dataset's data but replaced coordinates.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataset.reset_index\n",
      " |  \n",
      " |  shift(self, shifts=None, **shifts_kwargs)\n",
      " |      Shift this dataset by an offset along one or more dimensions.\n",
      " |      \n",
      " |      Only data variables are moved; coordinates stay in place. This is\n",
      " |      consistent with the behavior of ``shift`` in pandas.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      shifts : Mapping with the form of {dim: offset}\n",
      " |          Integer offset to shift along each of the given dimensions.\n",
      " |          Positive offsets shift to the right; negative offsets shift to the\n",
      " |          left.\n",
      " |      **shifts_kwargs:\n",
      " |          The keyword arguments form of ``shifts``.\n",
      " |          One of shifts or shifts_kwarg must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Dataset\n",
      " |          Dataset with the same coordinates and attributes but shifted data\n",
      " |          variables.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      roll\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> ds = xr.Dataset({'foo': ('x', list('abcde'))})\n",
      " |      >>> ds.shift(x=2)\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (x: 5)\n",
      " |      Coordinates:\n",
      " |        * x        (x) int64 0 1 2 3 4\n",
      " |      Data variables:\n",
      " |          foo      (x) object nan nan 'a' 'b' 'c'\n",
      " |  \n",
      " |  sortby(self, variables, ascending=True)\n",
      " |      Sort object by labels or values (along an axis).\n",
      " |      \n",
      " |      Sorts the dataset, either along specified dimensions,\n",
      " |      or according to values of 1-D dataarrays that share dimension\n",
      " |      with calling object.\n",
      " |      \n",
      " |      If the input variables are dataarrays, then the dataarrays are aligned\n",
      " |      (via left-join) to the calling object prior to sorting by cell values.\n",
      " |      NaNs are sorted to the end, following Numpy convention.\n",
      " |      \n",
      " |      If multiple sorts along the same dimension is\n",
      " |      given, numpy's lexsort is performed along that dimension:\n",
      " |      https://docs.scipy.org/doc/numpy/reference/generated/numpy.lexsort.html\n",
      " |      and the FIRST key in the sequence is used as the primary sort key,\n",
      " |      followed by the 2nd key, etc.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      variables: str, DataArray, or list of either\n",
      " |          1D DataArray objects or name(s) of 1D variable(s) in\n",
      " |          coords/data_vars whose values are used to sort the dataset.\n",
      " |      ascending: boolean, optional\n",
      " |          Whether to sort by ascending or descending order.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted: Dataset\n",
      " |          A new dataset where all the specified dims are sorted by dim\n",
      " |          labels.\n",
      " |  \n",
      " |  stack(self, dimensions=None, **dimensions_kwargs)\n",
      " |      Stack any number of existing dimensions into a single new dimension.\n",
      " |      \n",
      " |      New dimensions will be added at the end, and the corresponding\n",
      " |      coordinate variables will be combined into a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dimensions : Mapping of the form new_name=(dim1, dim2, ...)\n",
      " |          Names of new dimensions, and the existing dimensions that they\n",
      " |          replace.\n",
      " |      **dimensions_kwargs:\n",
      " |          The keyword arguments form of ``dimensions``.\n",
      " |          One of dimensions or dimensions_kwargs must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stacked : Dataset\n",
      " |          Dataset with stacked data.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Dataset.unstack\n",
      " |  \n",
      " |  std(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `std` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `std`.  By default `std` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `std` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `std` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  sum(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `sum` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `sum`.  By default `sum` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      min_count : int, default None\n",
      " |          The required number of valid values to perform the operation.\n",
      " |          If fewer than min_count non-NA values are present the result will\n",
      " |          be NA. New in version 0.10.8: Added with the default being None.\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `sum` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `sum` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  swap_dims(self, dims_dict, inplace=False)\n",
      " |      Returns a new object with swapped dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dims_dict : dict-like\n",
      " |          Dictionary whose keys are current dimension names and whose values\n",
      " |          are new names. Each value must already be a variable in the\n",
      " |          dataset.\n",
      " |      inplace : bool, optional\n",
      " |          If True, swap dimensions in-place. Otherwise, return a new dataset\n",
      " |          object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Dataset\n",
      " |          Dataset with swapped dimensions.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      \n",
      " |      Dataset.rename\n",
      " |      DataArray.swap_dims\n",
      " |  \n",
      " |  to_array(self, dim='variable', name=None)\n",
      " |      Convert this dataset into an xarray.DataArray\n",
      " |      \n",
      " |      The data variables of this dataset will be broadcast against each other\n",
      " |      and stacked along the first axis of the new array. All coordinates of\n",
      " |      this dataset will remain coordinates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str, optional\n",
      " |          Name of the new dimension.\n",
      " |      name : str, optional\n",
      " |          Name of the new data array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array : xarray.DataArray\n",
      " |  \n",
      " |  to_dask_dataframe(self, dim_order=None, set_index=False)\n",
      " |      Convert this dataset into a dask.dataframe.DataFrame.\n",
      " |      \n",
      " |      The dimensions, coordinates and data variables in this dataset form\n",
      " |      the columns of the DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim_order : list, optional\n",
      " |          Hierarchical dimension order for the resulting dataframe. All\n",
      " |          arrays are transposed to this order and then written out as flat\n",
      " |          vectors in contiguous order, so the last dimension in this list\n",
      " |          will be contiguous in the resulting DataFrame. This has a major\n",
      " |          influence on which operations are efficient on the resulting dask\n",
      " |          dataframe.\n",
      " |      \n",
      " |          If provided, must include all dimensions on this dataset. By\n",
      " |          default, dimensions are sorted alphabetically.\n",
      " |      set_index : bool, optional\n",
      " |          If set_index=True, the dask DataFrame is indexed by this dataset's\n",
      " |          coordinate. Since dask DataFrames to not support multi-indexes,\n",
      " |          set_index only works if the dataset only contains one dimension.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dask.dataframe.DataFrame\n",
      " |  \n",
      " |  to_dataframe(self)\n",
      " |      Convert this dataset into a pandas.DataFrame.\n",
      " |      \n",
      " |      Non-index variables in this dataset form the columns of the\n",
      " |      DataFrame. The DataFrame is be indexed by the Cartesian product of\n",
      " |      this dataset's indices.\n",
      " |  \n",
      " |  to_dict(self)\n",
      " |      Convert this dataset to a dictionary following xarray naming\n",
      " |      conventions.\n",
      " |      \n",
      " |      Converts all variables and attributes to native Python objects\n",
      " |      Useful for coverting to json. To avoid datetime incompatibility\n",
      " |      use decode_times=False kwarg in xarrray.open_dataset.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Dataset.from_dict\n",
      " |  \n",
      " |  to_netcdf(self, path=None, mode='w', format=None, group=None, engine=None, encoding=None, unlimited_dims=None, compute=True)\n",
      " |      Write dataset contents to a netCDF file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, Path or file-like object, optional\n",
      " |          Path to which to save this dataset. File-like objects are only\n",
      " |          supported by the scipy engine. If no path is provided, this\n",
      " |          function returns the resulting netCDF file as bytes; in this case,\n",
      " |          we need to use scipy, which does not support netCDF version 4 (the\n",
      " |          default format becomes NETCDF3_64BIT).\n",
      " |      mode : {'w', 'a'}, optional\n",
      " |          Write ('w') or append ('a') mode. If mode='w', any existing file at\n",
      " |          this location will be overwritten. If mode='a', existing variables\n",
      " |          will be overwritten.\n",
      " |      format : {'NETCDF4', 'NETCDF4_CLASSIC', 'NETCDF3_64BIT','NETCDF3_CLASSIC'}, optional\n",
      " |          File format for the resulting netCDF file:\n",
      " |      \n",
      " |          * NETCDF4: Data is stored in an HDF5 file, using netCDF4 API\n",
      " |            features.\n",
      " |          * NETCDF4_CLASSIC: Data is stored in an HDF5 file, using only\n",
      " |            netCDF 3 compatible API features.\n",
      " |          * NETCDF3_64BIT: 64-bit offset version of the netCDF 3 file format,\n",
      " |            which fully supports 2+ GB files, but is only compatible with\n",
      " |            clients linked against netCDF version 3.6.0 or later.\n",
      " |          * NETCDF3_CLASSIC: The classic netCDF 3 file format. It does not\n",
      " |            handle 2+ GB files very well.\n",
      " |      \n",
      " |          All formats are supported by the netCDF4-python library.\n",
      " |          scipy.io.netcdf only supports the last two formats.\n",
      " |      \n",
      " |          The default format is NETCDF4 if you are saving a file to disk and\n",
      " |          have the netCDF4-python library available. Otherwise, xarray falls\n",
      " |          back to using scipy to write netCDF files and defaults to the\n",
      " |          NETCDF3_64BIT format (scipy does not support netCDF4).\n",
      " |      group : str, optional\n",
      " |          Path to the netCDF4 group in the given file to open (only works for\n",
      " |          format='NETCDF4'). The group(s) will be created if necessary.\n",
      " |      engine : {'netcdf4', 'scipy', 'h5netcdf'}, optional\n",
      " |          Engine to use when writing netCDF files. If not provided, the\n",
      " |          default engine is chosen based on available dependencies, with a\n",
      " |          preference for 'netcdf4' if writing to a file on disk.\n",
      " |      encoding : dict, optional\n",
      " |          Nested dictionary with variable names as keys and dictionaries of\n",
      " |          variable specific encodings as values, e.g.,\n",
      " |          ``{'my_variable': {'dtype': 'int16', 'scale_factor': 0.1,\n",
      " |                             'zlib': True}, ...}``\n",
      " |      \n",
      " |          The `h5netcdf` engine supports both the NetCDF4-style compression\n",
      " |          encoding parameters ``{'zlib': True, 'complevel': 9}`` and the h5py\n",
      " |          ones ``{'compression': 'gzip', 'compression_opts': 9}``.\n",
      " |          This allows using any compression plugin installed in the HDF5\n",
      " |          library, e.g. LZF.\n",
      " |      \n",
      " |      unlimited_dims : sequence of str, optional\n",
      " |          Dimension(s) that should be serialized as unlimited dimensions.\n",
      " |          By default, no dimensions are treated as unlimited dimensions.\n",
      " |          Note that unlimited_dims may also be set via\n",
      " |          ``dataset.encoding['unlimited_dims']``.\n",
      " |      compute: boolean\n",
      " |          If true compute immediately, otherwise return a\n",
      " |          ``dask.delayed.Delayed`` object that can be computed later.\n",
      " |  \n",
      " |  to_zarr(self, store=None, mode='w-', synchronizer=None, group=None, encoding=None, compute=True)\n",
      " |      Write dataset contents to a zarr group.\n",
      " |      \n",
      " |      .. note:: Experimental\n",
      " |                The Zarr backend is new and experimental. Please report any\n",
      " |                unexpected behavior via github issues.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      store : MutableMapping or str, optional\n",
      " |          Store or path to directory in file system.\n",
      " |      mode : {'w', 'w-'}\n",
      " |          Persistence mode: 'w' means create (overwrite if exists);\n",
      " |          'w-' means create (fail if exists).\n",
      " |      synchronizer : object, optional\n",
      " |          Array synchronizer\n",
      " |      group : str, obtional\n",
      " |          Group path. (a.k.a. `path` in zarr terminology.)\n",
      " |      encoding : dict, optional\n",
      " |          Nested dictionary with variable names as keys and dictionaries of\n",
      " |          variable specific encodings as values, e.g.,\n",
      " |          ``{'my_variable': {'dtype': 'int16', 'scale_factor': 0.1,}, ...}``\n",
      " |      compute: boolean\n",
      " |          If true compute immediately, otherwise return a\n",
      " |          ``dask.delayed.Delayed`` object that can be computed later.\n",
      " |  \n",
      " |  transpose(self, *dims)\n",
      " |      Return a new Dataset object with all array dimensions transposed.\n",
      " |      \n",
      " |      Although the order of dimensions on each array will change, the dataset\n",
      " |      dimensions themselves will remain in fixed (sorted) order.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *dims : str, optional\n",
      " |          By default, reverse the dimensions on each array. Otherwise,\n",
      " |          reorder the dimensions to this order.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transposed : Dataset\n",
      " |          Each array in the dataset (including) coordinates will be\n",
      " |          transposed to the given order.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Although this operation returns a view of each array's data, it\n",
      " |      is not lazy -- the data will be fully loaded into memory.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose\n",
      " |      DataArray.transpose\n",
      " |  \n",
      " |  unstack(self, dim=None)\n",
      " |      Unstack existing dimensions corresponding to MultiIndexes into\n",
      " |      multiple new dimensions.\n",
      " |      \n",
      " |      New dimensions will be added at the end.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |          Dimension(s) over which to unstack. By default unstacks all\n",
      " |          MultiIndexes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : Dataset\n",
      " |          Dataset with unstacked data.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Dataset.stack\n",
      " |  \n",
      " |  update(self, other, inplace=True)\n",
      " |      Update this dataset's variables with those from another dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Dataset or castable to Dataset\n",
      " |          Dataset or variables with which to update this dataset.\n",
      " |      inplace : bool, optional\n",
      " |          If True, merge the other dataset into this dataset in-place.\n",
      " |          Otherwise, return a new dataset object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      updated : Dataset\n",
      " |          Updated dataset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If any dimensions would have inconsistent sizes in the updated\n",
      " |          dataset.\n",
      " |  \n",
      " |  var(self, dim=None, keep_attrs=False, skipna=None, **kwargs)\n",
      " |      Reduce this Dataset's data by applying `var` along some dimension(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : str or sequence of str, optional\n",
      " |                  Dimension(s) over which to apply `var`.  By default `var` is\n",
      " |                  applied over all dimensions.\n",
      " |      skipna : bool, optional\n",
      " |          If True, skip missing values (as marked by NaN). By default, only\n",
      " |          skips missing values for float dtypes; other dtypes either do not\n",
      " |          have a sentinel missing value (int) or skipna=True has not been\n",
      " |          implemented (object, datetime64 or timedelta64).\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the attributes (`attrs`) will be copied from the original\n",
      " |          object to the new one.  If False (default), the new object will be\n",
      " |          returned without attributes.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments passed on to the appropriate array\n",
      " |          function for calculating `var` on this object's data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reduced : Dataset\n",
      " |          New Dataset object with `var` applied to its data and the\n",
      " |          indicated dimension(s) removed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dataframe(dataframe) from abc.ABCMeta\n",
      " |      Convert a pandas.DataFrame into an xarray.Dataset\n",
      " |      \n",
      " |      Each column will be converted into an independent variable in the\n",
      " |      Dataset. If the dataframe's index is a MultiIndex, it will be expanded\n",
      " |      into a tensor product of one-dimensional indices (filling in missing\n",
      " |      values with NaN). This method will produce a Dataset very similar to\n",
      " |      that on which the 'to_dataframe' method was called, except with\n",
      " |      possibly redundant dimensions (since all dataset variables will have\n",
      " |      the same dimensionality).\n",
      " |  \n",
      " |  from_dict(d) from abc.ABCMeta\n",
      " |      Convert a dictionary into an xarray.Dataset.\n",
      " |      \n",
      " |      Input dict can take several forms::\n",
      " |      \n",
      " |          d = {'t': {'dims': ('t'), 'data': t},\n",
      " |               'a': {'dims': ('t'), 'data': x},\n",
      " |               'b': {'dims': ('t'), 'data': y}}\n",
      " |      \n",
      " |          d = {'coords': {'t': {'dims': 't', 'data': t,\n",
      " |                                'attrs': {'units':'s'}}},\n",
      " |               'attrs': {'title': 'air temperature'},\n",
      " |               'dims': 't',\n",
      " |               'data_vars': {'a': {'dims': 't', 'data': x, },\n",
      " |                             'b': {'dims': 't', 'data': y}}}\n",
      " |      \n",
      " |      where 't' is the name of the dimesion, 'a' and 'b' are names of data\n",
      " |      variables and t, x, and y are lists, numpy.arrays or pandas objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      d : dict, with a minimum structure of {'var_0': {'dims': [..],                                                          'data': [..]},                                                ...}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj : xarray.Dataset\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Dataset.to_dict\n",
      " |      DataArray.from_dict\n",
      " |  \n",
      " |  load_store(store, decoder=None) from abc.ABCMeta\n",
      " |      Create a new dataset from the contents of a backends.*DataStore\n",
      " |      object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  T\n",
      " |  \n",
      " |  __dask_optimize__\n",
      " |  \n",
      " |  __dask_scheduler__\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes on this dataset\n",
      " |  \n",
      " |  chunks\n",
      " |      Block dimensions for this dataset's data or None if it's not a dask\n",
      " |      array.\n",
      " |  \n",
      " |  coords\n",
      " |      Dictionary of xarray.DataArray objects corresponding to coordinate\n",
      " |      variables\n",
      " |  \n",
      " |  data_vars\n",
      " |      Dictionary of xarray.DataArray objects corresponding to data variables\n",
      " |  \n",
      " |  dims\n",
      " |      Mapping from dimension names to lengths.\n",
      " |      \n",
      " |      Cannot be modified directly, but is updated when adding new variables.\n",
      " |      \n",
      " |      Note that type of this object differs from `DataArray.dims`.\n",
      " |      See `Dataset.sizes` and `DataArray.sizes` for consistently named\n",
      " |      properties.\n",
      " |  \n",
      " |  encoding\n",
      " |      Dictionary of global encoding attributes on this dataset\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  indexes\n",
      " |      OrderedDict of pandas.Index objects used for label based indexing\n",
      " |  \n",
      " |  loc\n",
      " |      Attribute for location based indexing. Only supports __getitem__,\n",
      " |      and only when the key is a dict of the form {dim: labels}.\n",
      " |  \n",
      " |  nbytes\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  sizes\n",
      " |      Mapping from dimension names to lengths.\n",
      " |      \n",
      " |      Cannot be modified directly, but is updated when adding new variables.\n",
      " |      \n",
      " |      This is an alias for `Dataset.dims` provided for the benefit of\n",
      " |      consistency with `DataArray.sizes`.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataArray.sizes\n",
      " |  \n",
      " |  variables\n",
      " |      Low level interface to Dataset contents as dict of Variable objects.\n",
      " |      \n",
      " |      This ordered dictionary is frozen to prevent mutation that could\n",
      " |      violate Dataset invariants. It contains all variable objects\n",
      " |      constituting the Dataset, including both data variables and\n",
      " |      coordinates.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __array_priority__ = 50\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from collections.abc.Mapping:\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      " |  \n",
      " |  items(self)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  keys(self)\n",
      " |      D.keys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  values(self)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from collections.abc.Mapping:\n",
      " |  \n",
      " |  __reversed__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Collection:\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from xarray.core.common.DataWithCoords:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |  \n",
      " |  assign_attrs(self, *args, **kwargs)\n",
      " |      Assign new attrs to this object.\n",
      " |      \n",
      " |      Returns a new object equivalent to self.attrs.update(*args, **kwargs).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      args : positional arguments passed into ``attrs.update``.\n",
      " |      kwargs : keyword arguments passed into ``attrs.update``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      assigned : same type as caller\n",
      " |          A new object with the new attrs in addition to the existing data.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Dataset.assign\n",
      " |  \n",
      " |  assign_coords(self, **kwargs)\n",
      " |      Assign new coordinates to this object.\n",
      " |      \n",
      " |      Returns a new object with all the original data in addition to the new\n",
      " |      coordinates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kwargs : keyword, value pairs\n",
      " |          keywords are the variables names. If the values are callable, they\n",
      " |          are computed on this object and assigned to new coordinate\n",
      " |          variables. If the values are not callable, (e.g. a DataArray,\n",
      " |          scalar, or array), they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      assigned : same type as caller\n",
      " |          A new object with the new coordinates in addition to the existing\n",
      " |          data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Convert longitude coordinates from 0-359 to -180-179:\n",
      " |      \n",
      " |      >>> da = xr.DataArray(np.random.rand(4),\n",
      " |      ...                   coords=[np.array([358, 359, 0, 1])],\n",
      " |      ...                   dims='lon')\n",
      " |      >>> da\n",
      " |      <xarray.DataArray (lon: 4)>\n",
      " |      array([0.28298 , 0.667347, 0.657938, 0.177683])\n",
      " |      Coordinates:\n",
      " |        * lon      (lon) int64 358 359 0 1\n",
      " |      >>> da.assign_coords(lon=(((da.lon + 180) % 360) - 180))\n",
      " |      <xarray.DataArray (lon: 4)>\n",
      " |      array([0.28298 , 0.667347, 0.657938, 0.177683])\n",
      " |      Coordinates:\n",
      " |        * lon      (lon) int64 -2 -1 0 1\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Since ``kwargs`` is a dictionary, the order of your arguments may not\n",
      " |      be preserved, and so the order of the new variables is not well\n",
      " |      defined. Assigning multiple variables within the same ``assign_coords``\n",
      " |      is possible, but you cannot reference other variables created within\n",
      " |      the same ``assign_coords`` call.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Dataset.assign\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close any files linked to this object\n",
      " |  \n",
      " |  get_index(self, key)\n",
      " |      Get an index for a dimension, with fall-back to a default RangeIndex\n",
      " |  \n",
      " |  groupby(self, group, squeeze=True)\n",
      " |      Returns a GroupBy object for performing grouped operations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      group : str, DataArray or IndexVariable\n",
      " |          Array whose unique values should be used to group this array. If a\n",
      " |          string, must be the name of a variable contained in this dataset.\n",
      " |      squeeze : boolean, optional\n",
      " |          If \"group\" is a dimension of any arrays in this dataset, `squeeze`\n",
      " |          controls whether the subarrays have a dimension of length 1 along\n",
      " |          that dimension or if the dimension is squeezed out.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      grouped : GroupBy\n",
      " |          A `GroupBy` object patterned after `pandas.GroupBy` that can be\n",
      " |          iterated over in the form of `(unique_value, grouped_array)` pairs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Calculate daily anomalies for daily data:\n",
      " |      \n",
      " |      >>> da = xr.DataArray(np.linspace(0, 1826, num=1827),\n",
      " |      ...                   coords=[pd.date_range('1/1/2000', '31/12/2004',\n",
      " |      ...                           freq='D')],\n",
      " |      ...                   dims='time')\n",
      " |      >>> da\n",
      " |      <xarray.DataArray (time: 1827)>\n",
      " |      array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.824e+03, 1.825e+03, 1.826e+03])\n",
      " |      Coordinates:\n",
      " |        * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...\n",
      " |      >>> da.groupby('time.dayofyear') - da.groupby('time.dayofyear').mean('time')\n",
      " |      <xarray.DataArray (time: 1827)>\n",
      " |      array([-730.8, -730.8, -730.8, ...,  730.2,  730.2,  730.5])\n",
      " |      Coordinates:\n",
      " |        * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...\n",
      " |          dayofyear  (time) int64 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.DataArrayGroupBy\n",
      " |      core.groupby.DatasetGroupBy\n",
      " |  \n",
      " |  groupby_bins(self, group, bins, right=True, labels=None, precision=3, include_lowest=False, squeeze=True)\n",
      " |      Returns a GroupBy object for performing grouped operations.\n",
      " |      \n",
      " |      Rather than using all unique values of `group`, the values are discretized\n",
      " |      first by applying `pandas.cut` [1]_ to `group`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      group : str, DataArray or IndexVariable\n",
      " |          Array whose binned values should be used to group this array. If a\n",
      " |          string, must be the name of a variable contained in this dataset.\n",
      " |      bins : int or array of scalars\n",
      " |          If bins is an int, it defines the number of equal-width bins in the\n",
      " |          range of x. However, in this case, the range of x is extended by .1%\n",
      " |          on each side to include the min or max values of x. If bins is a\n",
      " |          sequence it defines the bin edges allowing for non-uniform bin\n",
      " |          width. No extension of the range of x is done in this case.\n",
      " |      right : boolean, optional\n",
      " |          Indicates whether the bins include the rightmost edge or not. If\n",
      " |          right == True (the default), then the bins [1,2,3,4] indicate\n",
      " |          (1,2], (2,3], (3,4].\n",
      " |      labels : array or boolean, default None\n",
      " |          Used as labels for the resulting bins. Must be of the same length as\n",
      " |          the resulting bins. If False, string bin labels are assigned by\n",
      " |          `pandas.cut`.\n",
      " |      precision : int\n",
      " |          The precision at which to store and display the bins labels.\n",
      " |      include_lowest : bool\n",
      " |          Whether the first interval should be left-inclusive or not.\n",
      " |      squeeze : boolean, optional\n",
      " |          If \"group\" is a dimension of any arrays in this dataset, `squeeze`\n",
      " |          controls whether the subarrays have a dimension of length 1 along\n",
      " |          that dimension or if the dimension is squeezed out.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      grouped : GroupBy\n",
      " |          A `GroupBy` object patterned after `pandas.GroupBy` that can be\n",
      " |          iterated over in the form of `(unique_value, grouped_array)` pairs.\n",
      " |          The name of the group has the added suffix `_bins` in order to\n",
      " |          distinguish it from the original variable.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] http://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html\n",
      " |  \n",
      " |  isin(self, test_elements)\n",
      " |      Tests each value in the array for whether it is in the supplied list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      test_elements : array_like\n",
      " |          The values against which to test each value of `element`.\n",
      " |          This argument is flattened if an array or array_like.\n",
      " |          See numpy notes for behavior with non-array-like parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      isin : same as object, bool\n",
      " |          Has the same shape as this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> array = xr.DataArray([1, 2, 3], dims='x')\n",
      " |      >>> array.isin([1, 3])\n",
      " |      <xarray.DataArray (x: 3)>\n",
      " |      array([ True, False,  True])\n",
      " |      Dimensions without coordinates: x\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.isin\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, *args, **kwargs)\n",
      " |      \n",
      " |      This method replicates the pandas method of the same name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to this xarray object (Dataset/DataArray).\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the xarray object.\n",
      " |      args : positional arguments passed into ``func``.\n",
      " |      kwargs : a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      xarray or pandas objects, e.g., instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(ds), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (ds.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (ds.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.pipe\n",
      " |  \n",
      " |  resample(self, freq=None, dim=None, how=None, skipna=None, closed=None, label=None, base=0, keep_attrs=False, **indexer)\n",
      " |      Returns a Resample object for performing resampling operations.\n",
      " |      \n",
      " |      Handles both downsampling and upsampling. If any intervals contain no\n",
      " |      values from the original object, they will be given the value ``NaN``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, optional\n",
      " |          Whether to skip missing values when aggregating in downsampling.\n",
      " |      closed : 'left' or 'right', optional\n",
      " |          Side of each interval to treat as closed.\n",
      " |      label : 'left or 'right', optional\n",
      " |          Side of each interval to use for labeling.\n",
      " |      base : int, optional\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '24H' frequency, base could\n",
      " |          range from 0 through 23.\n",
      " |      keep_attrs : bool, optional\n",
      " |          If True, the object's attributes (`attrs`) will be copied from\n",
      " |          the original object to the new one.  If False (default), the new\n",
      " |          object will be returned without attributes.\n",
      " |      **indexer : {dim: freq}\n",
      " |          Dictionary with a key indicating the dimension name to resample\n",
      " |          over and a value corresponding to the resampling frequency.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      resampled : same type as caller\n",
      " |          This object resampled.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Downsample monthly time-series data to seasonal data:\n",
      " |      \n",
      " |      >>> da = xr.DataArray(np.linspace(0, 11, num=12),\n",
      " |      ...                   coords=[pd.date_range('15/12/1999',\n",
      " |      ...                           periods=12, freq=pd.DateOffset(months=1))],\n",
      " |      ...                   dims='time')\n",
      " |      >>> da\n",
      " |      <xarray.DataArray (time: 12)>\n",
      " |      array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7., 8.,   9.,  10.,  11.])\n",
      " |      Coordinates:\n",
      " |        * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...\n",
      " |      >>> da.resample(time=\"QS-DEC\").mean()\n",
      " |      <xarray.DataArray (time: 4)>\n",
      " |      array([ 1.,  4.,  7., 10.])\n",
      " |      Coordinates:\n",
      " |        * time     (time) datetime64[ns] 1999-12-01 2000-03-01 2000-06-01 2000-09-01\n",
      " |      \n",
      " |      Upsample monthly time-series data to daily data:\n",
      " |      \n",
      " |      >>> da.resample(time='1D').interpolate('linear')\n",
      " |      <xarray.DataArray (time: 337)>\n",
      " |      array([ 0.      ,  0.032258,  0.064516, ..., 10.935484, 10.967742, 11.      ])\n",
      " |      Coordinates:\n",
      " |        * time     (time) datetime64[ns] 1999-12-15 1999-12-16 1999-12-17 ...\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      \n",
      " |      .. [1] http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases\n",
      " |  \n",
      " |  rolling(self, dim=None, min_periods=None, center=False, **dim_kwargs)\n",
      " |      Rolling window object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim: dict, optional\n",
      " |          Mapping from the dimension name to create the rolling iterator\n",
      " |          along (e.g. `time`) to its moving window size.\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). The default, None, is equivalent to\n",
      " |          setting min_periods equal to the size of the window.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      **dim_kwargs : optional\n",
      " |          The keyword arguments form of ``dim``.\n",
      " |          One of dim or dim_kwarg must be provided.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Rolling object (core.rolling.DataArrayRolling for DataArray,\n",
      " |      core.rolling.DatasetRolling for Dataset.)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create rolling seasonal average of monthly data e.g. DJF, JFM, ..., SON:\n",
      " |      \n",
      " |      >>> da = xr.DataArray(np.linspace(0, 11, num=12),\n",
      " |      ...                   coords=[pd.date_range('15/12/1999',\n",
      " |      ...                           periods=12, freq=pd.DateOffset(months=1))],\n",
      " |      ...                   dims='time')\n",
      " |      >>> da\n",
      " |      <xarray.DataArray (time: 12)>\n",
      " |      array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7., 8.,   9.,  10.,  11.])\n",
      " |      Coordinates:\n",
      " |        * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...\n",
      " |      >>> da.rolling(time=3, center=True).mean()\n",
      " |      <xarray.DataArray (time: 12)>\n",
      " |      array([nan,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., nan])\n",
      " |      Coordinates:\n",
      " |        * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...\n",
      " |      \n",
      " |      Remove the NaNs using ``dropna()``:\n",
      " |      \n",
      " |      >>> da.rolling(time=3, center=True).mean().dropna('time')\n",
      " |      <xarray.DataArray (time: 10)>\n",
      " |      array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      " |      Coordinates:\n",
      " |        * time     (time) datetime64[ns] 2000-01-15 2000-02-15 2000-03-15 ...\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.rolling.DataArrayRolling\n",
      " |      core.rolling.DatasetRolling\n",
      " |  \n",
      " |  squeeze(self, dim=None, drop=False, axis=None)\n",
      " |      Return a new object with squeezed data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dim : None or str or tuple of str, optional\n",
      " |          Selects a subset of the length one dimensions. If a dimension is\n",
      " |          selected with length greater than one, an error is raised. If\n",
      " |          None, all length one dimensions are squeezed.\n",
      " |      drop : bool, optional\n",
      " |          If ``drop=True``, drop squeezed coordinates instead of making them\n",
      " |          scalar.\n",
      " |      axis : int, optional\n",
      " |          Select the dimension to squeeze. Added for compatibility reasons.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      squeezed : same type as caller\n",
      " |          This object, but with with all or a subset of the dimensions of\n",
      " |          length 1 removed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.squeeze\n",
      " |  \n",
      " |  where(self, cond, other=<NA>, drop=False)\n",
      " |      Filter elements from this object according to a condition.\n",
      " |      \n",
      " |      This operation follows the normal broadcasting and alignment rules that\n",
      " |      xarray uses for binary arithmetic.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : DataArray or Dataset with boolean dtype\n",
      " |          Locations at which to preserve this object's values.\n",
      " |      other : scalar, DataArray or Dataset, optional\n",
      " |          Value to use for locations in this object where ``cond`` is False.\n",
      " |          By default, these locations filled with NA.\n",
      " |      drop : boolean, optional\n",
      " |          If True, coordinate labels that only correspond to False values of\n",
      " |          the condition are dropped from the result. Mutually exclusive with\n",
      " |          ``other``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import numpy as np\n",
      " |      >>> a = xr.DataArray(np.arange(25).reshape(5, 5), dims=('x', 'y'))\n",
      " |      >>> a.where(a.x + a.y < 4)\n",
      " |      <xarray.DataArray (x: 5, y: 5)>\n",
      " |      array([[  0.,   1.,   2.,   3.,  nan],\n",
      " |             [  5.,   6.,   7.,  nan,  nan],\n",
      " |             [ 10.,  11.,  nan,  nan,  nan],\n",
      " |             [ 15.,  nan,  nan,  nan,  nan],\n",
      " |             [ nan,  nan,  nan,  nan,  nan]])\n",
      " |      Dimensions without coordinates: x, y\n",
      " |      >>> a.where(a.x + a.y < 5, -1)\n",
      " |      <xarray.DataArray (x: 5, y: 5)>\n",
      " |      array([[ 0,  1,  2,  3,  4],\n",
      " |             [ 5,  6,  7,  8, -1],\n",
      " |             [10, 11, 12, -1, -1],\n",
      " |             [15, 16, -1, -1, -1],\n",
      " |             [20, -1, -1, -1, -1]])\n",
      " |      Dimensions without coordinates: x, y\n",
      " |      >>> a.where(a.x + a.y < 4, drop=True)\n",
      " |      <xarray.DataArray (x: 4, y: 4)>\n",
      " |      array([[  0.,   1.,   2.,   3.],\n",
      " |             [  5.,   6.,   7.,  nan],\n",
      " |             [ 10.,  11.,  nan,  nan],\n",
      " |             [ 15.,  nan,  nan,  nan]])\n",
      " |      Dimensions without coordinates: x, y\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.where : corresponding numpy function\n",
      " |      where : equivalent function\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from xarray.core.arithmetic.SupportsArithmetic:\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc, method, *inputs, **kwargs)\n",
      " |  \n",
      " |  __div__ = not_implemented(*args, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from xarray.core.common.AttrAccessMixin:\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from xarray.core.formatting.ReprMixin:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xr.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-acaaf01f002f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MOD06'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_vars, coords, attrs, compat)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_init_vars_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_set_init_vars_and_dims\u001b[0;34m(self, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         variables, coord_names, dims = merge_data_and_coords(\n\u001b[0;32m--> 383\u001b[0;31m             data_vars, coords, compat=compat)\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data, coords, compat, join)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return merge_core(objs, compat, join, explicit_coords=explicit_coords,\n\u001b[0;32m--> 370\u001b[0;31m                       indexes=indexes)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0m_assert_compat_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_variable_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mcoerce_pandas_values\u001b[0;34m(objects)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "foo = xr.Dataset('MOD06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray('/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray ()>\n",
       "array('/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf',\n",
       "      dtype='<U86')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ImplementsArrayReduce._reduce_method.<locals>.wrapped_func of <xarray.DataArray ()>\n",
       "array('/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf',\n",
       "      dtype='<U86')>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf',\n",
       "      dtype='<U86')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U86')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000344"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.nbytes / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf',\n",
       "      dtype='<U86')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-8f1b7af88084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_vars, coords, attrs, compat)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_init_vars_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_set_init_vars_and_dims\u001b[0;34m(self, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         variables, coord_names, dims = merge_data_and_coords(\n\u001b[0;32m--> 383\u001b[0;31m             data_vars, coords, compat=compat)\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data, coords, compat, join)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return merge_core(objs, compat, join, explicit_coords=explicit_coords,\n\u001b[0;32m--> 370\u001b[0;31m                       indexes=indexes)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0m_assert_compat_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_variable_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mcoerce_pandas_values\u001b[0;34m(objects)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "ds = xr.Dataset('/Users/saviosebastian/Desktop/XArraysTest/MYD06_L2.A2002185.0000.061.2018003215042.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = ['IA', 'IL', 'IN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range('2000-01-01', periods=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF4):\n",
      "    HDFEOSVersion: HDFEOS_V2.19\n",
      "    StructMetadata.0: GROUP=SwathStructure\n",
      "\tGROUP=SWATH_1\n",
      "\t\tSwathName=\"mod06\"\n",
      "\t\tGROUP=Dimension\n",
      "\t\t\tOBJECT=Dimension_1\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_5km\"\n",
      "\t\t\t\tSize=270\n",
      "\t\t\tEND_OBJECT=Dimension_1\n",
      "\t\t\tOBJECT=Dimension_2\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_5km\"\n",
      "\t\t\t\tSize=408\n",
      "\t\t\tEND_OBJECT=Dimension_2\n",
      "\t\t\tOBJECT=Dimension_3\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_1km\"\n",
      "\t\t\t\tSize=1354\n",
      "\t\t\tEND_OBJECT=Dimension_3\n",
      "\t\t\tOBJECT=Dimension_4\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_1km\"\n",
      "\t\t\t\tSize=2040\n",
      "\t\t\tEND_OBJECT=Dimension_4\n",
      "\t\t\tOBJECT=Dimension_5\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_hkm\"\n",
      "\t\t\t\tSize=2708\n",
      "\t\t\tEND_OBJECT=Dimension_5\n",
      "\t\t\tOBJECT=Dimension_6\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_hkm\"\n",
      "\t\t\t\tSize=4060\n",
      "\t\t\tEND_OBJECT=Dimension_6\n",
      "\t\t\tOBJECT=Dimension_7\n",
      "\t\t\t\tDimensionName=\"Band_Number\"\n",
      "\t\t\t\tSize=7\n",
      "\t\t\tEND_OBJECT=Dimension_7\n",
      "\t\t\tOBJECT=Dimension_8\n",
      "\t\t\t\tDimensionName=\"Band_Ratio\"\n",
      "\t\t\t\tSize=5\n",
      "\t\t\tEND_OBJECT=Dimension_8\n",
      "\t\t\tOBJECT=Dimension_9\n",
      "\t\t\t\tDimensionName=\"Band_Forcing\"\n",
      "\t\t\t\tSize=5\n",
      "\t\t\tEND_OBJECT=Dimension_9\n",
      "\t\t\tOBJECT=Dimension_10\n",
      "\t\t\t\tDimensionName=\"Band_Difference\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_10\n",
      "\t\t\tOBJECT=Dimension_11\n",
      "\t\t\t\tDimensionName=\"QA_Parameter_5km\"\n",
      "\t\t\t\tSize=10\n",
      "\t\t\tEND_OBJECT=Dimension_11\n",
      "\t\t\tOBJECT=Dimension_12\n",
      "\t\t\t\tDimensionName=\"QA_Parameter_1km\"\n",
      "\t\t\t\tSize=9\n",
      "\t\t\tEND_OBJECT=Dimension_12\n",
      "\t\t\tOBJECT=Dimension_13\n",
      "\t\t\t\tDimensionName=\"Cloud_Mask_1km_Num_Bytes\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_13\n",
      "\t\t\tOBJECT=Dimension_14\n",
      "\t\t\t\tDimensionName=\"Cloud_Mask_5km_Num_Bytes\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_14\n",
      "\t\t\tOBJECT=Dimension_15\n",
      "\t\t\t\tDimensionName=\"RadTran_NWL\"\n",
      "\t\t\t\tSize=7\n",
      "\t\t\tEND_OBJECT=Dimension_15\n",
      "\t\t\tOBJECT=Dimension_16\n",
      "\t\t\t\tDimensionName=\"RadTran_NRE_Ice\"\n",
      "\t\t\t\tSize=12\n",
      "\t\t\tEND_OBJECT=Dimension_16\n",
      "\t\t\tOBJECT=Dimension_17\n",
      "\t\t\t\tDimensionName=\"RadTran_NRE_Liq\"\n",
      "\t\t\t\tSize=18\n",
      "\t\t\tEND_OBJECT=Dimension_17\n",
      "\t\t\tOBJECT=Dimension_18\n",
      "\t\t\t\tDimensionName=\"SPI_nband\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_18\n",
      "\t\t\tOBJECT=Dimension_19\n",
      "\t\t\t\tDimensionName=\"RFM_nband\"\n",
      "\t\t\t\tSize=3\n",
      "\t\t\tEND_OBJECT=Dimension_19\n",
      "\t\t\tOBJECT=Dimension_20\n",
      "\t\t\t\tDimensionName=\"ACR_nband\"\n",
      "\t\t\t\tSize=6\n",
      "\t\t\tEND_OBJECT=Dimension_20\n",
      "\t\t\tOBJECT=Dimension_21\n",
      "\t\t\t\tDimensionName=\"Statistic_Parameter_1km\"\n",
      "\t\t\t\tSize=17\n",
      "\t\t\tEND_OBJECT=Dimension_21\n",
      "\t\tEND_GROUP=Dimension\n",
      "\t\tGROUP=DimensionMap\n",
      "\t\t\tOBJECT=DimensionMap_1\n",
      "\t\t\t\tGeoDimension=\"Cell_Across_Swath_5km\"\n",
      "\t\t\t\tDataDimension=\"Cell_Across_Swath_1km\"\n",
      "\t\t\t\tOffset=2\n",
      "\t\t\t\tIncrement=5\n",
      "\t\t\tEND_OBJECT=DimensionMap_1\n",
      "\t\t\tOBJECT=DimensionMap_2\n",
      "\t\t\t\tGeoDimension=\"Cell_Along_Swath_5km\"\n",
      "\t\t\t\tDataDimension=\"Cell_Along_Swath_1km\"\n",
      "\t\t\t\tOffset=2\n",
      "\t\t\t\tIncrement=5\n",
      "\t\t\tEND_OBJECT=DimensionMap_2\n",
      "\t\tEND_GROUP=DimensionMap\n",
      "\t\tGROUP=IndexDimensionMap\n",
      "\t\tEND_GROUP=IndexDimensionMap\n",
      "\t\tGROUP=GeoField\n",
      "\t\t\tOBJECT=GeoField_1\n",
      "\t\t\t\tGeoFieldName=\"Latitude\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=GeoField_1\n",
      "\t\t\tOBJECT=GeoField_2\n",
      "\t\t\t\tGeoFieldName=\"Longitude\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=GeoField_2\n",
      "\t\tEND_GROUP=GeoField\n",
      "\t\tGROUP=DataField\n",
      "\t\t\tOBJECT=DataField_1\n",
      "\t\t\t\tDataFieldName=\"Band_Number\"\n",
      "\t\t\t\tDataType=DFNT_INT32\n",
      "\t\t\t\tDimList=(\"Band_Number\")\n",
      "\t\t\tEND_OBJECT=DataField_1\n",
      "\t\t\tOBJECT=DataField_2\n",
      "\t\t\t\tDataFieldName=\"Statistics_1km\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Statistic_Parameter_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_2\n",
      "\t\t\tOBJECT=DataField_3\n",
      "\t\t\t\tDataFieldName=\"Scan_Start_Time\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT64\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_3\n",
      "\t\t\tOBJECT=DataField_4\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_4\n",
      "\t\t\tOBJECT=DataField_5\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_5\n",
      "\t\t\tOBJECT=DataField_6\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_6\n",
      "\t\t\tOBJECT=DataField_7\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_7\n",
      "\t\t\tOBJECT=DataField_8\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_8\n",
      "\t\t\tOBJECT=DataField_9\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_9\n",
      "\t\t\tOBJECT=DataField_10\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_10\n",
      "\t\t\tOBJECT=DataField_11\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_11\n",
      "\t\t\tOBJECT=DataField_12\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_12\n",
      "\t\t\tOBJECT=DataField_13\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_13\n",
      "\t\t\tOBJECT=DataField_14\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_14\n",
      "\t\t\tOBJECT=DataField_15\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_15\n",
      "\t\t\tOBJECT=DataField_16\n",
      "\t\t\t\tDataFieldName=\"Brightness_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Number\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_16\n",
      "\t\t\tOBJECT=DataField_17\n",
      "\t\t\t\tDataFieldName=\"Surface_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_17\n",
      "\t\t\tOBJECT=DataField_18\n",
      "\t\t\t\tDataFieldName=\"Surface_Pressure\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_18\n",
      "\t\t\tOBJECT=DataField_19\n",
      "\t\t\t\tDataFieldName=\"Cloud_Height_Method\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_19\n",
      "\t\t\tOBJECT=DataField_20\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_20\n",
      "\t\t\tOBJECT=DataField_21\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_21\n",
      "\t\t\tOBJECT=DataField_22\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_22\n",
      "\t\t\tOBJECT=DataField_23\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_23\n",
      "\t\t\tOBJECT=DataField_24\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_24\n",
      "\t\t\tOBJECT=DataField_25\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_25\n",
      "\t\t\tOBJECT=DataField_26\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_26\n",
      "\t\t\tOBJECT=DataField_27\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_27\n",
      "\t\t\tOBJECT=DataField_28\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_28\n",
      "\t\t\tOBJECT=DataField_29\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_29\n",
      "\t\t\tOBJECT=DataField_30\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_30\n",
      "\t\t\tOBJECT=DataField_31\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_31\n",
      "\t\t\tOBJECT=DataField_32\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_32\n",
      "\t\t\tOBJECT=DataField_33\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_33\n",
      "\t\t\tOBJECT=DataField_34\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_34\n",
      "\t\t\tOBJECT=DataField_35\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_35\n",
      "\t\t\tOBJECT=DataField_36\n",
      "\t\t\t\tDataFieldName=\"Tropopause_Height\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_36\n",
      "\t\t\tOBJECT=DataField_37\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_37\n",
      "\t\t\tOBJECT=DataField_38\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_38\n",
      "\t\t\tOBJECT=DataField_39\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_39\n",
      "\t\t\tOBJECT=DataField_40\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_40\n",
      "\t\t\tOBJECT=DataField_41\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_41\n",
      "\t\t\tOBJECT=DataField_42\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_42\n",
      "\t\t\tOBJECT=DataField_43\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_43\n",
      "\t\t\tOBJECT=DataField_44\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_44\n",
      "\t\t\tOBJECT=DataField_45\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_45\n",
      "\t\t\tOBJECT=DataField_46\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_46\n",
      "\t\t\tOBJECT=DataField_47\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_47\n",
      "\t\t\tOBJECT=DataField_48\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_48\n",
      "\t\t\tOBJECT=DataField_49\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Infrared\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_49\n",
      "\t\t\tOBJECT=DataField_50\n",
      "\t\t\t\tDataFieldName=\"Spectral_Cloud_Forcing\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Forcing\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_50\n",
      "\t\t\tOBJECT=DataField_51\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_From_Ratios\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Ratio\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_51\n",
      "\t\t\tOBJECT=DataField_52\n",
      "\t\t\t\tDataFieldName=\"Radiance_Variance\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_52\n",
      "\t\t\tOBJECT=DataField_53\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_53\n",
      "\t\t\tOBJECT=DataField_54\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_54\n",
      "\t\t\tOBJECT=DataField_55\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_55\n",
      "\t\t\tOBJECT=DataField_56\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_56\n",
      "\t\t\tOBJECT=DataField_57\n",
      "\t\t\t\tDataFieldName=\"IRP_CTH_Consistency_Flag_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_57\n",
      "\t\t\tOBJECT=DataField_58\n",
      "\t\t\t\tDataFieldName=\"os_top_flag_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_58\n",
      "\t\t\tOBJECT=DataField_59\n",
      "\t\t\t\tDataFieldName=\"cloud_top_pressure_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_59\n",
      "\t\t\tOBJECT=DataField_60\n",
      "\t\t\t\tDataFieldName=\"cloud_top_height_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_60\n",
      "\t\t\tOBJECT=DataField_61\n",
      "\t\t\t\tDataFieldName=\"cloud_top_temperature_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_61\n",
      "\t\t\tOBJECT=DataField_62\n",
      "\t\t\t\tDataFieldName=\"cloud_emissivity_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_62\n",
      "\t\t\tOBJECT=DataField_63\n",
      "\t\t\t\tDataFieldName=\"cloud_top_method_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_63\n",
      "\t\t\tOBJECT=DataField_64\n",
      "\t\t\t\tDataFieldName=\"surface_temperature_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_64\n",
      "\t\t\tOBJECT=DataField_65\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss11_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_65\n",
      "\t\t\tOBJECT=DataField_66\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss12_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_66\n",
      "\t\t\tOBJECT=DataField_67\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss13_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_67\n",
      "\t\t\tOBJECT=DataField_68\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss85_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_68\n",
      "\t\t\tOBJECT=DataField_69\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_69\n",
      "\t\t\tOBJECT=DataField_70\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_70\n",
      "\t\t\tOBJECT=DataField_71\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_71\n",
      "\t\t\tOBJECT=DataField_72\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_72\n",
      "\t\t\tOBJECT=DataField_73\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_73\n",
      "\t\t\tOBJECT=DataField_74\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_74\n",
      "\t\t\tOBJECT=DataField_75\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_75\n",
      "\t\t\tOBJECT=DataField_76\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_76\n",
      "\t\t\tOBJECT=DataField_77\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_77\n",
      "\t\t\tOBJECT=DataField_78\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_78\n",
      "\t\t\tOBJECT=DataField_79\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_79\n",
      "\t\t\tOBJECT=DataField_80\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_80\n",
      "\t\t\tOBJECT=DataField_81\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_81\n",
      "\t\t\tOBJECT=DataField_82\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_82\n",
      "\t\t\tOBJECT=DataField_83\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_83\n",
      "\t\t\tOBJECT=DataField_84\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_84\n",
      "\t\t\tOBJECT=DataField_85\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_85\n",
      "\t\t\tOBJECT=DataField_86\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_86\n",
      "\t\t\tOBJECT=DataField_87\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_87\n",
      "\t\t\tOBJECT=DataField_88\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_88\n",
      "\t\t\tOBJECT=DataField_89\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_89\n",
      "\t\t\tOBJECT=DataField_90\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_90\n",
      "\t\t\tOBJECT=DataField_91\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_91\n",
      "\t\t\tOBJECT=DataField_92\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_92\n",
      "\t\t\tOBJECT=DataField_93\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_93\n",
      "\t\t\tOBJECT=DataField_94\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_94\n",
      "\t\t\tOBJECT=DataField_95\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_95\n",
      "\t\t\tOBJECT=DataField_96\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_96\n",
      "\t\t\tOBJECT=DataField_97\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_97\n",
      "\t\t\tOBJECT=DataField_98\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_98\n",
      "\t\t\tOBJECT=DataField_99\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_99\n",
      "\t\t\tOBJECT=DataField_100\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_100\n",
      "\t\t\tOBJECT=DataField_101\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_101\n",
      "\t\t\tOBJECT=DataField_102\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_102\n",
      "\t\t\tOBJECT=DataField_103\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_103\n",
      "\t\t\tOBJECT=DataField_104\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_104\n",
      "\t\t\tOBJECT=DataField_105\n",
      "\t\t\t\tDataFieldName=\"Above_Cloud_Water_Vapor_094\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_105\n",
      "\t\t\tOBJECT=DataField_106\n",
      "\t\t\t\tDataFieldName=\"IRW_Low_Cloud_Temperature_From_COP\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_106\n",
      "\t\t\tOBJECT=DataField_107\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Optical_Properties\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_107\n",
      "\t\t\tOBJECT=DataField_108\n",
      "\t\t\t\tDataFieldName=\"Cloud_Multi_Layer_Flag\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_108\n",
      "\t\t\tOBJECT=DataField_109\n",
      "\t\t\t\tDataFieldName=\"Cirrus_Reflectance\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_109\n",
      "\t\t\tOBJECT=DataField_110\n",
      "\t\t\t\tDataFieldName=\"Cirrus_Reflectance_Flag\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_110\n",
      "\t\t\tOBJECT=DataField_111\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_5km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\",\"Cloud_Mask_5km_Num_Bytes\")\n",
      "\t\t\tEND_OBJECT=DataField_111\n",
      "\t\t\tOBJECT=DataField_112\n",
      "\t\t\t\tDataFieldName=\"Quality_Assurance_5km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\",\"QA_Parameter_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_112\n",
      "\t\t\tOBJECT=DataField_113\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"Cloud_Mask_1km_Num_Bytes\")\n",
      "\t\t\tEND_OBJECT=DataField_113\n",
      "\t\t\tOBJECT=DataField_114\n",
      "\t\t\t\tDataFieldName=\"Extinction_Efficiency_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_114\n",
      "\t\t\tOBJECT=DataField_115\n",
      "\t\t\t\tDataFieldName=\"Asymmetry_Parameter_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_115\n",
      "\t\t\tOBJECT=DataField_116\n",
      "\t\t\t\tDataFieldName=\"Single_Scatter_Albedo_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_116\n",
      "\t\t\tOBJECT=DataField_117\n",
      "\t\t\t\tDataFieldName=\"Extinction_Efficiency_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_117\n",
      "\t\t\tOBJECT=DataField_118\n",
      "\t\t\t\tDataFieldName=\"Asymmetry_Parameter_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_118\n",
      "\t\t\tOBJECT=DataField_119\n",
      "\t\t\t\tDataFieldName=\"Single_Scatter_Albedo_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_119\n",
      "\t\t\tOBJECT=DataField_120\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_SPI\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"SPI_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_120\n",
      "\t\t\tOBJECT=DataField_121\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_121\n",
      "\t\t\tOBJECT=DataField_122\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_122\n",
      "\t\t\tOBJECT=DataField_123\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_123\n",
      "\t\t\tOBJECT=DataField_124\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_124\n",
      "\t\t\tOBJECT=DataField_125\n",
      "\t\t\t\tDataFieldName=\"Atm_Corr_Refl\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"ACR_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_125\n",
      "\t\t\tOBJECT=DataField_126\n",
      "\t\t\t\tDataFieldName=\"Quality_Assurance_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"QA_Parameter_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_126\n",
      "\t\tEND_GROUP=DataField\n",
      "\t\tGROUP=MergedFields\n",
      "\t\tEND_GROUP=MergedFields\n",
      "\tEND_GROUP=SWATH_1\n",
      "END_GROUP=SwathStructure\n",
      "GROUP=GridStructure\n",
      "END_GROUP=GridStructure\n",
      "GROUP=PointStructure\n",
      "END_GROUP=PointStructure\n",
      "END\n",
      "\n",
      "    Number_of_Instrument_Scans: 2040\n",
      "    Maximum_Number_of_1km_Frames: 1354\n",
      "    history: $Id: MOD06_L2.CDL.fs,v 1.13 2013/06/19 15:38:46 wind Exp $                          \n",
      "\n",
      "    title: MODIS Level 2 Cloud Properties                                                      \n",
      "\n",
      "    CoreMetadata.0: \n",
      "GROUP                  = INVENTORYMETADATA\n",
      "  GROUPTYPE            = MASTERGROUP\n",
      "\n",
      "  GROUP                  = ECSDATAGRANULE\n",
      "\n",
      "    OBJECT                 = REPROCESSINGPLANNED\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"further update is anticipated\"\n",
      "    END_OBJECT             = REPROCESSINGPLANNED\n",
      "\n",
      "    OBJECT                 = REPROCESSINGACTUAL\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"processed once\"\n",
      "    END_OBJECT             = REPROCESSINGACTUAL\n",
      "\n",
      "    OBJECT                 = LOCALGRANULEID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MYD06_L2.A2002185.0000.061.2018003215042.hdf\"\n",
      "    END_OBJECT             = LOCALGRANULEID\n",
      "\n",
      "    OBJECT                 = DAYNIGHTFLAG\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"Night\"\n",
      "    END_OBJECT             = DAYNIGHTFLAG\n",
      "\n",
      "    OBJECT                 = PRODUCTIONDATETIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2018-01-03T21:50:42.000Z\"\n",
      "    END_OBJECT             = PRODUCTIONDATETIME\n",
      "\n",
      "    OBJECT                 = LOCALVERSIONID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"061\"\n",
      "    END_OBJECT             = LOCALVERSIONID\n",
      "\n",
      "  END_GROUP              = ECSDATAGRANULE\n",
      "\n",
      "  GROUP                  = MEASUREDPARAMETER\n",
      "\n",
      "    OBJECT                 = MEASUREDPARAMETERCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = PARAMETERNAME\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"Cloud_Top_Pressure\"\n",
      "      END_OBJECT             = PARAMETERNAME\n",
      "\n",
      "      GROUP                  = QAFLAGS\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = AUTOMATICQUALITYFLAG\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"Passed\"\n",
      "        END_OBJECT             = AUTOMATICQUALITYFLAG\n",
      "\n",
      "        OBJECT                 = AUTOMATICQUALITYFLAGEXPLANATION\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"Passed: >10% useable; Failed: <10% useable\"\n",
      "        END_OBJECT             = AUTOMATICQUALITYFLAGEXPLANATION\n",
      "\n",
      "        OBJECT                 = SCIENCEQUALITYFLAG\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = \"Not Investigated\"\n",
      "          CLASS                = \"1\"\n",
      "        END_OBJECT             = SCIENCEQUALITYFLAG\n",
      "\n",
      "        OBJECT                 = SCIENCEQUALITYFLAGEXPLANATION\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = \"See http://modis-atmos.gsfc.nasa.gov/validation.html for more details on MODIS Atmosphere data quality.\"\n",
      "          CLASS                = \"1\"\n",
      "        END_OBJECT             = SCIENCEQUALITYFLAGEXPLANATION\n",
      "\n",
      "      END_GROUP              = QAFLAGS\n",
      "\n",
      "      GROUP                  = QASTATS\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = QAPERCENTMISSINGDATA\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = 63\n",
      "        END_OBJECT             = QAPERCENTMISSINGDATA\n",
      "\n",
      "      END_GROUP              = QASTATS\n",
      "\n",
      "    END_OBJECT             = MEASUREDPARAMETERCONTAINER\n",
      "\n",
      "  END_GROUP              = MEASUREDPARAMETER\n",
      "\n",
      "  GROUP                  = ORBITCALCULATEDSPATIALDOMAIN\n",
      "\n",
      "    OBJECT                 = ORBITCALCULATEDSPATIALDOMAINCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ORBITNUMBER\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = 885\n",
      "      END_OBJECT             = ORBITNUMBER\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGLONGITUDE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = 20.4199118302919\n",
      "      END_OBJECT             = EQUATORCROSSINGLONGITUDE\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGTIME\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"00:12:58.823356\"\n",
      "      END_OBJECT             = EQUATORCROSSINGTIME\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGDATE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"2002-07-04\"\n",
      "      END_OBJECT             = EQUATORCROSSINGDATE\n",
      "\n",
      "    END_OBJECT             = ORBITCALCULATEDSPATIALDOMAINCONTAINER\n",
      "\n",
      "  END_GROUP              = ORBITCALCULATEDSPATIALDOMAIN\n",
      "\n",
      "  GROUP                  = COLLECTIONDESCRIPTIONCLASS\n",
      "\n",
      "    OBJECT                 = SHORTNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MYD06_L2\"\n",
      "    END_OBJECT             = SHORTNAME\n",
      "\n",
      "    OBJECT                 = VERSIONID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = 61\n",
      "    END_OBJECT             = VERSIONID\n",
      "\n",
      "  END_GROUP              = COLLECTIONDESCRIPTIONCLASS\n",
      "\n",
      "  GROUP                  = INPUTGRANULE\n",
      "\n",
      "    OBJECT                 = INPUTPOINTER\n",
      "      NUM_VAL              = 50\n",
      "      VALUE                = (\"MYD021KM.A2002185.0000.061.2017363141721.hdf\", \"MYD03.A2002185.0000.061.2017362174430.hdf\", \"MYD35_L2.A2002185.0000.061.2017363141846.hdf\", \"gdas1.PGrbF00.020704.00z\", \"oisst.20020703\", \"goge1_2_img.v1\", \"modisdet.dry.101.lit_end.v3\", \"\n",
      "          modisdet.ozo.101.lit_end.v3\", \"modisdet.wts.101.lit_end.v3\", \"modisdet.wtl.101.lit_end.v3\", \"modisdet.wco.101.lit_end.v3\", \"MYDCSR_B.A2002185.061.2017363154239.hdf\", \"gdas1.PGrbF00.020704.06z\", \"eng.020704\", \"NISE_SSMIF13_20020704.HDFEOS\", \"MODIS_Ice_library.hdf.v5\", \"\n",
      "          MODIS_Water_library.hdf.v4\", \"MODIS_Ice_library_ws3.hdf.v3\", \"MODIS_Ice_library_ws3sd.hdf.v4\", \"MODIS_Ice_library_ws7.hdf.v3\", \"MODIS_Ice_library_ws7sd.hdf.v4\", \"MODIS_Ice_library_ws15.hdf.v3\", \"MODIS_Ice_library_ws15sd.hdf.v4\", \"MODIS_Water_library_ws3.hdf.v2\", \"\n",
      "          MODIS_Water_library_ws3sd.hdf.v3\", \"MODIS_Water_library_ws7.hdf.v2\", \"MODIS_Water_library_ws7sd.hdf.v3\", \"MODIS_Water_library_ws15.hdf.v2\", \"MODIS_Water_library_ws15sd.hdf.v3\", \"MODIS_Ice_WaterPhaseFunc.hdf.v3\", \"Transmittance.hdf.v2\", \"IGBP.EcoMap.NtoS.2004.149.v004.hdf\", \"\n",
      "          AlbSnwStst.ByNISE.W90.D90.WS.Hemi.2000-2004.YrAvg.hdf\", \"MCD43GF_wsa_Band1_185_2002_V006.hdf\", \"MCD43GF_wsa_Band2_185_2002_V006.hdf\", \"MCD43GF_wsa_Band5_185_2002_V006.hdf\", \"MCD43GF_wsa_Band6_185_2002_V006.hdf\", \"MCD43GF_wsa_Band7_185_2002_V006.hdf\")\n",
      "    END_OBJECT             = INPUTPOINTER\n",
      "\n",
      "  END_GROUP              = INPUTGRANULE\n",
      "\n",
      "  GROUP                  = SPATIALDOMAINCONTAINER\n",
      "\n",
      "    GROUP                  = HORIZONTALSPATIALDOMAINCONTAINER\n",
      "\n",
      "      GROUP                  = BOUNDINGRECTANGLE\n",
      "\n",
      "        OBJECT                 = WESTBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 15.0125121267976\n",
      "        END_OBJECT             = WESTBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = NORTHBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 47.4712121222453\n",
      "        END_OBJECT             = NORTHBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = EASTBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 46.3027701461145\n",
      "        END_OBJECT             = EASTBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = SOUTHBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 26.6036189855835\n",
      "        END_OBJECT             = SOUTHBOUNDINGCOORDINATE\n",
      "\n",
      "      END_GROUP              = BOUNDINGRECTANGLE\n",
      "\n",
      "    END_GROUP              = HORIZONTALSPATIALDOMAINCONTAINER\n",
      "\n",
      "  END_GROUP              = SPATIALDOMAINCONTAINER\n",
      "\n",
      "  GROUP                  = RANGEDATETIME\n",
      "\n",
      "    OBJECT                 = RANGEBEGINNINGDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2002-07-04\"\n",
      "    END_OBJECT             = RANGEBEGINNINGDATE\n",
      "\n",
      "    OBJECT                 = RANGEBEGINNINGTIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"00:00:00.000000\"\n",
      "    END_OBJECT             = RANGEBEGINNINGTIME\n",
      "\n",
      "    OBJECT                 = RANGEENDINGDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2002-07-04\"\n",
      "    END_OBJECT             = RANGEENDINGDATE\n",
      "\n",
      "    OBJECT                 = RANGEENDINGTIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"00:05:00.000000\"\n",
      "    END_OBJECT             = RANGEENDINGTIME\n",
      "\n",
      "  END_GROUP              = RANGEDATETIME\n",
      "\n",
      "  GROUP                  = PGEVERSIONCLASS\n",
      "\n",
      "    OBJECT                 = PGEVERSION\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"6.1.4\"\n",
      "    END_OBJECT             = PGEVERSION\n",
      "\n",
      "  END_GROUP              = PGEVERSIONCLASS\n",
      "\n",
      "  GROUP                  = ANCILLARYINPUTGRANULE\n",
      "\n",
      "    OBJECT                 = ANCILLARYINPUTGRANULECONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ANCILLARYINPUTTYPE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"Geolocation\"\n",
      "      END_OBJECT             = ANCILLARYINPUTTYPE\n",
      "\n",
      "      OBJECT                 = ANCILLARYINPUTPOINTER\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"MYD03.A2002185.0000.061.2017362174430.hdf\"\n",
      "      END_OBJECT             = ANCILLARYINPUTPOINTER\n",
      "\n",
      "    END_OBJECT             = ANCILLARYINPUTGRANULECONTAINER\n",
      "\n",
      "  END_GROUP              = ANCILLARYINPUTGRANULE\n",
      "\n",
      "  GROUP                  = ASSOCIATEDPLATFORMINSTRUMENTSENSOR\n",
      "\n",
      "    OBJECT                 = ASSOCIATEDPLATFORMINSTRUMENTSENSORCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDSENSORSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MODIS\"\n",
      "      END_OBJECT             = ASSOCIATEDSENSORSHORTNAME\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDPLATFORMSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"Aqua\"\n",
      "      END_OBJECT             = ASSOCIATEDPLATFORMSHORTNAME\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDINSTRUMENTSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MODIS\"\n",
      "      END_OBJECT             = ASSOCIATEDINSTRUMENTSHORTNAME\n",
      "\n",
      "    END_OBJECT             = ASSOCIATEDPLATFORMINSTRUMENTSENSORCONTAINER\n",
      "\n",
      "  END_GROUP              = ASSOCIATEDPLATFORMINSTRUMENTSENSOR\n",
      "\n",
      "  GROUP                  = ADDITIONALATTRIBUTES\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SuccessCloudTopPropRtrPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"   36.98\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"2\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"2\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SuccessCloudPhaseRtrPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"2\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"2\"\n",
      "          VALUE                = \"   36.66\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"4\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"4\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"LowCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"4\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"4\"\n",
      "          VALUE                = \"   32.12\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"5\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"5\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MidCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"5\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"5\"\n",
      "          VALUE                = \"    2.40\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"6\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"6\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"HighCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"6\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"6\"\n",
      "          VALUE                = \"    2.45\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"7\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"7\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"ThinCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"7\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"7\"\n",
      "          VALUE                = \"    9.74\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"8\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"8\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"ThickCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"8\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"8\"\n",
      "          VALUE                = \"   10.37\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"9\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"9\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"OpaqueCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"9\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"9\"\n",
      "          VALUE                = \"   16.86\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"10\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"10\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"CirrusCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"10\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"10\"\n",
      "          VALUE                = \"   20.12\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"11\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"11\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"IceCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"11\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"11\"\n",
      "          VALUE                = \"    1.27\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"12\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"12\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"WaterCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"12\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"12\"\n",
      "          VALUE                = \"   32.99\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"13\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"13\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MixedCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"13\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"13\"\n",
      "          VALUE                = \"    0.00\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"14\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"14\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"CloudPhaseUncertainPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"14\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"14\"\n",
      "          VALUE                = \"    2.40\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"15\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"15\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"OceanCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"15\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"15\"\n",
      "          VALUE                = \"   45.11\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"16\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"16\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"LandCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"16\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"16\"\n",
      "          VALUE                = \"   54.89\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"17\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"17\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SnowCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"17\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"17\"\n",
      "          VALUE                = \"    0.06\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"18\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"18\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"identifier_product_doi\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"18\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"18\"\n",
      "          VALUE                = \"10.5067/MODIS/MYD06_L2.061\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"19\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"19\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"identifier_product_doi_authority\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"19\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"19\"\n",
      "          VALUE                = \"http://dx.doi.org\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "  END_GROUP              = ADDITIONALATTRIBUTES\n",
      "\n",
      "END_GROUP              = INVENTORYMETADATA\n",
      "\n",
      "END\n",
      "\n",
      "    ArchiveMetadata.0: \n",
      "GROUP                  = ARCHIVEDMETADATA\n",
      "  GROUPTYPE            = MASTERGROUP\n",
      "\n",
      "  OBJECT                 = PROCESSINGENVIRONMENT\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"Linux minion7260 3.10.0-693.11.1.el7.x86_64 #1 SMP Mon Dec 4 23:52:40 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\"\n",
      "  END_OBJECT             = PROCESSINGENVIRONMENT\n",
      "\n",
      "  GROUP                  = ALGORITHMPACKAGE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEACCEPTANCEDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"June 1997\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEACCEPTANCEDATE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEMATURITYCODE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"at-launch\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEMATURITYCODE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGENAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"ATBD-MOD-04 and ATBD-MOD-05\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGENAME\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEVERSION\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEVERSION\n",
      "\n",
      "    OBJECT                 = INSTRUMENTNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"Moderate Resolution Imaging Spectroradiometer\"\n",
      "    END_OBJECT             = INSTRUMENTNAME\n",
      "\n",
      "    OBJECT                 = LONGNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MODIS/Aqua Clouds 5-Min L2 Swath 1km and 5km\"\n",
      "    END_OBJECT             = LONGNAME\n",
      "\n",
      "    OBJECT                 = LOCALINPUTGRANULEID\n",
      "      NUM_VAL              = 20\n",
      "      VALUE                = (\"MYD021KM.A2002185.0000.061.2017363141721.hdf\", \"MYD03.A2002185.0000.061.2017362174430.hdf\", \"MYD35_L2.A2002185.0000.061.2017363141846.hdf\", \"MYDCSR_B.A2002185.061.2017363154239.hdf\")\n",
      "    END_OBJECT             = LOCALINPUTGRANULEID\n",
      "\n",
      "  END_GROUP              = ALGORITHMPACKAGE\n",
      "\n",
      "  GROUP                  = GPOLYGON\n",
      "\n",
      "    OBJECT                 = GPOLYGONCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      GROUP                  = GRING\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = EXCLUSIONGRINGFLAG\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"N\"\n",
      "        END_OBJECT             = EXCLUSIONGRINGFLAG\n",
      "\n",
      "      END_GROUP              = GRING\n",
      "\n",
      "      GROUP                  = GRINGPOINT\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = GRINGPOINTLONGITUDE\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (16.6802142122724, 46.3037511907536, 38.7590005022001, 14.9898525858698)\n",
      "        END_OBJECT             = GRINGPOINTLONGITUDE\n",
      "\n",
      "        OBJECT                 = GRINGPOINTLATITUDE\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (47.4897565211684, 43.2358532665263, 26.5236230538033, 29.7440219071349)\n",
      "        END_OBJECT             = GRINGPOINTLATITUDE\n",
      "\n",
      "        OBJECT                 = GRINGPOINTSEQUENCENO\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (1, 2, 3, 4)\n",
      "        END_OBJECT             = GRINGPOINTSEQUENCENO\n",
      "\n",
      "      END_GROUP              = GRINGPOINT\n",
      "\n",
      "    END_OBJECT             = GPOLYGONCONTAINER\n",
      "\n",
      "  END_GROUP              = GPOLYGON\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_TOP_PROPERTY_IR\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_TOP_PROPERTY_IR\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_PHASE_IR\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_PHASE_IR\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_PROPERTY_VIS\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_PROPERTY_VIS\n",
      "\n",
      "  OBJECT                 = DESCRREVISION\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"6.1\"\n",
      "  END_OBJECT             = DESCRREVISION\n",
      "\n",
      "  OBJECT                 = PRODUCTIONHISTORY\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"PGE06:6.1.4\"\n",
      "  END_OBJECT             = PRODUCTIONHISTORY\n",
      "\n",
      "END_GROUP              = ARCHIVEDMETADATA\n",
      "\n",
      "END\n",
      "\n",
      "    Clear_Sky_Restoral_Status: y\n",
      "    Collection_4_Phase_Used: n\n",
      "    Ice_Phase_Forced: n\n",
      "    Water_Phase_Forced: n\n",
      "    identifier_product_doi: 10.5067/MODIS/MYD06_L2.061\n",
      "    identifier_product_doi_authority: http://dx.doi.org\n",
      "    dimensions(sizes): Cell_Along_Swath_5km:mod06(408), Cell_Across_Swath_5km:mod06(270), Band_Number:mod06(7), Band_Forcing:mod06(5), Band_Ratio:mod06(5), Cell_Along_Swath_1km:mod06(2040), Cell_Across_Swath_1km:mod06(1354), Cloud_Mask_5km_Num_Bytes:mod06(2), QA_Parameter_5km:mod06(10), Cloud_Mask_1km_Num_Bytes:mod06(2), RadTran_NRE_Ice:mod06(12), RadTran_NWL:mod06(7), RadTran_NRE_Liq:mod06(18), SPI_nband:mod06(2), RFM_nband:mod06(3), ACR_nband:mod06(6), QA_Parameter_1km:mod06(9), fakeDim17(17)\n",
      "    variables(dimensions): >f4 \u001b[4mLatitude\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >f4 \u001b[4mLongitude\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >f8 \u001b[4mScan_Start_Time\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mBrightness_Temperature\u001b[0m(Band_Number:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSurface_Temperature\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSurface_Pressure\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Height_Method\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mTropopause_Height\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Infrared\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSpectral_Cloud_Forcing\u001b[0m(Band_Forcing:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_From_Ratios\u001b[0m(Band_Ratio:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mRadiance_Variance\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mIRP_CTH_Consistency_Flag_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mos_top_flag_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_pressure_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_height_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_temperature_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mcloud_emissivity_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mcloud_top_method_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4msurface_temperature_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss11_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss12_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss13_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss85_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mAbove_Cloud_Water_Vapor_094\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mIRW_Low_Cloud_Temperature_From_COP\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Phase_Optical_Properties\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Multi_Layer_Flag\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCirrus_Reflectance\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCirrus_Reflectance_Flag\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Mask_5km\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06,Cloud_Mask_5km_Num_Bytes:mod06), int8 \u001b[4mQuality_Assurance_5km\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06,QA_Parameter_5km:mod06), int8 \u001b[4mCloud_Mask_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,Cloud_Mask_1km_Num_Bytes:mod06), >f4 \u001b[4mExtinction_Efficiency_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mAsymmetry_Parameter_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mSingle_Scatter_Albedo_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mExtinction_Efficiency_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >f4 \u001b[4mAsymmetry_Parameter_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >f4 \u001b[4mSingle_Scatter_Albedo_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >i2 \u001b[4mCloud_Mask_SPI\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,SPI_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mAtm_Corr_Refl\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,ACR_nband:mod06), int8 \u001b[4mQuality_Assurance_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,QA_Parameter_1km:mod06), >f4 \u001b[4mStatistics_1km_sds\u001b[0m(fakeDim17)\n",
      "    groups: \n",
      "\n",
      "---------------\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF4):\n",
      "    HDFEOSVersion: HDFEOS_V2.19\n",
      "    StructMetadata.0: GROUP=SwathStructure\n",
      "\tGROUP=SWATH_1\n",
      "\t\tSwathName=\"mod06\"\n",
      "\t\tGROUP=Dimension\n",
      "\t\t\tOBJECT=Dimension_1\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_5km\"\n",
      "\t\t\t\tSize=270\n",
      "\t\t\tEND_OBJECT=Dimension_1\n",
      "\t\t\tOBJECT=Dimension_2\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_5km\"\n",
      "\t\t\t\tSize=408\n",
      "\t\t\tEND_OBJECT=Dimension_2\n",
      "\t\t\tOBJECT=Dimension_3\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_1km\"\n",
      "\t\t\t\tSize=1354\n",
      "\t\t\tEND_OBJECT=Dimension_3\n",
      "\t\t\tOBJECT=Dimension_4\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_1km\"\n",
      "\t\t\t\tSize=2040\n",
      "\t\t\tEND_OBJECT=Dimension_4\n",
      "\t\t\tOBJECT=Dimension_5\n",
      "\t\t\t\tDimensionName=\"Cell_Across_Swath_hkm\"\n",
      "\t\t\t\tSize=2708\n",
      "\t\t\tEND_OBJECT=Dimension_5\n",
      "\t\t\tOBJECT=Dimension_6\n",
      "\t\t\t\tDimensionName=\"Cell_Along_Swath_hkm\"\n",
      "\t\t\t\tSize=4060\n",
      "\t\t\tEND_OBJECT=Dimension_6\n",
      "\t\t\tOBJECT=Dimension_7\n",
      "\t\t\t\tDimensionName=\"Band_Number\"\n",
      "\t\t\t\tSize=7\n",
      "\t\t\tEND_OBJECT=Dimension_7\n",
      "\t\t\tOBJECT=Dimension_8\n",
      "\t\t\t\tDimensionName=\"Band_Ratio\"\n",
      "\t\t\t\tSize=5\n",
      "\t\t\tEND_OBJECT=Dimension_8\n",
      "\t\t\tOBJECT=Dimension_9\n",
      "\t\t\t\tDimensionName=\"Band_Forcing\"\n",
      "\t\t\t\tSize=5\n",
      "\t\t\tEND_OBJECT=Dimension_9\n",
      "\t\t\tOBJECT=Dimension_10\n",
      "\t\t\t\tDimensionName=\"Band_Difference\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_10\n",
      "\t\t\tOBJECT=Dimension_11\n",
      "\t\t\t\tDimensionName=\"QA_Parameter_5km\"\n",
      "\t\t\t\tSize=10\n",
      "\t\t\tEND_OBJECT=Dimension_11\n",
      "\t\t\tOBJECT=Dimension_12\n",
      "\t\t\t\tDimensionName=\"QA_Parameter_1km\"\n",
      "\t\t\t\tSize=9\n",
      "\t\t\tEND_OBJECT=Dimension_12\n",
      "\t\t\tOBJECT=Dimension_13\n",
      "\t\t\t\tDimensionName=\"Cloud_Mask_1km_Num_Bytes\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_13\n",
      "\t\t\tOBJECT=Dimension_14\n",
      "\t\t\t\tDimensionName=\"Cloud_Mask_5km_Num_Bytes\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_14\n",
      "\t\t\tOBJECT=Dimension_15\n",
      "\t\t\t\tDimensionName=\"RadTran_NWL\"\n",
      "\t\t\t\tSize=7\n",
      "\t\t\tEND_OBJECT=Dimension_15\n",
      "\t\t\tOBJECT=Dimension_16\n",
      "\t\t\t\tDimensionName=\"RadTran_NRE_Ice\"\n",
      "\t\t\t\tSize=12\n",
      "\t\t\tEND_OBJECT=Dimension_16\n",
      "\t\t\tOBJECT=Dimension_17\n",
      "\t\t\t\tDimensionName=\"RadTran_NRE_Liq\"\n",
      "\t\t\t\tSize=18\n",
      "\t\t\tEND_OBJECT=Dimension_17\n",
      "\t\t\tOBJECT=Dimension_18\n",
      "\t\t\t\tDimensionName=\"SPI_nband\"\n",
      "\t\t\t\tSize=2\n",
      "\t\t\tEND_OBJECT=Dimension_18\n",
      "\t\t\tOBJECT=Dimension_19\n",
      "\t\t\t\tDimensionName=\"RFM_nband\"\n",
      "\t\t\t\tSize=3\n",
      "\t\t\tEND_OBJECT=Dimension_19\n",
      "\t\t\tOBJECT=Dimension_20\n",
      "\t\t\t\tDimensionName=\"ACR_nband\"\n",
      "\t\t\t\tSize=6\n",
      "\t\t\tEND_OBJECT=Dimension_20\n",
      "\t\t\tOBJECT=Dimension_21\n",
      "\t\t\t\tDimensionName=\"Statistic_Parameter_1km\"\n",
      "\t\t\t\tSize=17\n",
      "\t\t\tEND_OBJECT=Dimension_21\n",
      "\t\tEND_GROUP=Dimension\n",
      "\t\tGROUP=DimensionMap\n",
      "\t\t\tOBJECT=DimensionMap_1\n",
      "\t\t\t\tGeoDimension=\"Cell_Across_Swath_5km\"\n",
      "\t\t\t\tDataDimension=\"Cell_Across_Swath_1km\"\n",
      "\t\t\t\tOffset=2\n",
      "\t\t\t\tIncrement=5\n",
      "\t\t\tEND_OBJECT=DimensionMap_1\n",
      "\t\t\tOBJECT=DimensionMap_2\n",
      "\t\t\t\tGeoDimension=\"Cell_Along_Swath_5km\"\n",
      "\t\t\t\tDataDimension=\"Cell_Along_Swath_1km\"\n",
      "\t\t\t\tOffset=2\n",
      "\t\t\t\tIncrement=5\n",
      "\t\t\tEND_OBJECT=DimensionMap_2\n",
      "\t\tEND_GROUP=DimensionMap\n",
      "\t\tGROUP=IndexDimensionMap\n",
      "\t\tEND_GROUP=IndexDimensionMap\n",
      "\t\tGROUP=GeoField\n",
      "\t\t\tOBJECT=GeoField_1\n",
      "\t\t\t\tGeoFieldName=\"Latitude\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=GeoField_1\n",
      "\t\t\tOBJECT=GeoField_2\n",
      "\t\t\t\tGeoFieldName=\"Longitude\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=GeoField_2\n",
      "\t\tEND_GROUP=GeoField\n",
      "\t\tGROUP=DataField\n",
      "\t\t\tOBJECT=DataField_1\n",
      "\t\t\t\tDataFieldName=\"Band_Number\"\n",
      "\t\t\t\tDataType=DFNT_INT32\n",
      "\t\t\t\tDimList=(\"Band_Number\")\n",
      "\t\t\tEND_OBJECT=DataField_1\n",
      "\t\t\tOBJECT=DataField_2\n",
      "\t\t\t\tDataFieldName=\"Statistics_1km\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"Statistic_Parameter_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_2\n",
      "\t\t\tOBJECT=DataField_3\n",
      "\t\t\t\tDataFieldName=\"Scan_Start_Time\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT64\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_3\n",
      "\t\t\tOBJECT=DataField_4\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_4\n",
      "\t\t\tOBJECT=DataField_5\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_5\n",
      "\t\t\tOBJECT=DataField_6\n",
      "\t\t\t\tDataFieldName=\"Solar_Zenith_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_6\n",
      "\t\t\tOBJECT=DataField_7\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_7\n",
      "\t\t\tOBJECT=DataField_8\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_8\n",
      "\t\t\tOBJECT=DataField_9\n",
      "\t\t\t\tDataFieldName=\"Solar_Azimuth_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_9\n",
      "\t\t\tOBJECT=DataField_10\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_10\n",
      "\t\t\tOBJECT=DataField_11\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_11\n",
      "\t\t\tOBJECT=DataField_12\n",
      "\t\t\t\tDataFieldName=\"Sensor_Zenith_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_12\n",
      "\t\t\tOBJECT=DataField_13\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_13\n",
      "\t\t\tOBJECT=DataField_14\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_14\n",
      "\t\t\tOBJECT=DataField_15\n",
      "\t\t\t\tDataFieldName=\"Sensor_Azimuth_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_15\n",
      "\t\t\tOBJECT=DataField_16\n",
      "\t\t\t\tDataFieldName=\"Brightness_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Number\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_16\n",
      "\t\t\tOBJECT=DataField_17\n",
      "\t\t\t\tDataFieldName=\"Surface_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_17\n",
      "\t\t\tOBJECT=DataField_18\n",
      "\t\t\t\tDataFieldName=\"Surface_Pressure\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_18\n",
      "\t\t\tOBJECT=DataField_19\n",
      "\t\t\t\tDataFieldName=\"Cloud_Height_Method\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_19\n",
      "\t\t\tOBJECT=DataField_20\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_20\n",
      "\t\t\tOBJECT=DataField_21\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_21\n",
      "\t\t\tOBJECT=DataField_22\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_22\n",
      "\t\t\tOBJECT=DataField_23\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Height_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_23\n",
      "\t\t\tOBJECT=DataField_24\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_24\n",
      "\t\t\tOBJECT=DataField_25\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_25\n",
      "\t\t\tOBJECT=DataField_26\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_26\n",
      "\t\t\tOBJECT=DataField_27\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_27\n",
      "\t\t\tOBJECT=DataField_28\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_28\n",
      "\t\t\tOBJECT=DataField_29\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_29\n",
      "\t\t\tOBJECT=DataField_30\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_30\n",
      "\t\t\tOBJECT=DataField_31\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_31\n",
      "\t\t\tOBJECT=DataField_32\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_32\n",
      "\t\t\tOBJECT=DataField_33\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_33\n",
      "\t\t\tOBJECT=DataField_34\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_34\n",
      "\t\t\tOBJECT=DataField_35\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Temperature_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_35\n",
      "\t\t\tOBJECT=DataField_36\n",
      "\t\t\t\tDataFieldName=\"Tropopause_Height\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_36\n",
      "\t\t\tOBJECT=DataField_37\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_37\n",
      "\t\t\tOBJECT=DataField_38\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_38\n",
      "\t\t\tOBJECT=DataField_39\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_39\n",
      "\t\t\tOBJECT=DataField_40\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_40\n",
      "\t\t\tOBJECT=DataField_41\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_41\n",
      "\t\t\tOBJECT=DataField_42\n",
      "\t\t\t\tDataFieldName=\"Cloud_Fraction_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_42\n",
      "\t\t\tOBJECT=DataField_43\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_43\n",
      "\t\t\tOBJECT=DataField_44\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_44\n",
      "\t\t\tOBJECT=DataField_45\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_45\n",
      "\t\t\tOBJECT=DataField_46\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_46\n",
      "\t\t\tOBJECT=DataField_47\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_47\n",
      "\t\t\tOBJECT=DataField_48\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Emissivity_Nadir_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_48\n",
      "\t\t\tOBJECT=DataField_49\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_Infrared\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_49\n",
      "\t\t\tOBJECT=DataField_50\n",
      "\t\t\t\tDataFieldName=\"Spectral_Cloud_Forcing\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Forcing\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_50\n",
      "\t\t\tOBJECT=DataField_51\n",
      "\t\t\t\tDataFieldName=\"Cloud_Top_Pressure_From_Ratios\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Band_Ratio\",\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_51\n",
      "\t\t\tOBJECT=DataField_52\n",
      "\t\t\t\tDataFieldName=\"Radiance_Variance\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_52\n",
      "\t\t\tOBJECT=DataField_53\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_53\n",
      "\t\t\tOBJECT=DataField_54\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_Night\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_54\n",
      "\t\t\tOBJECT=DataField_55\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_Day\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_55\n",
      "\t\t\tOBJECT=DataField_56\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Infrared_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_56\n",
      "\t\t\tOBJECT=DataField_57\n",
      "\t\t\t\tDataFieldName=\"IRP_CTH_Consistency_Flag_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_57\n",
      "\t\t\tOBJECT=DataField_58\n",
      "\t\t\t\tDataFieldName=\"os_top_flag_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_58\n",
      "\t\t\tOBJECT=DataField_59\n",
      "\t\t\t\tDataFieldName=\"cloud_top_pressure_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_59\n",
      "\t\t\tOBJECT=DataField_60\n",
      "\t\t\t\tDataFieldName=\"cloud_top_height_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_60\n",
      "\t\t\tOBJECT=DataField_61\n",
      "\t\t\t\tDataFieldName=\"cloud_top_temperature_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_61\n",
      "\t\t\tOBJECT=DataField_62\n",
      "\t\t\t\tDataFieldName=\"cloud_emissivity_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_62\n",
      "\t\t\tOBJECT=DataField_63\n",
      "\t\t\t\tDataFieldName=\"cloud_top_method_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_63\n",
      "\t\t\tOBJECT=DataField_64\n",
      "\t\t\t\tDataFieldName=\"surface_temperature_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_64\n",
      "\t\t\tOBJECT=DataField_65\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss11_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_65\n",
      "\t\t\tOBJECT=DataField_66\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss12_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_66\n",
      "\t\t\tOBJECT=DataField_67\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss13_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_67\n",
      "\t\t\tOBJECT=DataField_68\n",
      "\t\t\t\tDataFieldName=\"cloud_emiss85_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_68\n",
      "\t\t\tOBJECT=DataField_69\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_69\n",
      "\t\t\tOBJECT=DataField_70\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_70\n",
      "\t\t\tOBJECT=DataField_71\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_71\n",
      "\t\t\tOBJECT=DataField_72\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_72\n",
      "\t\t\tOBJECT=DataField_73\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_73\n",
      "\t\t\tOBJECT=DataField_74\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_74\n",
      "\t\t\tOBJECT=DataField_75\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_75\n",
      "\t\t\tOBJECT=DataField_76\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_76\n",
      "\t\t\tOBJECT=DataField_77\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_77\n",
      "\t\t\tOBJECT=DataField_78\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_78\n",
      "\t\t\tOBJECT=DataField_79\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_79\n",
      "\t\t\tOBJECT=DataField_80\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_80\n",
      "\t\t\tOBJECT=DataField_81\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_81\n",
      "\t\t\tOBJECT=DataField_82\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_82\n",
      "\t\t\tOBJECT=DataField_83\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_83\n",
      "\t\t\tOBJECT=DataField_84\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_84\n",
      "\t\t\tOBJECT=DataField_85\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_85\n",
      "\t\t\tOBJECT=DataField_86\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_86\n",
      "\t\t\tOBJECT=DataField_87\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_87\n",
      "\t\t\tOBJECT=DataField_88\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_1621_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_88\n",
      "\t\t\tOBJECT=DataField_89\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_89\n",
      "\t\t\tOBJECT=DataField_90\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_16_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_90\n",
      "\t\t\tOBJECT=DataField_91\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_91\n",
      "\t\t\tOBJECT=DataField_92\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_37_PCL\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_92\n",
      "\t\t\tOBJECT=DataField_93\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_93\n",
      "\t\t\tOBJECT=DataField_94\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_94\n",
      "\t\t\tOBJECT=DataField_95\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_95\n",
      "\t\t\tOBJECT=DataField_96\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_96\n",
      "\t\t\tOBJECT=DataField_97\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_97\n",
      "\t\t\tOBJECT=DataField_98\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_98\n",
      "\t\t\tOBJECT=DataField_99\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_99\n",
      "\t\t\tOBJECT=DataField_100\n",
      "\t\t\t\tDataFieldName=\"Cloud_Effective_Radius_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_100\n",
      "\t\t\tOBJECT=DataField_101\n",
      "\t\t\t\tDataFieldName=\"Cloud_Optical_Thickness_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_101\n",
      "\t\t\tOBJECT=DataField_102\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_102\n",
      "\t\t\tOBJECT=DataField_103\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_103\n",
      "\t\t\tOBJECT=DataField_104\n",
      "\t\t\t\tDataFieldName=\"Cloud_Water_Path_Uncertainty_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_104\n",
      "\t\t\tOBJECT=DataField_105\n",
      "\t\t\t\tDataFieldName=\"Above_Cloud_Water_Vapor_094\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_105\n",
      "\t\t\tOBJECT=DataField_106\n",
      "\t\t\t\tDataFieldName=\"IRW_Low_Cloud_Temperature_From_COP\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_106\n",
      "\t\t\tOBJECT=DataField_107\n",
      "\t\t\t\tDataFieldName=\"Cloud_Phase_Optical_Properties\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_107\n",
      "\t\t\tOBJECT=DataField_108\n",
      "\t\t\t\tDataFieldName=\"Cloud_Multi_Layer_Flag\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_108\n",
      "\t\t\tOBJECT=DataField_109\n",
      "\t\t\t\tDataFieldName=\"Cirrus_Reflectance\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_109\n",
      "\t\t\tOBJECT=DataField_110\n",
      "\t\t\t\tDataFieldName=\"Cirrus_Reflectance_Flag\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_110\n",
      "\t\t\tOBJECT=DataField_111\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_5km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\",\"Cloud_Mask_5km_Num_Bytes\")\n",
      "\t\t\tEND_OBJECT=DataField_111\n",
      "\t\t\tOBJECT=DataField_112\n",
      "\t\t\t\tDataFieldName=\"Quality_Assurance_5km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_5km\",\"Cell_Across_Swath_5km\",\"QA_Parameter_5km\")\n",
      "\t\t\tEND_OBJECT=DataField_112\n",
      "\t\t\tOBJECT=DataField_113\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"Cloud_Mask_1km_Num_Bytes\")\n",
      "\t\t\tEND_OBJECT=DataField_113\n",
      "\t\t\tOBJECT=DataField_114\n",
      "\t\t\t\tDataFieldName=\"Extinction_Efficiency_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_114\n",
      "\t\t\tOBJECT=DataField_115\n",
      "\t\t\t\tDataFieldName=\"Asymmetry_Parameter_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_115\n",
      "\t\t\tOBJECT=DataField_116\n",
      "\t\t\t\tDataFieldName=\"Single_Scatter_Albedo_Ice\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Ice\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_116\n",
      "\t\t\tOBJECT=DataField_117\n",
      "\t\t\t\tDataFieldName=\"Extinction_Efficiency_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_117\n",
      "\t\t\tOBJECT=DataField_118\n",
      "\t\t\t\tDataFieldName=\"Asymmetry_Parameter_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_118\n",
      "\t\t\tOBJECT=DataField_119\n",
      "\t\t\t\tDataFieldName=\"Single_Scatter_Albedo_Liq\"\n",
      "\t\t\t\tDataType=DFNT_FLOAT32\n",
      "\t\t\t\tDimList=(\"RadTran_NRE_Liq\",\"RadTran_NWL\")\n",
      "\t\t\tEND_OBJECT=DataField_119\n",
      "\t\t\tOBJECT=DataField_120\n",
      "\t\t\t\tDataFieldName=\"Cloud_Mask_SPI\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"SPI_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_120\n",
      "\t\t\tOBJECT=DataField_121\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_121\n",
      "\t\t\tOBJECT=DataField_122\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_16\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_122\n",
      "\t\t\tOBJECT=DataField_123\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_37\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_123\n",
      "\t\t\tOBJECT=DataField_124\n",
      "\t\t\t\tDataFieldName=\"Retrieval_Failure_Metric_1621\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"RFM_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_124\n",
      "\t\t\tOBJECT=DataField_125\n",
      "\t\t\t\tDataFieldName=\"Atm_Corr_Refl\"\n",
      "\t\t\t\tDataType=DFNT_INT16\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"ACR_nband\")\n",
      "\t\t\tEND_OBJECT=DataField_125\n",
      "\t\t\tOBJECT=DataField_126\n",
      "\t\t\t\tDataFieldName=\"Quality_Assurance_1km\"\n",
      "\t\t\t\tDataType=DFNT_INT8\n",
      "\t\t\t\tDimList=(\"Cell_Along_Swath_1km\",\"Cell_Across_Swath_1km\",\"QA_Parameter_1km\")\n",
      "\t\t\tEND_OBJECT=DataField_126\n",
      "\t\tEND_GROUP=DataField\n",
      "\t\tGROUP=MergedFields\n",
      "\t\tEND_GROUP=MergedFields\n",
      "\tEND_GROUP=SWATH_1\n",
      "END_GROUP=SwathStructure\n",
      "GROUP=GridStructure\n",
      "END_GROUP=GridStructure\n",
      "GROUP=PointStructure\n",
      "END_GROUP=PointStructure\n",
      "END\n",
      "\n",
      "    Number_of_Instrument_Scans: 2040\n",
      "    Maximum_Number_of_1km_Frames: 1354\n",
      "    history: $Id: MOD06_L2.CDL.fs,v 1.13 2013/06/19 15:38:46 wind Exp $                          \n",
      "\n",
      "    title: MODIS Level 2 Cloud Properties                                                      \n",
      "\n",
      "    CoreMetadata.0: \n",
      "GROUP                  = INVENTORYMETADATA\n",
      "  GROUPTYPE            = MASTERGROUP\n",
      "\n",
      "  GROUP                  = ECSDATAGRANULE\n",
      "\n",
      "    OBJECT                 = REPROCESSINGPLANNED\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"further update is anticipated\"\n",
      "    END_OBJECT             = REPROCESSINGPLANNED\n",
      "\n",
      "    OBJECT                 = REPROCESSINGACTUAL\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"processed once\"\n",
      "    END_OBJECT             = REPROCESSINGACTUAL\n",
      "\n",
      "    OBJECT                 = LOCALGRANULEID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MYD06_L2.A2002185.0000.061.2018003215042.hdf\"\n",
      "    END_OBJECT             = LOCALGRANULEID\n",
      "\n",
      "    OBJECT                 = DAYNIGHTFLAG\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"Night\"\n",
      "    END_OBJECT             = DAYNIGHTFLAG\n",
      "\n",
      "    OBJECT                 = PRODUCTIONDATETIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2018-01-03T21:50:42.000Z\"\n",
      "    END_OBJECT             = PRODUCTIONDATETIME\n",
      "\n",
      "    OBJECT                 = LOCALVERSIONID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"061\"\n",
      "    END_OBJECT             = LOCALVERSIONID\n",
      "\n",
      "  END_GROUP              = ECSDATAGRANULE\n",
      "\n",
      "  GROUP                  = MEASUREDPARAMETER\n",
      "\n",
      "    OBJECT                 = MEASUREDPARAMETERCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = PARAMETERNAME\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"Cloud_Top_Pressure\"\n",
      "      END_OBJECT             = PARAMETERNAME\n",
      "\n",
      "      GROUP                  = QAFLAGS\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = AUTOMATICQUALITYFLAG\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"Passed\"\n",
      "        END_OBJECT             = AUTOMATICQUALITYFLAG\n",
      "\n",
      "        OBJECT                 = AUTOMATICQUALITYFLAGEXPLANATION\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"Passed: >10% useable; Failed: <10% useable\"\n",
      "        END_OBJECT             = AUTOMATICQUALITYFLAGEXPLANATION\n",
      "\n",
      "        OBJECT                 = SCIENCEQUALITYFLAG\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = \"Not Investigated\"\n",
      "          CLASS                = \"1\"\n",
      "        END_OBJECT             = SCIENCEQUALITYFLAG\n",
      "\n",
      "        OBJECT                 = SCIENCEQUALITYFLAGEXPLANATION\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = \"See http://modis-atmos.gsfc.nasa.gov/validation.html for more details on MODIS Atmosphere data quality.\"\n",
      "          CLASS                = \"1\"\n",
      "        END_OBJECT             = SCIENCEQUALITYFLAGEXPLANATION\n",
      "\n",
      "      END_GROUP              = QAFLAGS\n",
      "\n",
      "      GROUP                  = QASTATS\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = QAPERCENTMISSINGDATA\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = 63\n",
      "        END_OBJECT             = QAPERCENTMISSINGDATA\n",
      "\n",
      "      END_GROUP              = QASTATS\n",
      "\n",
      "    END_OBJECT             = MEASUREDPARAMETERCONTAINER\n",
      "\n",
      "  END_GROUP              = MEASUREDPARAMETER\n",
      "\n",
      "  GROUP                  = ORBITCALCULATEDSPATIALDOMAIN\n",
      "\n",
      "    OBJECT                 = ORBITCALCULATEDSPATIALDOMAINCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ORBITNUMBER\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = 885\n",
      "      END_OBJECT             = ORBITNUMBER\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGLONGITUDE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = 20.4199118302919\n",
      "      END_OBJECT             = EQUATORCROSSINGLONGITUDE\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGTIME\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"00:12:58.823356\"\n",
      "      END_OBJECT             = EQUATORCROSSINGTIME\n",
      "\n",
      "      OBJECT                 = EQUATORCROSSINGDATE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"2002-07-04\"\n",
      "      END_OBJECT             = EQUATORCROSSINGDATE\n",
      "\n",
      "    END_OBJECT             = ORBITCALCULATEDSPATIALDOMAINCONTAINER\n",
      "\n",
      "  END_GROUP              = ORBITCALCULATEDSPATIALDOMAIN\n",
      "\n",
      "  GROUP                  = COLLECTIONDESCRIPTIONCLASS\n",
      "\n",
      "    OBJECT                 = SHORTNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MYD06_L2\"\n",
      "    END_OBJECT             = SHORTNAME\n",
      "\n",
      "    OBJECT                 = VERSIONID\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = 61\n",
      "    END_OBJECT             = VERSIONID\n",
      "\n",
      "  END_GROUP              = COLLECTIONDESCRIPTIONCLASS\n",
      "\n",
      "  GROUP                  = INPUTGRANULE\n",
      "\n",
      "    OBJECT                 = INPUTPOINTER\n",
      "      NUM_VAL              = 50\n",
      "      VALUE                = (\"MYD021KM.A2002185.0000.061.2017363141721.hdf\", \"MYD03.A2002185.0000.061.2017362174430.hdf\", \"MYD35_L2.A2002185.0000.061.2017363141846.hdf\", \"gdas1.PGrbF00.020704.00z\", \"oisst.20020703\", \"goge1_2_img.v1\", \"modisdet.dry.101.lit_end.v3\", \"\n",
      "          modisdet.ozo.101.lit_end.v3\", \"modisdet.wts.101.lit_end.v3\", \"modisdet.wtl.101.lit_end.v3\", \"modisdet.wco.101.lit_end.v3\", \"MYDCSR_B.A2002185.061.2017363154239.hdf\", \"gdas1.PGrbF00.020704.06z\", \"eng.020704\", \"NISE_SSMIF13_20020704.HDFEOS\", \"MODIS_Ice_library.hdf.v5\", \"\n",
      "          MODIS_Water_library.hdf.v4\", \"MODIS_Ice_library_ws3.hdf.v3\", \"MODIS_Ice_library_ws3sd.hdf.v4\", \"MODIS_Ice_library_ws7.hdf.v3\", \"MODIS_Ice_library_ws7sd.hdf.v4\", \"MODIS_Ice_library_ws15.hdf.v3\", \"MODIS_Ice_library_ws15sd.hdf.v4\", \"MODIS_Water_library_ws3.hdf.v2\", \"\n",
      "          MODIS_Water_library_ws3sd.hdf.v3\", \"MODIS_Water_library_ws7.hdf.v2\", \"MODIS_Water_library_ws7sd.hdf.v3\", \"MODIS_Water_library_ws15.hdf.v2\", \"MODIS_Water_library_ws15sd.hdf.v3\", \"MODIS_Ice_WaterPhaseFunc.hdf.v3\", \"Transmittance.hdf.v2\", \"IGBP.EcoMap.NtoS.2004.149.v004.hdf\", \"\n",
      "          AlbSnwStst.ByNISE.W90.D90.WS.Hemi.2000-2004.YrAvg.hdf\", \"MCD43GF_wsa_Band1_185_2002_V006.hdf\", \"MCD43GF_wsa_Band2_185_2002_V006.hdf\", \"MCD43GF_wsa_Band5_185_2002_V006.hdf\", \"MCD43GF_wsa_Band6_185_2002_V006.hdf\", \"MCD43GF_wsa_Band7_185_2002_V006.hdf\")\n",
      "    END_OBJECT             = INPUTPOINTER\n",
      "\n",
      "  END_GROUP              = INPUTGRANULE\n",
      "\n",
      "  GROUP                  = SPATIALDOMAINCONTAINER\n",
      "\n",
      "    GROUP                  = HORIZONTALSPATIALDOMAINCONTAINER\n",
      "\n",
      "      GROUP                  = BOUNDINGRECTANGLE\n",
      "\n",
      "        OBJECT                 = WESTBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 15.0125121267976\n",
      "        END_OBJECT             = WESTBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = NORTHBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 47.4712121222453\n",
      "        END_OBJECT             = NORTHBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = EASTBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 46.3027701461145\n",
      "        END_OBJECT             = EASTBOUNDINGCOORDINATE\n",
      "\n",
      "        OBJECT                 = SOUTHBOUNDINGCOORDINATE\n",
      "          NUM_VAL              = 1\n",
      "          VALUE                = 26.6036189855835\n",
      "        END_OBJECT             = SOUTHBOUNDINGCOORDINATE\n",
      "\n",
      "      END_GROUP              = BOUNDINGRECTANGLE\n",
      "\n",
      "    END_GROUP              = HORIZONTALSPATIALDOMAINCONTAINER\n",
      "\n",
      "  END_GROUP              = SPATIALDOMAINCONTAINER\n",
      "\n",
      "  GROUP                  = RANGEDATETIME\n",
      "\n",
      "    OBJECT                 = RANGEBEGINNINGDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2002-07-04\"\n",
      "    END_OBJECT             = RANGEBEGINNINGDATE\n",
      "\n",
      "    OBJECT                 = RANGEBEGINNINGTIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"00:00:00.000000\"\n",
      "    END_OBJECT             = RANGEBEGINNINGTIME\n",
      "\n",
      "    OBJECT                 = RANGEENDINGDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2002-07-04\"\n",
      "    END_OBJECT             = RANGEENDINGDATE\n",
      "\n",
      "    OBJECT                 = RANGEENDINGTIME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"00:05:00.000000\"\n",
      "    END_OBJECT             = RANGEENDINGTIME\n",
      "\n",
      "  END_GROUP              = RANGEDATETIME\n",
      "\n",
      "  GROUP                  = PGEVERSIONCLASS\n",
      "\n",
      "    OBJECT                 = PGEVERSION\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"6.1.4\"\n",
      "    END_OBJECT             = PGEVERSION\n",
      "\n",
      "  END_GROUP              = PGEVERSIONCLASS\n",
      "\n",
      "  GROUP                  = ANCILLARYINPUTGRANULE\n",
      "\n",
      "    OBJECT                 = ANCILLARYINPUTGRANULECONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ANCILLARYINPUTTYPE\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"Geolocation\"\n",
      "      END_OBJECT             = ANCILLARYINPUTTYPE\n",
      "\n",
      "      OBJECT                 = ANCILLARYINPUTPOINTER\n",
      "        NUM_VAL              = 1\n",
      "        CLASS                = \"1\"\n",
      "        VALUE                = \"MYD03.A2002185.0000.061.2017362174430.hdf\"\n",
      "      END_OBJECT             = ANCILLARYINPUTPOINTER\n",
      "\n",
      "    END_OBJECT             = ANCILLARYINPUTGRANULECONTAINER\n",
      "\n",
      "  END_GROUP              = ANCILLARYINPUTGRANULE\n",
      "\n",
      "  GROUP                  = ASSOCIATEDPLATFORMINSTRUMENTSENSOR\n",
      "\n",
      "    OBJECT                 = ASSOCIATEDPLATFORMINSTRUMENTSENSORCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDSENSORSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MODIS\"\n",
      "      END_OBJECT             = ASSOCIATEDSENSORSHORTNAME\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDPLATFORMSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"Aqua\"\n",
      "      END_OBJECT             = ASSOCIATEDPLATFORMSHORTNAME\n",
      "\n",
      "      OBJECT                 = ASSOCIATEDINSTRUMENTSHORTNAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MODIS\"\n",
      "      END_OBJECT             = ASSOCIATEDINSTRUMENTSHORTNAME\n",
      "\n",
      "    END_OBJECT             = ASSOCIATEDPLATFORMINSTRUMENTSENSORCONTAINER\n",
      "\n",
      "  END_GROUP              = ASSOCIATEDPLATFORMINSTRUMENTSENSOR\n",
      "\n",
      "  GROUP                  = ADDITIONALATTRIBUTES\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"1\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SuccessCloudTopPropRtrPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"   36.98\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"2\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"2\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SuccessCloudPhaseRtrPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"2\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"2\"\n",
      "          VALUE                = \"   36.66\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"4\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"4\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"LowCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"4\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"4\"\n",
      "          VALUE                = \"   32.12\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"5\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"5\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MidCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"5\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"5\"\n",
      "          VALUE                = \"    2.40\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"6\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"6\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"HighCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"6\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"6\"\n",
      "          VALUE                = \"    2.45\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"7\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"7\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"ThinCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"7\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"7\"\n",
      "          VALUE                = \"    9.74\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"8\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"8\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"ThickCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"8\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"8\"\n",
      "          VALUE                = \"   10.37\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"9\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"9\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"OpaqueCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"9\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"9\"\n",
      "          VALUE                = \"   16.86\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"10\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"10\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"CirrusCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"10\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"10\"\n",
      "          VALUE                = \"   20.12\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"11\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"11\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"IceCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"11\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"11\"\n",
      "          VALUE                = \"    1.27\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"12\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"12\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"WaterCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"12\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"12\"\n",
      "          VALUE                = \"   32.99\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"13\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"13\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"MixedCloudDetectedPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"13\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"13\"\n",
      "          VALUE                = \"    0.00\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"14\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"14\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"CloudPhaseUncertainPct_IR\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"14\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"14\"\n",
      "          VALUE                = \"    2.40\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"15\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"15\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"OceanCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"15\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"15\"\n",
      "          VALUE                = \"   45.11\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"16\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"16\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"LandCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"16\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"16\"\n",
      "          VALUE                = \"   54.89\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"17\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"17\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"SnowCoverFractionPct\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"17\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"17\"\n",
      "          VALUE                = \"    0.06\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"18\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"18\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"identifier_product_doi\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"18\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"18\"\n",
      "          VALUE                = \"10.5067/MODIS/MYD06_L2.061\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "    OBJECT                 = ADDITIONALATTRIBUTESCONTAINER\n",
      "      CLASS                = \"19\"\n",
      "\n",
      "      OBJECT                 = ADDITIONALATTRIBUTENAME\n",
      "        CLASS                = \"19\"\n",
      "        NUM_VAL              = 1\n",
      "        VALUE                = \"identifier_product_doi_authority\"\n",
      "      END_OBJECT             = ADDITIONALATTRIBUTENAME\n",
      "\n",
      "      GROUP                  = INFORMATIONCONTENT\n",
      "        CLASS                = \"19\"\n",
      "\n",
      "        OBJECT                 = PARAMETERVALUE\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"19\"\n",
      "          VALUE                = \"http://dx.doi.org\"\n",
      "        END_OBJECT             = PARAMETERVALUE\n",
      "\n",
      "      END_GROUP              = INFORMATIONCONTENT\n",
      "\n",
      "    END_OBJECT             = ADDITIONALATTRIBUTESCONTAINER\n",
      "\n",
      "  END_GROUP              = ADDITIONALATTRIBUTES\n",
      "\n",
      "END_GROUP              = INVENTORYMETADATA\n",
      "\n",
      "END\n",
      "\n",
      "    ArchiveMetadata.0: \n",
      "GROUP                  = ARCHIVEDMETADATA\n",
      "  GROUPTYPE            = MASTERGROUP\n",
      "\n",
      "  OBJECT                 = PROCESSINGENVIRONMENT\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"Linux minion7260 3.10.0-693.11.1.el7.x86_64 #1 SMP Mon Dec 4 23:52:40 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\"\n",
      "  END_OBJECT             = PROCESSINGENVIRONMENT\n",
      "\n",
      "  GROUP                  = ALGORITHMPACKAGE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEACCEPTANCEDATE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"June 1997\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEACCEPTANCEDATE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEMATURITYCODE\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"at-launch\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEMATURITYCODE\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGENAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"ATBD-MOD-04 and ATBD-MOD-05\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGENAME\n",
      "\n",
      "    OBJECT                 = ALGORITHMPACKAGEVERSION\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"2\"\n",
      "    END_OBJECT             = ALGORITHMPACKAGEVERSION\n",
      "\n",
      "    OBJECT                 = INSTRUMENTNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"Moderate Resolution Imaging Spectroradiometer\"\n",
      "    END_OBJECT             = INSTRUMENTNAME\n",
      "\n",
      "    OBJECT                 = LONGNAME\n",
      "      NUM_VAL              = 1\n",
      "      VALUE                = \"MODIS/Aqua Clouds 5-Min L2 Swath 1km and 5km\"\n",
      "    END_OBJECT             = LONGNAME\n",
      "\n",
      "    OBJECT                 = LOCALINPUTGRANULEID\n",
      "      NUM_VAL              = 20\n",
      "      VALUE                = (\"MYD021KM.A2002185.0000.061.2017363141721.hdf\", \"MYD03.A2002185.0000.061.2017362174430.hdf\", \"MYD35_L2.A2002185.0000.061.2017363141846.hdf\", \"MYDCSR_B.A2002185.061.2017363154239.hdf\")\n",
      "    END_OBJECT             = LOCALINPUTGRANULEID\n",
      "\n",
      "  END_GROUP              = ALGORITHMPACKAGE\n",
      "\n",
      "  GROUP                  = GPOLYGON\n",
      "\n",
      "    OBJECT                 = GPOLYGONCONTAINER\n",
      "      CLASS                = \"1\"\n",
      "\n",
      "      GROUP                  = GRING\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = EXCLUSIONGRINGFLAG\n",
      "          NUM_VAL              = 1\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = \"N\"\n",
      "        END_OBJECT             = EXCLUSIONGRINGFLAG\n",
      "\n",
      "      END_GROUP              = GRING\n",
      "\n",
      "      GROUP                  = GRINGPOINT\n",
      "        CLASS                = \"1\"\n",
      "\n",
      "        OBJECT                 = GRINGPOINTLONGITUDE\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (16.6802142122724, 46.3037511907536, 38.7590005022001, 14.9898525858698)\n",
      "        END_OBJECT             = GRINGPOINTLONGITUDE\n",
      "\n",
      "        OBJECT                 = GRINGPOINTLATITUDE\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (47.4897565211684, 43.2358532665263, 26.5236230538033, 29.7440219071349)\n",
      "        END_OBJECT             = GRINGPOINTLATITUDE\n",
      "\n",
      "        OBJECT                 = GRINGPOINTSEQUENCENO\n",
      "          NUM_VAL              = 4\n",
      "          CLASS                = \"1\"\n",
      "          VALUE                = (1, 2, 3, 4)\n",
      "        END_OBJECT             = GRINGPOINTSEQUENCENO\n",
      "\n",
      "      END_GROUP              = GRINGPOINT\n",
      "\n",
      "    END_OBJECT             = GPOLYGONCONTAINER\n",
      "\n",
      "  END_GROUP              = GPOLYGON\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_TOP_PROPERTY_IR\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_TOP_PROPERTY_IR\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_PHASE_IR\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_PHASE_IR\n",
      "\n",
      "  OBJECT                 = ALGORITHM_VERSION_CLOUD_PROPERTY_VIS\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"1\"\n",
      "  END_OBJECT             = ALGORITHM_VERSION_CLOUD_PROPERTY_VIS\n",
      "\n",
      "  OBJECT                 = DESCRREVISION\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"6.1\"\n",
      "  END_OBJECT             = DESCRREVISION\n",
      "\n",
      "  OBJECT                 = PRODUCTIONHISTORY\n",
      "    NUM_VAL              = 1\n",
      "    VALUE                = \"PGE06:6.1.4\"\n",
      "  END_OBJECT             = PRODUCTIONHISTORY\n",
      "\n",
      "END_GROUP              = ARCHIVEDMETADATA\n",
      "\n",
      "END\n",
      "\n",
      "    Clear_Sky_Restoral_Status: y\n",
      "    Collection_4_Phase_Used: n\n",
      "    Ice_Phase_Forced: n\n",
      "    Water_Phase_Forced: n\n",
      "    identifier_product_doi: 10.5067/MODIS/MYD06_L2.061\n",
      "    identifier_product_doi_authority: http://dx.doi.org\n",
      "    dimensions(sizes): Cell_Along_Swath_5km:mod06(408), Cell_Across_Swath_5km:mod06(270), Band_Number:mod06(7), Band_Forcing:mod06(5), Band_Ratio:mod06(5), Cell_Along_Swath_1km:mod06(2040), Cell_Across_Swath_1km:mod06(1354), Cloud_Mask_5km_Num_Bytes:mod06(2), QA_Parameter_5km:mod06(10), Cloud_Mask_1km_Num_Bytes:mod06(2), RadTran_NRE_Ice:mod06(12), RadTran_NWL:mod06(7), RadTran_NRE_Liq:mod06(18), SPI_nband:mod06(2), RFM_nband:mod06(3), ACR_nband:mod06(6), QA_Parameter_1km:mod06(9), fakeDim17(17)\n",
      "    variables(dimensions): >f4 \u001b[4mLatitude\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >f4 \u001b[4mLongitude\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >f8 \u001b[4mScan_Start_Time\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Zenith_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSolar_Azimuth_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Zenith_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSensor_Azimuth_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mBrightness_Temperature\u001b[0m(Band_Number:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSurface_Temperature\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSurface_Pressure\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Height_Method\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Height_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Temperature_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mTropopause_Height\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Fraction_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Effective_Emissivity_Nadir_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_Infrared\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mSpectral_Cloud_Forcing\u001b[0m(Band_Forcing:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mCloud_Top_Pressure_From_Ratios\u001b[0m(Band_Ratio:mod06,Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), >i2 \u001b[4mRadiance_Variance\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_Night\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_Day\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06), int8 \u001b[4mCloud_Phase_Infrared_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mIRP_CTH_Consistency_Flag_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mos_top_flag_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_pressure_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_height_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_top_temperature_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mcloud_emissivity_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mcloud_top_method_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4msurface_temperature_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss11_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss12_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss13_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mcloud_emiss85_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_1621_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_16_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_37_PCL\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Effective_Radius_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Optical_Thickness_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCloud_Water_Path_Uncertainty_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mAbove_Cloud_Water_Vapor_094\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mIRW_Low_Cloud_Temperature_From_COP\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Phase_Optical_Properties\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Multi_Layer_Flag\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), >i2 \u001b[4mCirrus_Reflectance\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCirrus_Reflectance_Flag\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06), int8 \u001b[4mCloud_Mask_5km\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06,Cloud_Mask_5km_Num_Bytes:mod06), int8 \u001b[4mQuality_Assurance_5km\u001b[0m(Cell_Along_Swath_5km:mod06,Cell_Across_Swath_5km:mod06,QA_Parameter_5km:mod06), int8 \u001b[4mCloud_Mask_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,Cloud_Mask_1km_Num_Bytes:mod06), >f4 \u001b[4mExtinction_Efficiency_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mAsymmetry_Parameter_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mSingle_Scatter_Albedo_Ice\u001b[0m(RadTran_NRE_Ice:mod06,RadTran_NWL:mod06), >f4 \u001b[4mExtinction_Efficiency_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >f4 \u001b[4mAsymmetry_Parameter_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >f4 \u001b[4mSingle_Scatter_Albedo_Liq\u001b[0m(RadTran_NRE_Liq:mod06,RadTran_NWL:mod06), >i2 \u001b[4mCloud_Mask_SPI\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,SPI_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_16\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_37\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mRetrieval_Failure_Metric_1621\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,RFM_nband:mod06), >i2 \u001b[4mAtm_Corr_Refl\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,ACR_nband:mod06), int8 \u001b[4mQuality_Assurance_1km\u001b[0m(Cell_Along_Swath_1km:mod06,Cell_Across_Swath_1km:mod06,QA_Parameter_1km:mod06), >f4 \u001b[4mStatistics_1km_sds\u001b[0m(fakeDim17)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(MOD06)\n",
    "data = MOD06\n",
    "print(\"---------------\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-af3aea3ae2ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, coords, dims, name, attrs, encoding, fastpath)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dims'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dims'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attrs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "foo = xr.DataArray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = data.variables['Cloud_Mask_1km'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOD03 = Dataset('/Users/saviosebastian/Desktop/XArraysTest/MYD03.A2002185.0000.061.2017362174430.hdf', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = MOD03.variables['Latitude'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        ...,\n",
       "        [30.023902893066406, 30.0213565826416, 30.018844604492188, ...,\n",
       "         26.660354614257812, 26.649608612060547, 26.63867950439453],\n",
       "        [30.005863189697266, 30.003368377685547, 30.000919342041016, ...,\n",
       "         26.643115997314453, 26.632293701171875, 26.621292114257812],\n",
       "        [29.987855911254883, 29.985397338867188, 29.982986450195312, ...,\n",
       "         26.62582778930664, 26.614887237548828, 26.603618621826172]],\n",
       "  mask=[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "  fill_value=-999.0,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = MOD03.variables['Longitude'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        ...,\n",
       "        [15.015028953552246, 15.064740180969238, 15.11345100402832, ...,\n",
       "         38.32621383666992, 38.37139129638672, 38.41727066040039],\n",
       "        [15.014087677001953, 15.063920021057129, 15.112410545349121, ...,\n",
       "         38.32081985473633, 38.366085052490234, 38.41202926635742],\n",
       "        [15.01251220703125, 15.062713623046875, 15.111570358276367, ...,\n",
       "         38.31563949584961, 38.36115646362305, 38.4079704284668]],\n",
       "  mask=[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "  fill_value=-999.0,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        ...,\n",
       "        [15.015028953552246, 15.064740180969238, 15.11345100402832, ...,\n",
       "         38.32621383666992, 38.37139129638672, 38.41727066040039],\n",
       "        [15.014087677001953, 15.063920021057129, 15.112410545349121, ...,\n",
       "         38.32081985473633, 38.366085052490234, 38.41202926635742],\n",
       "        [15.01251220703125, 15.062713623046875, 15.111570358276367, ...,\n",
       "         38.31563949584961, 38.36115646362305, 38.4079704284668]],\n",
       "  mask=[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "  fill_value=-999.0,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        ...,\n",
       "        [15.015028953552246, 15.064740180969238, 15.11345100402832, ...,\n",
       "         38.32621383666992, 38.37139129638672, 38.41727066040039],\n",
       "        [15.014087677001953, 15.063920021057129, 15.112410545349121, ...,\n",
       "         38.32081985473633, 38.366085052490234, 38.41202926635742],\n",
       "        [15.01251220703125, 15.062713623046875, 15.111570358276367, ...,\n",
       "         38.31563949584961, 38.36115646362305, 38.4079704284668]],\n",
       "  mask=[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "  fill_value=-999.0,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lat=np.ravel(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[--, --, --, ..., 26.62582778930664, 26.614887237548828,\n",
       "                   26.603618621826172],\n",
       "             mask=[ True,  True,  True, ..., False, False, False],\n",
       "       fill_value=-999.0,\n",
       "            dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon=np.ravel(long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM=np.ravel(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[--, --, --, ..., --, --, --],\n",
       "             mask=[ True,  True,  True, ...,  True,  True,  True],\n",
       "       fill_value=0,\n",
       "            dtype=int8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of pixels in this granule (cloud mask CM>=0) --\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total Number of pixels in this granule (cloud mask CM>=0)',np.sum(CM>=0)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_bnd = np.arange(-90,91,1)\n",
    "lon_bnd = np.arange(-180,180,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlat = 180\n",
    "nlon = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT_pix      = np.zeros(nlat*nlon)\n",
    "CLD_pix      = np.zeros(nlat*nlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_index = value_locate(lat_bnd,Lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_index = value_locate(lon_bnd,Lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_index = lat_index*nlon + lon_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_index_unique = np.unique(latlon_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(latlon_index_unique.size):\n",
    "    j=latlon_index_unique[i]\n",
    "    TOT_pix[j] = TOT_pix[j]+np.sum(CM[np.where(latlon_index == j)]>=0)\n",
    "    CLD_pix[j] = CLD_pix[j]+np.sum(CM[np.where(latlon_index == j)]<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derive the averaged Level-3 cloud fraction\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print('derive the averaged Level-3 cloud fraction')\n",
    "total_cloud_fraction  =  division(CLD_pix,TOT_pix).reshape([nlat,nlon])\n",
    "print(np.nansum(total_cloud_fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOT_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2762160"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2762160"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
